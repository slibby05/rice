\documentclass{book}
\usepackage{thesis}
\usepackage{amsfonts}
\usepackage[fleqn]{amsmath}
\usepackage{xspace}
\usepackage{hyperref}
\usepackage[all]{xy}
\usepackage{mdframed}
\usepackage{qtree}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{array}
\usepackage{hhline}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{tikz}
\usepackage{cite}
\usepackage{tikz-cd}
\usepackage{mathtools}
\usepackage{imakeidx}
\makeindex


\usetikzlibrary{calc,shapes.multipart,chains,arrows}
\def\N{\mathbb{N}}
\newcommand{\xyS}[1]{\ar@{-}@/-6pt/[#1]}
\newcommand{\xyU}[1]{\ar@{-}@/^6pt/[#1]}
\newcommand{\xyD}[1]{\ar@{-}@/_6pt/[#1]}
\newcommand{\xydD}[1]{\ar@{->}@/_6pt/[#1]}
\newcommand{\xydU}[1]{\ar@{->}@/^6pt/[#1]}
\newcommand{\xydS}[1]{\ar@{->}@/-6pt/[#1]}
\newcommand{\graphxy}[1]{\xymatrix@C=-2pt@R=10pt@C=5pt{#1}}
\newcommand{\xynode}[1]{\llap{#1\,} \bullet }
\newcommand{\yxnode}[1]{\bullet\ \ \ \llap{#1\,} }
\newcommand{\tif}[1]{\texttt{if(}#1\texttt{)}}

\newcommand{\cuUnify}{\mathbin{=\!\!:\!\!=}}
\newcommand{\cuFunPat}{\mathbin{=\!\!:\!\!<\!\!<\!\!=}}

\newcommand{\rice}{\texttt{RICE}}
\newcommand{\ricesp}{\texttt{RICE }}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}{Theorem}[theorem]

\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]

\def\O{\mathcal{O}}

\DeclareMathSymbol{:}{\mathord}{operators}{"3A}
%% ODER: format ==         = "\mathrel{==}"
%% ODER: format /=         = "\neq "
%
%
\makeatletter
\@ifundefined{lhs2tex.lhs2tex.sty.read}%
  {\@namedef{lhs2tex.lhs2tex.sty.read}{}%
   \newcommand\SkipToFmtEnd{}%
   \newcommand\EndFmtInput{}%
   \long\def\SkipToFmtEnd#1\EndFmtInput{}%
  }\SkipToFmtEnd

\newcommand\ReadOnlyOnce[1]{\@ifundefined{#1}{\@namedef{#1}{}}\SkipToFmtEnd}
\usepackage{amstext}
\usepackage{amssymb}
\usepackage{stmaryrd}
\DeclareFontFamily{OT1}{cmtex}{}
\DeclareFontShape{OT1}{cmtex}{m}{n}
  {<5><6><7><8>cmtex8
   <9>cmtex9
   <10><10.95><12><14.4><17.28><20.74><24.88>cmtex10}{}
\DeclareFontShape{OT1}{cmtex}{m}{it}
  {<-> ssub * cmtt/m/it}{}
\newcommand{\texfamily}{\fontfamily{cmtex}\selectfont}
\DeclareFontShape{OT1}{cmtt}{bx}{n}
  {<5><6><7><8>cmtt8
   <9>cmbtt9
   <10><10.95><12><14.4><17.28><20.74><24.88>cmbtt10}{}
\DeclareFontShape{OT1}{cmtex}{bx}{n}
  {<-> ssub * cmtt/bx/n}{}
\newcommand{\tex}[1]{\text{\texfamily#1}}	% NEU

\newcommand{\Sp}{\hskip.33334em\relax}


\newcommand{\Conid}[1]{\mathit{#1}}
\newcommand{\Varid}[1]{\mathit{#1}}
\newcommand{\anonymous}{\kern0.06em \vbox{\hrule\@width.5em}}
\newcommand{\plus}{\mathbin{+\!\!\!+}}
\newcommand{\bind}{\mathbin{>\!\!\!>\mkern-6.7mu=}}
\newcommand{\rbind}{\mathbin{=\mkern-6.7mu<\!\!\!<}}% suggested by Neil Mitchell
\newcommand{\sequ}{\mathbin{>\!\!\!>}}
\renewcommand{\leq}{\leqslant}
\renewcommand{\geq}{\geqslant}
\usepackage{polytable}

%mathindent has to be defined
\@ifundefined{mathindent}%
  {\newdimen\mathindent\mathindent\leftmargini}%
  {}%

\def\resethooks{%
  \global\let\SaveRestoreHook\empty
  \global\let\ColumnHook\empty}
\newcommand*{\savecolumns}[1][default]%
  {\g@addto@macro\SaveRestoreHook{\savecolumns[#1]}}
\newcommand*{\restorecolumns}[1][default]%
  {\g@addto@macro\SaveRestoreHook{\restorecolumns[#1]}}
\newcommand*{\aligncolumn}[2]%
  {\g@addto@macro\ColumnHook{\column{#1}{#2}}}

\resethooks

\newcommand{\onelinecommentchars}{\quad-{}- }
\newcommand{\commentbeginchars}{\enskip\{-}
\newcommand{\commentendchars}{-\}\enskip}

\newcommand{\visiblecomments}{%
  \let\onelinecomment=\onelinecommentchars
  \let\commentbegin=\commentbeginchars
  \let\commentend=\commentendchars}

\newcommand{\invisiblecomments}{%
  \let\onelinecomment=\empty
  \let\commentbegin=\empty
  \let\commentend=\empty}

\visiblecomments

\newlength{\blanklineskip}
\setlength{\blanklineskip}{0.66084ex}

\newcommand{\hsindent}[1]{\quad}% default is fixed indentation
\let\hspre\empty
\let\hspost\empty
\newcommand{\NB}{\textbf{NB}}
\newcommand{\Todo}[1]{$\langle$\textbf{To do:}~#1$\rangle$}

\EndFmtInput
\makeatother
%
%
%
%
%
%
% This package provides two environments suitable to take the place
% of hscode, called "plainhscode" and "arrayhscode". 
%
% The plain environment surrounds each code block by vertical space,
% and it uses \abovedisplayskip and \belowdisplayskip to get spacing
% similar to formulas. Note that if these dimensions are changed,
% the spacing around displayed math formulas changes as well.
% All code is indented using \leftskip.
%
% Changed 19.08.2004 to reflect changes in colorcode. Should work with
% CodeGroup.sty.
%
\ReadOnlyOnce{polycode.fmt}%
\makeatletter

\newcommand{\hsnewpar}[1]%
  {{\parskip=0pt\parindent=0pt\par\vskip #1\noindent}}

% can be used, for instance, to redefine the code size, by setting the
% command to \small or something alike
\newcommand{\hscodestyle}{}

% The command \sethscode can be used to switch the code formatting
% behaviour by mapping the hscode environment in the subst directive
% to a new LaTeX environment.

\newcommand{\sethscode}[1]%
  {\expandafter\let\expandafter\hscode\csname #1\endcsname
   \expandafter\let\expandafter\endhscode\csname end#1\endcsname}

% "compatibility" mode restores the non-polycode.fmt layout.

\newenvironment{compathscode}%
  {\par\noindent
   \advance\leftskip\mathindent
   \hscodestyle
   \let\\=\@normalcr
   \let\hspre\(\let\hspost\)%
   \pboxed}%
  {\endpboxed\)%
   \par\noindent
   \ignorespacesafterend}

\newcommand{\compaths}{\sethscode{compathscode}}

% "plain" mode is the proposed default.
% It should now work with \centering.
% This required some changes. The old version
% is still available for reference as oldplainhscode.

\newenvironment{plainhscode}%
  {\hsnewpar\abovedisplayskip
   \advance\leftskip\mathindent
   \hscodestyle
   \let\hspre\(\let\hspost\)%
   \pboxed}%
  {\endpboxed%
   \hsnewpar\belowdisplayskip
   \ignorespacesafterend}

\newenvironment{oldplainhscode}%
  {\hsnewpar\abovedisplayskip
   \advance\leftskip\mathindent
   \hscodestyle
   \let\\=\@normalcr
   \(\pboxed}%
  {\endpboxed\)%
   \hsnewpar\belowdisplayskip
   \ignorespacesafterend}

% Here, we make plainhscode the default environment.

\newcommand{\plainhs}{\sethscode{plainhscode}}
\newcommand{\oldplainhs}{\sethscode{oldplainhscode}}
\plainhs

% The arrayhscode is like plain, but makes use of polytable's
% parray environment which disallows page breaks in code blocks.

\newenvironment{arrayhscode}%
  {\hsnewpar\abovedisplayskip
   \advance\leftskip\mathindent
   \hscodestyle
   \let\\=\@normalcr
   \(\parray}%
  {\endparray\)%
   \hsnewpar\belowdisplayskip
   \ignorespacesafterend}

\newcommand{\arrayhs}{\sethscode{arrayhscode}}

% The mathhscode environment also makes use of polytable's parray 
% environment. It is supposed to be used only inside math mode 
% (I used it to typeset the type rules in my thesis).

\newenvironment{mathhscode}%
  {\parray}{\endparray}

\newcommand{\mathhs}{\sethscode{mathhscode}}

% texths is similar to mathhs, but works in text mode.

\newenvironment{texthscode}%
  {\(\parray}{\endparray\)}

\newcommand{\texths}{\sethscode{texthscode}}

% The framed environment places code in a framed box.

\def\codeframewidth{\arrayrulewidth}
\RequirePackage{calc}

\newenvironment{framedhscode}%
  {\parskip=\abovedisplayskip\par\noindent
   \hscodestyle
   \arrayrulewidth=\codeframewidth
   \tabular{@{}|p{\linewidth-2\arraycolsep-2\arrayrulewidth-2pt}|@{}}%
   \hline\framedhslinecorrect\\{-1.5ex}%
   \let\endoflinesave=\\
   \let\\=\@normalcr
   \(\pboxed}%
  {\endpboxed\)%
   \framedhslinecorrect\endoflinesave{.5ex}\hline
   \endtabular
   \parskip=\belowdisplayskip\par\noindent
   \ignorespacesafterend}

\newcommand{\framedhslinecorrect}[2]%
  {#1[#2]}

\newcommand{\framedhs}{\sethscode{framedhscode}}

% The inlinehscode environment is an experimental environment
% that can be used to typeset displayed code inline.

\newenvironment{inlinehscode}%
  {\(\def\column##1##2{}%
   \let\>\undefined\let\<\undefined\let\\\undefined
   \newcommand\>[1][]{}\newcommand\<[1][]{}\newcommand\\[1][]{}%
   \def\fromto##1##2##3{##3}%
   \def\nextline{}}{\) }%

\newcommand{\inlinehs}{\sethscode{inlinehscode}}

% The joincode environment is a separate environment that
% can be used to surround and thereby connect multiple code
% blocks.

\newenvironment{joincode}%
  {\let\orighscode=\hscode
   \let\origendhscode=\endhscode
   \def\endhscode{\def\hscode{\endgroup\def\@currenvir{hscode}\\}\begingroup}
   %\let\SaveRestoreHook=\empty
   %\let\ColumnHook=\empty
   %\let\resethooks=\empty
   \orighscode\def\hscode{\endgroup\def\@currenvir{hscode}}}%
  {\origendhscode
   \global\let\hscode=\orighscode
   \global\let\endhscode=\origendhscode}%

\makeatother
\EndFmtInput
%












































\title{Making Curry with Rice \\
       \large{An Optimizing Curry Compiler}}
\author{Steven Libby}


\begin{document}
\frontmatter
\maketitle

\tableofcontents

\setcounter{chapter}{0}
\chapter{Introduction} \label{ch:Introduction}


With all of the chaos in the world today,
sometimes it's nice to just relax and make a nice Curry.
But people today are impatient.
They can't wait; they want their Curry fast.
This is a problem, because Curry has historically been considered slow.
Some have considered it unusably slow,
which is a shame, because Curry is actually a great languguage,
and can solve many problems well.
In this dissertation we aim to recitify the problem
of Curry taking too long.
We present the \ricesp Curry compiler,
and show how it can deliver a fast, satisfying, Curry.

\subsection{Why Curry?}

Functional logic programming is a very powerful technique for
expressing complicated ideas in a simple form.
Curry implements these ideas with a clean, easy to read syntax,
which is similar to Haskell, a well known functional programming language.
It's also lazy, so evaluation of Curry programs is similar to Haskell as well.
Curry extends Haskell with two new concepts.
First, there are non-deterministic functions, such as ``\ensuremath{\mathbin{?}}''.  
Semantically \ensuremath{\Varid{a}\mathbin{?}\Varid{b}} will evaluate
\ensuremath{\Varid{a}} and \ensuremath{\Varid{b}} and will return both answers to the user.
Second, there are free, or logic, variables.
A free variable is a variable that is not in the scope of the current function.
The value of a free variable is not defined, but it may be constrained.

Consider the following Curry code for solving n-queens:\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{4}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{queens}\mid \Varid{isEmpty}\;(\Varid{set1}\;\Varid{unsafe}\;\Varid{p})\mathrel{=}\Varid{p}{}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mathbf{where}\;\Varid{p}\mathrel{=}\Varid{permute}\;[\mskip1.5mu \mathrm{1}\mathinner{\ldotp\ldotp}\Varid{n}\mskip1.5mu]{}\<[E]%
\\[\blanklineskip]%
\>[3]{}\Varid{unsafe}\;(\Varid{xs}\plus [\mskip1.5mu \Varid{a}\mskip1.5mu]\plus \Varid{ys}\plus [\mskip1.5mu \Varid{b}\mskip1.5mu]\plus \Varid{zs})\mathrel{=}\Varid{abs}\;(\Varid{a}\mathbin{-}\Varid{b})\cuUnify\Varid{length}\;\Varid{ys}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks

In the \ensuremath{\Varid{unsafe}} function the input list is broken into 5 pieces.
Two of the pieces, \ensuremath{\Varid{a}} and \ensuremath{\Varid{b}}, are lists with a single element.
The sublists, \ensuremath{\Varid{xs}}, \ensuremath{\Varid{ys}}, and \ensuremath{\Varid{zs}} are free to be as long as they want.
However, We've constrained the total list \ensuremath{\Varid{xs}\plus [\mskip1.5mu \Varid{a}\mskip1.5mu]\plus \Varid{ys}\plus [\mskip1.5mu \Varid{b}\mskip1.5mu]\plus \Varid{zs}}
to be the same as the argument.
The effect is that \ensuremath{\Varid{a}} and \ensuremath{\Varid{b}} are arbitrary elements in the list,
and \ensuremath{\Varid{ys}} is the list of elements between \ensuremath{\Varid{a}} and \ensuremath{\Varid{b}}.
If the difference between \ensuremath{\Varid{a}} and \ensuremath{\Varid{b}} is equal to the distance between
the two element, then two queens could capture each other diagonally.
So, we compute the set of all capturing queens,
If the set is empty, then we return that permutation.

Free variables are given concrete values in Curry programs through narrowing.
The semantics of narrowing and non-determinism in Curry are given by 
Antoy et al. \cite{Needed}

\subsection{Current Compilers}

There are currently two mature Curry compilers, Pakcs \cite{pakcs} and Kics2 \cite{kics2}.
Pakcs compiles Curry to Prolog in an effort to leverage Prolog's non-determinism and free variables.
Kics2 compiles Curry to Haskell in an effort to leverage Haskell's
higher order functions and optimizing compiler.
Both compilers have their advantages.
Pakcs tends to perform better on non-deterministic expressions with free variables,
where Kics2 tends to perform much better on deterministic expressions.
Unfortunately neither of these compilers perform well in both circumstances.

Sprite \cite{sprite}, an experimental compiler, aims to fix these inefficiencies.
The strategy is to compile to a virtual assembly language, known as LLVM.
So far, Sprite has shown promising improvements over both Pakcs and Kics2 in performance,
but it is not a mature compiler.

Similarly Mcc \cite{mcc} also worked to improve performance by compiling to C.
While Mcc often ran faster than both Pakcs or Kics2,
it could perform very slowly on common Curry examples.
It's also no longer in active development.

One major disadvantage of all four compilers is that they all
attempt to pass off optimization to another compiler.
Pakcs attempts to have Prolog optimize the non-deterministic code;
Kics2 attempts to use Haskell to optimize
deterministic code; Sprite attempts to use LLVM to optimize the low level code;
and Mcc simply didn't optimize its code.
Unfortunately none of these approaches works very well.
While some implementations of Prolog can optimize non-deterministic expressions,
they have no concept of higher order functions,
so there are many optimizations that cannot be applied.
Kics2 is in a similar situation.  
In order to incorporate non-deterministic computations in Haskell, 
a significant amount of code must be threaded through each computation.
This means that any non-deterministic expression cannot be optimized in Kics2.
Finally, since LLVM doesn't know about either higher order functions or non-determinism,
it loses many easy opprotunities for optimization.

Curry programs have one last hope for efficient execution.
Recently, many scientists \cite{peval, offline_peval} 
have developed a strong theory of partial evaluation for functional logic programs.
While these results are interesting, partial evaluation is not currently automatic in Curry.
Guidance is required from the programmer to run the optimization.
Furthermore, the optimization fails to optimize several common programs.

\subsection{The Need for Optimizations}

So far, none of these approaches have included the large body 
of work on program optimizations
\cite{orbit, dragon, optimizationAllen, dataflowAllen, ssa, compilersAppel, continuationsAppel, 
ANormal, shortcutDeforestation, ultimateGoto, rabbit, lambdaRename, dataflowKildall, dominatorFlow, 
haskellInliner, stg, ssaVariable, deforestationWadler, ssaOptimizations }.
This leads to the inescapable conclusion that Curry needs an optimizer.
We propose a new compiler environment for developing and testing optimizations.
The Reduction Inspired Compiler Environment (\rice) Curry compiler.
This compiler is intended to make developing new optimizations for Curry as simple as possible.
We test this idea by developing several common optimizations for the \ricesp compiler.
Furthermore we implement three specific optimizations for Curry, 
Unboxing \cite{unboxing}, Shortcutting \cite{shortcutting}, and Deforestation \cite{shortcutDeforestation}.
We chose these optimizations specifically because they focus on reducing the amount of memory
consumed by programs, which is a common problem for Curry programs \cite{proposal}.

The rest of this dissertation is organized as follows:
chapter \label{ch:Mathematical Background} presents the mathematical background of Term and Graph Rewriting;
chapter \label{ch:The Curry Language} presents the Curry Language and its semantics;
chapter \label{ch:The Generated Code} discusses the target code for this compiler;
chapter \label{ch:Generating and Altering Subexpressions} introduces the GAS system for implementing optimizations;
chapter \label{ch:The Compiler Pipeline} overviews the compiler pipeline, and the translation to C.
chapter \label{ch:Basic Optimizations} discusses the implementation of several common optimizations;
chapter \label{ch:Memory Optimizations} discusses the implementation of Unboxing, Shortcutting, and Deforestation;
chapter \label{ch:Results} shows the results of our optimizations;
and chapter \label{ch:Conclusion} concludes and discusses future work.


\mainmatter

\chapter{Mathematical Background} \label{ch:Mathematical Background}


When cooking, it is very important to follow the rules.
You don't need to stick to an exact recipe, 
but you do need to know the how ingredients will react to temperature
and how different combinations will taste.
Otherwise you might get some unexpected reactions.

Similarly, there isn't a single way to compile Curry programs,
however we do need to know the rules of the game.
Throughout this compiler, we'll be transforming Curry programs
in many different ways, and it's important to make sure that all
of these transformations respect the rules of Curry.
As we'll see, if we break these rules, 
then we may get some unexpected results.

We introduce the concept of Rewriting, 
along with the more specific Term and Graph Rewriting.
We give a basic intuition about how to apply these topics,
and show several examples using a small, but not trivial,
example of a rewrite system for Peano Arithmetic \ref{fig:peano}.

\section{Rewriting}
In programming language terms, the rules of Curry are its semantics.
The semantics of Curry are generally given in terms of rewriting.
\cite{IntegrationFunLog, FunLog, Needed}
While there are other semantics \cite{currySemantics, crwl, monadSemantics}, 
rewriting is a common formalism for many functional languages,
and the general theory of Curry grew out of this discipline \cite{Needed},
a good fit for Curry \cite{CurryReport}.
We'll give a definition of rewrite systems,
then we'll look at two distinct types of rewrite systems:
Term Rewrite Systems, which are used to implement transformations and optimizations
on the Curry syntax trees;
and Graph Rewrite Systems, which define the operational semantics for Curry programs.
This mathematical foundation will help us justify the correctness of our transformations
even in the presence of laziness, non-determinism, and free variables.

An Abstract Rewriting System (ARS)\index{Abstract Rewriting System}
is a set $A$ along with a relation $\to$\index{$\to$}.
We write $a \to b$ instead of $(a,b) \in \to$, and we have several modifiers on our relation.
\begin{itemize}
    \item $a \to^n b$\index{$\to^n$} iff $a = x_0 \to x_1 \to \ldots x_n = b$.
    \item $a \to^{\le n} b$\index{$\to^{\le n}$} b iff $a \to^i b$ and $i \leq n$.
    \item reflexive closure: $a \to^= b$\index{$\to^=$} iff $a = b$ or $a \to b$.
    \item symmetric closure: $a \leftrightarrow b$\index{$\leftrightarrow$} iff $a \to b$ or $b \to a$.
    \item transitive closure: $a \to^+ b$\index{$\to^+$} iff $\exists n\in \N. a \to^{\le n} b$.
    \item reflexive transitive closure: $a \to^* b$\index{$\to^*b$} iff $a \to^= b$ or $a \to^+ b$.
    \item rewrite derivation\index{rewrite derivation}: 
          a sequence of rewrite steps $a_0 \to a_1 \to \ldots a_n$.
    \item $a$ is in Normal Form (NF)\index{normal form} if no rewrite rules can apply.
\end{itemize}

A rewrite system is meant to invoke the feeling of algebra.
In fact, rewrite system are much more general, but they can still retain the feeling.
If we have an expression $(x\cdot x + 1)(2 + x)$, we might reduce this with the reduction in figure \ref{fig:reduce}.

\begin{figure}
\begin{tabular}{rll}
          & $(x\cdot x + 1)(2 + x)$                          & \\
    $\to$ & $(x\cdot x + 1)(x + 2)$                          & by commutativity of addition \\
    $\to$ & $(x^2 + 1)(x + 2)$                               & by definition of $x^2$\\
    $\to$ & $x^2\cdot x + 2\cdot x^2 + 1\cdot x + 1 \cdot 2$ & by FOIL\\
    $\to$ & $x^2\cdot x + 2x^2 + x + 2$                      & by identity of multiplication\\ 
    $\to$ & $x^3 + 2x^2 + x + 2$                             & by definition of $x^3$\\
\end{tabular}\\
    \caption{reducing $(x\cdot x + 1)(2 + x)$ using the standard rules of algebra}
    \label{fig:reduce}
\end{figure}

We can conclude that $(x\cdot x + 1)(x + 2) \to^+ x^3 + 2x^2 + x + 2$.
This idea of rewriting invokes the feel of algebraic rules.
The mechanical process of rewriting allows for a simple implementation on a computer.

It's worth understanding the properties and limitations of these rewrite systems.
Traditionally there are two important questions to answer about any rewrite system.
Is it \emph{confluent}? Is it \emph{terminating}?

A \emph{confluent}\index{confluent} system is a system 
where the order of the rewrites doesn't change the final result.
For example, consider the distributive rule.
When evaluating $3\cdot(4 + 5)$ we could either evaluate the addition or multiplication first.
Both of these reductions arrived at the same answer as can be seen in figure \ref{fig:confluent}.

\begin{figure}[h]
  \begin{subfigure}{.5\textwidth}
      \centering
    \fbox{
      \begin{tabular}{rl}
              & $3\cdot(4 + 5)$       \\
        $\to$ & $3\cdot 4 + 3\cdot 5$ \\
        $\to$ & $12 + 15$             \\
        $\to$ & $27$                  \\
      \end{tabular}
    }
      \caption{distributing first}
  \end{subfigure}
  \begin{subfigure}{.5\textwidth}
      \centering
    \fbox{
      \begin{tabular}{rl}
              & $3\cdot(4 + 5)$       \\
        $\to$ & $3\cdot 9$            \\
        $\to$ & $27$                  \\
      \end{tabular}
    }
      \caption{reducing $4 + 5$ first}
  \end{subfigure}
    \caption{Two possible reductions of $3\cdot(4 + 5)$.  
             Since this is a confluent system, they both can rewrite to 27.}
    \label{fig:confluent}
\end{figure}

In a \emph{terminating}\index{terminating} system every derivation is finite.
That means that eventually there are no rules that can be applied.
The distributive rule is terminating, 
whereas the commutative rule is not terminating.  See figure \ref{fig:terminate}.

\begin{figure}[h]
  \begin{subfigure}{.5\textwidth}
    \centering
    \fbox{
      \begin{tabular}{rl}
              & $a\cdot (b + c)$\\
        $\to$ & $a\cdot b + a\cdot c$ \\
      \end{tabular}
    }
  \end{subfigure}
  \begin{subfigure}{.5\textwidth}
    \centering
    \fbox{
      \begin{tabular}{rl}
              & $x + y$\\
        $\to$ & $y + x$\\
        $\to$ & $x + y$\\
        $\ldots$      & \\
      \end{tabular}
    }
  \end{subfigure}
    \caption{A system with a single rule for distribution is terminating,
             but any system with a commutative rule is not.
             Note that $x + y \to^2 x + y$}
    \label{fig:terminate}
\end{figure}

Confluence and termination are important topics in rewriting, but we will largely ignore them.
After all, Curry programs are neither confluent nor terminating.
However, there will be a few cases where these concepts will be important.
For example, if our optimizer isn't terminating, then we'll never actually compile a program.

Now that we have a general notation for rewriting, we can introduce two important rewriting frameworks:
term rewriting and graph rewriting, where we are transforming trees and graphs respectively.

\section{Term Rewriting}

As mentioned previously, one application of term rewriting
is to transform terms representing syntax trees.
This will be useful in optimizing the Abstract Syntax Trees (ASTs) of Curry programs.
Term rewriting is a special case of abstract rewriting.
Therefore everything from abstract rewriting will apply to term rewriting.

A term is made up of signatures and variables. \cite{AdvancedTRS}[Def 3.1.2]
We let $\Sigma$ and $V$ be two arbitrary alphabets, 
but we require that $V$ be countably infinite, and $\Sigma \cap V = \emptyset$ to avoid name conflicts.
A \emph{signature}\index{signature} $f^{(n)}$ consists of a name $f \in \Sigma$ and an arity $n\in \mathbb{N}$.
A \emph{variable}\index{variable} $v\in V$ is just a name.
Finally a \emph{term}\index{term} is defined inductively.
The term $t$ is either a variable $v$, or it's a signature $f^{(n)}$ with children $t_1,t_2, \ldots t_n$,
where $t_1,t_2, \ldots t_n$ are all terms.
We write the set of terms all as $T(\Sigma,V)$\index{$T(\Sigma,V)$}.
If $t \in T(\Sigma,V)$ then we write $Var(t)$ to denote the set of variables in $t$.
By definition $Var(t) \subseteq V$.
We say that a term is \emph{linear}\index{linear} if no variable appears twice in the term \cite{AdvancedTRS}[Def. 3.2.4].

This inductive definition gives us a tree structure for terms.
As an example consider Peano arithmetic $\Sigma = \{+^2, *^2, -^2, <^2, 0^0, S^1, True^0, False^0\}$.
We can define the term $*(+(0, S(0)), +(S(0), 0))$.
This gives us the tree in figure \ref{fig:tree}.
Every term can be converted into a tree like this and vice versa.
The symbol at the top of the tree is called the root of the term.


\begin{figure}[ht]
    \Tree[.$*$ [.$+$ $0$ [.$S$ $0$ ] ] [.$+$ [.$S$ $0$ ] $0$ ] ]\\
    \caption{Tree representation of the term $*(+(0, S(0)), +(S(0), 0))$.}
    \label{fig:tree}
\end{figure}

A \emph{child}\index{child} $c$ of term $f(t_1, t_2, \ldots t_n)$ is one of $t_1, t_2, \ldots t_n$.
A \emph{subterm}\index{subterm} $s$ of $t$ is either $t$ itself, or it is a subterm of a child of $t$.
We write $s = t|_p$\index{$t|_p$} where $p = [i_1,i_2,\ldots i_n]$ to denote that 
$t$ has child $t_{i_1}$ which has child $t_{i_2}$ and so on until $t_{i_n} = s$.
Note that we can define this recursively as
$t\vert_{[i_1,i_2,\ldots i_n]} = t_{i_1}\vert_{[i_2,\ldots i_n]}$, which matches our definition for subterm.
We call $[i_1,i_2,\ldots i_n]$ the \emph{path}\index{path} from $t$ to $s$ \cite{AdvancedTRS}[Def 3.1.5].
We write $\epsilon$ for the empty path,
and $i:p$ for the path starting with the number $i$ and followed by the path $p$,
and $p\cdot q$ for concatenation of paths $p$ and $q$.

In our previous term $S(0)$ is a subterm in two different places.
One occurrence is at path $[0,1]$, and the other is at path $[1,0]$.

We write $t[p \to r]$\index{$t[p \to r]$} to denote replacing subterm $t|_p$ with $r$.
We define the algorithm for this in figure \ref{fig:subterm}.

\begin{figure}[ht]
    $t[\epsilon \to r] = r$\\
    $f(t_1,\ldots t_i,\ldots t_n)[i:p \to r] = f(t_1,\ldots t_i[p\to r],\ldots t_n) $\\
    \caption{algorithm for finding a subterm of $t$.}
    \label{fig:subterm}
\end{figure}

In our above example $t =*(+(0, S(0), +(S(0), 0)))$,
We can compute the rewrite  $t[[0,1] \to *(S(0),S(0))]$, and we get the term
$*(+(0,*(S(0),S(0))), +(S(0), 0))$, with the tree in figure \ref{fig:subtree}.

\begin{figure}[h]
    \begin{center}
    \begin{tabular}{>{\centering\arraybackslash}m{2cm}>{\centering\arraybackslash}m{1cm}>{\centering\arraybackslash}m{2cm}} 
        \Tree[.$*$ [.$+$ $0$ [.$S$ $0$ ] ] [.$+$ [.$S$ $0$ ] $0$ ] ] &
        {\huge $\Rightarrow$} &
        \Tree[.$*$ [.$+$ $0$ [.$*$ [.$S$ $0$ ] [.$S$ $0$ ] ] ] [.$+$ [.$S$ $0$ ] $0$ ] ] \\
    \end{tabular}
    \end{center}
    \caption{The result of the computation $t[[0,1] \to S(0)]$}
    \label{fig:subtree}
\end{figure}

A substitution replaces variables with terms.
Formally, a \emph{substitution}\index{substitution} is a mapping from 
$\sigma : V \to T(\Sigma,V)$\index{$\sigma$},
such that $\sigma(x) \ne x$ \cite{AdvancedTRS}[Def. 3.1.7].
We write $\sigma = \{v_1 \mapsto t_1, \ldots v_n \mapsto t_n\}$ to denote the substitution
where $s(v_i) = t_i$ for $i \in \{1\ldots n\}$, and $s(v) = v$ otherwise.
We can uniquely extend $\sigma$ to a function on terms by figure \ref{fig:substitute}

\begin{figure}[h]
    $\sigma'(v) = \sigma(v)$\\
    $\sigma'(f(t_1,\ldots t_n) = f(\sigma'(t_1) \ldots \sigma'(t_n))$\\
    \caption{Algorithm for applying a substitution.}
    \label{fig:substitute}
\end{figure}

Since this extension is unique, we will just write $\sigma$ instead of $\sigma'$.
Term $t_1$ \emph{matches} term $t_2$
if there exists some substitution $\sigma$ such that $t_1 = \sigma(t_2)$ \cite{AdvancedTRS}[3.1.8],.
We call $\sigma$ a \emph{matcher}\index{matcher}.
Two terms $t_1$ and $t_2$ \emph{unify}
if there exists some substitution $\sigma$ such that $\sigma(t_1) = \sigma(t_2)$ \cite{AdvancedTRS}[3.1.8],.
In this case $\sigma$ is called a \emph{unifier}\index{unifier} for $t_1$ and $t_2$.

We can order substitutions based on what variables they define.
A substitution $\sigma \leq \tau$, iff,
there is some substitution $\nu$ such that $\tau = \nu \circ \sigma$.
The relation $\sigma \leq \tau$ should be read as $\sigma$ is more general than $\tau$,
and it is a quasi-order on the set of substitutions.
A unifier $u$ for two terms is \emph{most general} (or an mgu), iff, for all unifiers $v$, $v \le u$.
Mgu's are unique up to renaming of variables.
That is, if $u_1$ and $u_2$ are mgu's for two terms, then $u_1 = \sigma_1 \circ u_2$
and $u_2 = \sigma_2 \circ u_1$.
This can only happen if $\sigma_1$ and $\sigma_2$ just rename the variables in their terms.

As an example $+(x,y)$ matches $+(0, S(0))$ with $\sigma = \{x \mapsto 0, y \mapsto S(0)\}$.
The term $+(x, S(0))$ unifies with term $+(0, y)$ with unifier
$\sigma = \{x \mapsto 0, y \mapsto S(0)\}$.
If $\tau = \{x \mapsto 0, y \mapsto S(z)\}$, then $\tau \le \sigma$.  We can define $\nu = \{z \mapsto 0\}$,
and $\{\sigma = \nu \circ \tau\}$

Now that we have a definition for a term, we need to be able to rewrite it.
A \emph{rewrite rule}\index{rewrite rule} $l \to r$ is a pair of terms.
However this time we require that $Var(r) \subseteq Var(l)$, and that $l \not \in V$.
A \emph{Term Rewriting System (TRS)}\index{Term Rewriting System (TRS)}
is the pair $(T(\Sigma,V),R)$ where $R$ is a set of rewrite rules.


\theoremstyle{definition}
\begin{definition}{Rewriting\index{Rewriting}:}
Given terms $t,s$, path $p$, and rule $l \to r$, we say that $t$ rewrites to $s$ if, 
$l$ matches $t\vert_p$ with matcher $\sigma$, and $t[p \to \sigma(r)] = s$.
The term $\sigma(l)$ is the \emph{redex}\index{redex}, and the term $\sigma(r)$ is the \emph{contractum}\index{contractum}
of the rewrite.
\end{definition}

There are a few important properties of rewrite rules $l \to r$.
A rule is left or right linear if $l$ or $r$ is linear respectively
\cite{AdvancedTRS}[Def. 3.2.4].
A rule is \emph{collapsing}\index{collapsing} if $r \in V$.
A rule is \emph{duplicating}\index{duplicating} if there is an $x \in V$ that occurs more often in $r$ than in $l$
\cite{AdvancedTRS}[Def. 3.2.5].

Two terms $s$ and $t$ are \emph{overlapping}\index{overlapping} if $t$ unifies with a subterm of $s$,
or $s$ unifies with a subterm of $t$ at a non-variable position \cite{AdvancedTRS}[Def. 4.3.3].
Two rules $l_1 \to r_1$ and $l_2 \to r_2$ if $l_1$ and $l_2$ overlap.
A rewrite system is \emph{overlapping} if, and only if, any two rules overlap.
Otherwise it's non-overlapping.
Any non-overlapping left linear system is \emph{orthogonal}\index{orthogonal} \cite{AdvancedTRS}[Def.4.3.4].
Orthogonal systems have several nice properties, such as the following theorem \cite{AdvancedTRS}[Thm. 4.3.11].

\begin{theorem}
Every orthogonal TRS is confluent.
\end{theorem}

As an example, in figure \ref{fig:overlap} examples (b) and (c) both overlap.
It's clear that these systems aren't confluent,
but non-confluence can arise in more subtle ways.
The converse to theorem 2.1 isn't true. There can be overlapping systems which are confluent.

\begin{figure}[h]
    \begin{subfigure}{.26\textwidth}
    \fbox{
    \begin{tabular}{c}
    $g(0,y) \to 0$\\
    $g(1,y) \to 1$\\
    \end{tabular}
    }
    \caption{A non-overlapping system}
    \end{subfigure}
    \hspace{.06\textwidth}
    \begin{subfigure}{.26\textwidth}
    \fbox{
    \begin{tabular}{c}
    $g(0,y) \to 0$\\
    $g(x,1) \to 1$\\
    \end{tabular}
    }
    \caption{A system that overlaps at the root}
    \end{subfigure}
    \hspace{.06\textwidth}
    \begin{subfigure}{.26\textwidth}
    \fbox{
    \begin{tabular}{c}
    $f(g(x,y)) \to 0$\\
    $g(x,y)    \to 1$\\
    \end{tabular}
    }
    \caption{A system that overlaps at a subterm}
    \end{subfigure}
    \caption{Three TRSs demonstrating how rules can overlap.
            In (a) they don't overlap at all,
            In (b) both rules overlap at the root,
            and in (c) rule 2 overlaps with a subterm of rule 1.}
    \label{fig:overlap}
\end{figure}

When defining rewrite systems we usually follow the constructor discipline;
we separate the set $\Sigma = C \uplus F$.
$C$ is the set of \textit{constructors},
and $F$ is the set of \textit{function symbols}.
Furthermore, for every rule $l \to r$, the root of $l$ is a function symbol, 
and every other symbol is a constructor or variable.
We call such systems \textit{constructor systems}.
As an example, the rewrite system for Peano arithmetic is a constructor system.

\begin{figure}[h]
    \begin{tabular}{lclcl}
        $R_1$ &    : & $0    + y$      & $\to$ & $y$       \\
        $R_2$ &    : & $S(x) + y$      & $\to$ & $S(x+y)$  \\
        $R_3$ &    : & $0    * y$      & $\to$ & $0$       \\
        $R_4$ &    : & $S(x) * y$      & $\to$ & $y+(x*y)$ \\
        $R_5$ &    : & $0    - y$      & $\to$ & $0$       \\
        $R_6$ &    : & $S(x) - 0$      & $\to$ & $S(x)$    \\
        $R_7$ &    : & $S(x) - S(y)$   & $\to$ & $x - y$   \\
        $R_8$ &    : & $0    \le y$    & $\to$ & $True$    \\
        $R_9$ &    : & $S(x) \le 0$    & $\to$ & $False$    \\
        $R_{10}$ & : & $S(x) \le S(y)$ & $\to$ & $x < y$   \\
        $R_{11}$ & : & $0    = 0   $   & $\to$ & $True$    \\
        $R_{12}$ & : & $S(x) = 0   $   & $\to$ & $False$    \\
        $R_{13}$ & : & $0    = S(y)$   & $\to$ & $False$    \\
        $R_{14}$ & : & $S(x) = S(y)$   & $\to$ & $x = y$   \\
    \end{tabular}
    \caption{The rewrite rules for Peano Arithmetic with addition, multiplicaton,
             subtraction, and comparison.  All operators use infix notation.}
    \label{fig:peano}
\end{figure}

The two sets are $C = \{0, S, True, False\}$ and $F = \{+,*,-,\le\}$,
and the root of the left hand side of each rule is a function symbol.
In contrast, the SKI system is not a constructor system.
While $S,K,I$ can all be constructors, the $Ap$ symbol appears in both root
and non-root positions of the left hand side of rules.
This example will become important for us in Curry.
We will do something similar to implement higher order functions.
This means that Curry programs won't directly follow the constructor discipline.
Therefore, we must be careful when specifying the semantics of function application.

\begin{figure}[h]
    \begin{tabular}{lcl}
        $Ap(I,x)$             & $\to$ & $x$\\
        $Ap(Ap(K,x),y)$       & $\to$ & $x$\\
        $Ap(Ap(Ap(S,x),y),z)$ & $\to$ & $Ap(Ap(x,z),Ap(y,z))x$\\
    \end{tabular}
    \caption{The SKI system from combinatorial logic.}
    \label{fig:SKI}
\end{figure}


Constructor systems have several nice properties.
They are usually easy to analyze for confluence and termination.
For example, if the left hand side of two rules don't unify, then they cannot overlap.
We don't need to check if subterms overlap.
Furthermore, any term that consists entirely of constructors and variables is in normal form.
For this reason, it's not surprising that most functional languages are based on constructor systems.

%Finally, we can introduce conditions to rewriting systems.
%We introduce a new symbol $True$ to the rewrite system's alphabet $\Sigma$.
%A conditional rewrite rule is a rule $l \vert c \to r$ where $l,c,$ and $r$ are terms.
%A term $t$ conditionally rewrites to $s$ with rule $l \vert c \to r$ if
%there exists a path $p$ and substitution $\sigma$ such that 
%$t_p = \sigma(l)$, $\sigma(c) \to^* True$, and $s = \sigma(r)$.
%
%The idea is actually a pretty simple extension.
%In order to rewrite a term, we must satisfy a condition.
%If the condition is true, then the rule is applied.
%In order to simplify the semantics of this system,
%we determine if a condition is true by rewriting it to the value $True$.
%Figure \ref{fig:gcd} gives an example of a conditional rewrite system for computing
%greatest common divisor.  It uses the rule defined in \ref{fig:peano}.
%
%\begin{figure}
%    \begin{tabular}{lllcl}
%        $gcd(x,x)$ &         &           & $\to$ & $x$ \\
%        $gcd(x,y)$ & $\vert$ & $y \le x$ & $\to$ & $gcd(x-y,y)$ \\
%        $gcd(x,y)$ & $\vert$ & $x \le y$ & $\to$ & $gcd(x,y-x)$ \\
%    \end{tabular}
%    \caption{Conditional rewrite system for computing greatest common divisor.}
%    \label{fig:gcd}
%\end{figure}
%
%While most treatments of conditional rewriting \cite{IntegrationFunLog,condKaplan}
%define a condition as a pair $s = t$ where $s$ and $t$ mutually rewrite to each other,
%We chose this definition because it's closer to the definition of Curry,
%where the condition must reduce to the boolean value \texttt{True} for the rule to apply.
%
%Curry uses conditional rewriting extensively,
%and efficiently evaluating conditional rewrite systems 
%is the core problem in most functional logic languages.
%The solution to this problem comes from the theory of narrowing.


\section{Narrowing}

Narrowing was originally developed to solve the problem of semantic unification.
The goal was, given a set of equations $E = \{a_1 = b_2, a_2 = b_2, \ldots a_n = b_n\}$ 
how do you solve the $t_1 = t_2$ for arbitrary terms $t_1$ and $t_2$.
Here a solution to $t_1 = t_2$ is a substitution $\sigma$ such that $\sigma(t_1)$
can be transformed into $\sigma(t_2)$ by the equations in $E$.

As an example let $E = \{*(x +(y, z)) = +(*(x,y), *(x,z))\}$
Then the equation $*(1,+(x,3)) = +(+(*(1,4), *(y,5)), *(z,3))$
is solved by $\sigma = \{x \mapsto +(4,5), y \mapsto 1, z \mapsto 1\}$.
The derivation is in figure \ref{fig:narrow}.

\begin{figure}[h]
\begin{tabular}{ll}
    $\sigma(*(1,+(x,3)))$                & = \\
    $*(1,+(+(4,5),3))$                   & = \\
    $+(*(1,+(4,5)),*(1,3))$              & = \\
    $+(+(*(1,4),*(1,5)),*(1,3))$         & = \\
    $\sigma(+(+(*(1,4),*(y,5)),*(z,3)))$ &
\end{tabular}
    \caption{Derivation of $*(1,+(x,3)) = +(+(*(1,4), *(y,5)), *(z,3))$ with
             $\sigma = \{x \mapsto +(4,5), y \mapsto 1, z \mapsto 1\}$.}
    \label{fig:narrow}
\end{figure}

Unsurprisingly, there is a lot of overlap with rewriting.
One of the earlier solutions to this problem was to convert 
the equations into a confluent, terminating rewrite system. \cite{KnuthBendix}
Unfortunately, this only works for ground terms, that is, terms without variables.
However, this idea still has merit.
So we want to extend it to terms with variables.

Before, when we rewrote a term $t$ with rule $l \to r$, we assumed it was a ground term,
then we could find a substitution $\sigma$ that would match a subterm $t\vert_p$ with $l$,
so that $\sigma(l) = t\vert_p$.
To extend this idea to terms with variables in them, 
we look for a unifier $\sigma$ that unifies $t\vert_p$ with $l$.
This is really the only change we need to make \cite{AdvancedTRS}.
However, now we record $\sigma$, because it is part of our solution.

\theoremstyle{definition}
\begin{definition}{Narrowing\index{Narrowing}:}
Given terms $t,s$, path $p$, and rule $l \to r$, we say that $t$ narrows to $s$ if, 
$l$ unifies with $t\vert_p$ with unifier $\sigma$, and $t[p \to \sigma(r)] = s$.
We write $t \rightsquigarrow_{p,l\to r,\sigma} s$.
We may write $t \rightsquigarrow_\sigma s$ if $p$ and $l \to r$ are clear.
\end{definition}

Notice that this is almost identical to the definition of rewriting.
The only difference is that $\sigma$ is a unifier instead of a matcher.

Narrowing was first developed to solve equations for automated theorem provers \cite{narrowing}.
However, for our purposes it's more important that narrowing allows us to
rewrite terms with free variables. \cite{multiparadigm}

At this point, rewrite systems are a nice curiosity,
but they are completely impractical. 
This is because we don't have a plan for solving equations in them.
In the definition for both rewriting and narrowing,
we did not specify how to find $\sigma$ the correct rule to apply, or even
what subterm to apply the rule.

In confluent terminating rewrite systems, we could simply try every possible rule
at every possible position with every possible substitution.
Since the system is confluent, we could choose the first rule that could be successfully applied,
and since the system is terminating, we'd be sure to find a normal form.
In a narrowing system, this is still not guaranteed to halt, because there could be
an infinite number of substitutions.
This is the best possible case for rewrite systems, 
and we still can ensure that our algorithm will finish.
We need a systematic method for deciding what rule should be applied,
what subterm to apply it to,
and what substitution to use.
This is the role of a strategy.

\section{Rewriting Strategies}

Our goal with a rewriting strategy is to be able to find a normal form for any term.
Similarly our goal for narrowing will be to find a normal form and substitution.
However, we want to be efficient when rewriting.
We would like to use only local information when deciding what rule to select.
We would also like to avoid unnecessary rewrites.
Consider the following term from the SKI system defined in figure \ref{fig:SKI}
$Ap(Ap(K, I), Ap(Ap(S,Ap(I,I)),Ap(S,Ap(I,I))))$.
It would be pointless to reduce $Ap(Ap(S,Ap(I,I)),Ap(S,Ap(I,I))))$ since $Ap(Ap(K,I,z)$ rewrites to $I$
no matter what $z$ is.
In this particular case, since $Ap(Ap(S,Ap(I,I)),Ap(S,Ap(I,I))))$ reduces to itself,
we have turned a potentially non-terminating reduction to a terminating one.

A \emph{Rewriting Strategy}\index{Rewrite Strategy} $\mathcal{S} : T(\Sigma, V) \to Pos\times R$ 
is a function that takes a term, and returns a position to rewrite, and a rule to rewrite with
\cite{termRewriting}.
Furthermore we require that if $(p,l \to r) = \mathcal{S}(t)$, then $t\vert_p$ is a redex that matches $l$.
The idea is that $S(t)$ should give us a position to rewrite, and the rule to rewrite with.

For orthogonal rewriting systems, 
there are two common rewriting strategies that do not run in 
parallel,\footnote{we avoid discussing parallel strategies,
                   because our work is focused on sequential execution of Curry programs.
                   That has been a lot of work done on parallel execution of Curry programs 
                   elsewhere \cite{concurrentCurry,abstractConcurrentCurry}.}
innermost and outermost rewriting\cite{termRewriting,rewriteStrategies}.
Innermost rewriting corresponds to eager evaluation in functional programming.
We rewrite the term that matches a rule that is the furthest down the tree.
Outermost rewriting correspond roughly to lazy evaluation.
We rewrite the highest possible term that matches a rewrite rule.

A strategy is \emph{normalizing}\index{normalizing} if, when a term $t$ has a normal form, 
then the strategy will eventually find it.
While outermost rewriting isn't normalizing in general,
it is for left-normal systems, 
which is a large subclass of orthogonal rewrite systems \cite{termRewriting}.
This matches the intuition from programming languages.
Lazy languages can perform computations that would run forever with an eager language.

While both of these strategies are well understood, we can actually make a stronger guarantee.
We want to reduce only the redexes that are necessary to find a normal form.
To formalize this we need to understand what can happen when we rewrite a term.
Specifically for a redex $s$ that is a subterm of $t$, how can $s$ change as we rewrite $t$.
If we're rewriting at position $p$ with rule $l \to r$, then there are 3 cases to consider.\\
Case 1: we are rewriting $s$ itself.  That is, $s$ is the subterm $t\vert_p$.
Then $s$ disappears entirely.\\
Case 2: $s$ is either above $t\vert_p$, or they are completely disjoint.
In this case $s$ doesn't change.\\
Case 3: $s$ is a subterm of $t\vert_p$.
In this case $s$ may be duplicated, or erased, moved, or left unchanged.
It depends on whether the rule is duplicating, erasing, or right linear.\\
These cases can be seen in figure \ref{fig:descendant}
We can formalize this with the notion of descendants with the following definition from 
\cite{AdvancedTRS}[Def. 4.3.6].


\begin{figure}
  \begin{subfigure}{.6\textwidth}
    \begin{tabular}{>{\centering\arraybackslash}m{2cm}>{\centering\arraybackslash}m{1cm}>{\centering\arraybackslash}m{2cm}} 
        \Tree[.$S$ [.\fbox{$+$} [.$S$ $0$ ] [.$+$ [.$S$ $0$ ] $0$ ] ] ] &
        {\huge $\Rightarrow$} &
        \Tree[.$S$ [.\fbox{$+$} [.$S$ $0$ ] [.$S$ [.$+$ $0$ $0$ ] ] ] ] \\
    \end{tabular}
    \caption{rewrite $R_1$ at position $[0,1]$ doesn't affect $t\vert_{[0]}$.}
  \end{subfigure}
  \begin{subfigure}{.4\textwidth}
    \begin{tabular}{>{\centering\arraybackslash}m{1.5cm}>{\centering\arraybackslash}m{1cm}>{\centering\arraybackslash}m{1.5cm}} 
        \Tree[.$*$ [.\fbox{.$+$} $0$ $0$ ] [.$*$ $0$ $0$ ] ] &
        {\huge $\Rightarrow$} &
        \Tree[.$*$ [.\fbox{.$+$} $0$ $0$ ] $0$ ] \\
    \end{tabular}
    \caption{rewrite $R_4$ at position $[1]$ doesn't affect $t\vert_{[0]}$.}
  \end{subfigure}
  \begin{subfigure}{.6\textwidth}
    \begin{tabular}{>{\centering\arraybackslash}m{2cm}>{\centering\arraybackslash}m{1cm}>{\centering\arraybackslash}m{2cm}} 
        \Tree[.$S$ [.$*$ [.$S$ $0$ ] [.\fbox{$+$} $0$ $0$ ] ] ] &
        {\huge $\Rightarrow$} &
        \Tree[.$S$ [.$+$ [.\fbox{$+$} $0$ $0$ ] [.$*$ $0$ [.\fbox{$+$} $0$ $0$ ] ] ] ] \\
    \end{tabular}
    \caption{rewrite $R_3$ at position $[0]$ duplicates $t\vert_{[0,1]}$.}
  \end{subfigure}
  \begin{subfigure}{.4\textwidth}
    \begin{tabular}{>{\centering\arraybackslash}m{1.5cm}>{\centering\arraybackslash}m{1cm}>{\centering\arraybackslash}m{1cm}} 
        \Tree[.$S$ [.$-$ $0$ [.\fbox{$+$} $0$ $0$ ] ] ] &
        {\huge $\Rightarrow$} &
        \Tree[.$S$ $0$ ] \\
    \end{tabular}
    \caption{rewrite $R_5$ at position $[0]$ erases term at $t\vert_{[0,1]}$.}
  \end{subfigure}
  \begin{subfigure}{.5\textwidth}
    \begin{tabular}{>{\centering\arraybackslash}m{2cm}>{\centering\arraybackslash}m{1cm}>{\centering\arraybackslash}m{1cm}} 
        \Tree[.$S$ [.$+$ [$S$ $0$ ] .\fbox{$0$} ] ] &
        {\huge $\Rightarrow$} &
        \Tree[.$S$ [.$S$ [.$+$ $0$ .\fbox{$0$} ] ] ] \\
    \end{tabular}
    \caption{rewrite $R_2$ at position $[0]$ moves $t\vert_{[0,1]}$ to position $[0,0,1]$.}
  \end{subfigure}
    \caption{four cases for the descendants for a term after a single rewrite.
             The boxed term is either left alone, duplicated, or erased, or moved.
             The rules are defined in figure \ref{fig:peano}}
    \label{fig:descendant}
\end{figure}


\theoremstyle{definition}
\begin{definition}{Descendant\index{descendant}:}
    Let $s = t\vert_v$, and $A = l \rightarrow_{p,\sigma,R} r$ be a rewrite step in $t$.
    The set of descendants of $s$ is given by $Des(s,A)$\\
    $$
    Des(s,A) = 
    \begin{cases}
        \emptyset & \text{if}\ v = u \\
        \{s\}     & \text{if}\ p \not \leq v \\
        \{t\vert_{u\cdot w\cdot q}\ :\ r\vert_w = x \}
                  & \text{if}\ p = u\cdot v \cdot q\ \text{and}\ t\vert_v = x\ \text{and}\ x\in V
    \end{cases}
    $$\\
    This definition extends to derivation $t \to_{A_1} t_1 \to_{A_2} t_2 \to_{A_2} \ldots \to_{A_n}, t_{n+1}$.
    $Des(s,A_1,A_2\ldots A_n) = \bigcup_{s' \in Des(s,A_1)} Des(s', A_2,\ldots A_n)$.
\end{definition}

The first part of the definition is formalizing the notion of descendant.
The second part is extending it to a rewrite derivation.
The extension is straightforward. Calculate the descendants for the first rewrite,
then for each descendant, calculate the descendants for the rest of the rewrites.
With the idea of a descendant, we can talk about what happens to a term in the future.
This is necessary to describing our rewriting strategy.
Now we can formally define what it means for a redex to be necessary for computing
a normal form.

\theoremstyle{definition}
\begin{definition}{Needed\index{needed}:}
    A redex $s$ that is a subterm of $t$ is \emph{needed} in $t$ if,
    for every derivation of $t$ to a normal form,
    a descendant of $s$ is the root of a rewrite.
\end{definition}

This definition is good because it's immediately clear that, if we're going
to rewrite a term to normal form, we need to rewrite all of the needed redexes.
In fact, we can guarantee more than that with the following theorem \cite{condKaplan}.

\begin{theorem}
    For an orthogonal TRS, any term that is not in normal form contains a needed redex.
    Furthermore, a rewrite strategy that rewrites only needed redexes is normalizing.
\end{theorem}

This is a very powerful result.
We can compute normal forms by rewriting needed redexes.
This is also, in some sense, the best possible strategy.
Every needed redex needs to be rewritten.
Now we just need to make sure our strategy only rewrites needed redexes.
There's only one problem with this plan.
Determining if a redex is needed is undecidable in general.
However, with some restrictions, there are rewrite systems where this is possible
\cite{termRewriting}[def. 3.3.7].\footnote{The original definition used the notion of a
                                           context in normal form.}

\theoremstyle{definition}
\begin{definition}{Sequential\index{sequential}}
    A rewrite system is \emph{sequential} if, given a term $t$ with $n$ variables $v_1,v_2\ldots v_n$,
    such that $t$ is in normal form,
    then there is an $i$ such that for every substitution $\sigma$ from variables to redexes,
    $\sigma(v_i)$ is needed in $\sigma(t)$.
\end{definition}

If we have a sequential rewrite system,
then this leads to an efficient algorithm for reducing terms to normal form.
Unfortunately, sequential is also an undecidable property.
There is still hope.
As we'll see in the next section,
with certain restrictions we can ensure the our rewrite systems are sequential.
Actually we can make a stronger guarantee.
The rewrite system will admit a narrowing strategy that only narrows needed redexes.

\section{Narrowing Strategies}

Similar to rewriting strategies, narrowing strategies attempt to compute a normal form
for a term using narrowing steps.
However, a narrowing strategy must also compute a substitution for that term.
There have been many narrowing strategies including basic \cite{basicNarrowing},
innermost \cite{slog}, outermost \cite{outerNarrowing},
standard \cite{standardNarrowing}, and lazy \cite{lazyNarrowing}.
Unfortunately, each of these strategies are too restrictive on the rewrite systems they allow.


\begin{figure}[h]
  \begin{subfigure}{.45\textwidth}
      $(x + x) + x = 0$
    \caption{This fails for eager narrowing, because evaluating $x + x$ can produce infinitely many answers.
             However This is fine for lazy narrowing. We will get
             $(0 + 0) + 0 = 0, \{x = 0\}$
             or $S(S(y + S(y)) + S(y)) = 0 \{x = S(y)\}$
             and the second one will fail.}
  \end{subfigure}
  \hspace{.05\textwidth}
  \begin{subfigure}{.45\textwidth}
      $x \le y + y$
    \caption{With a lazy narrowing strategy we may end up computing more than is necessary.
             If $x$ is instantiated to $0$, then we don't need to evaluate $y + y$ at all.}
  \end{subfigure}
    \caption{examples of where eager and lazy narrowing can fail using the rewrite system
             if figure \ref{fig:peano}.}
    \label{NarrowingComp}
\end{figure}


Fortunately there exists a narrowing strategy that's defined on a large class of rewrite systems,
only narrows needed expressions, and is sound and complete.
However this strategy requires a new construct called a definitional tree.

The idea is that since we are working with constructor rewrite systems,
we can group all of the rules defined for the same function symbol together.
We'll put them together in a tree structure defined below, and 
then we can compute a narrowing step by traversing the tree for the defined symbol.


\theoremstyle{definition}
\begin{definition}
    $T$ is a \emph{partial definitional tree} if $T$ is one of the following.\\
    $T = exempt(\pi)$ where $\pi$ is a pattern.\\
    $T = leaf(\pi \to r)$ where $\pi$ is a pattern, and $\pi \to r$ is a rewrite rule.\\
    $T = branch(\pi, o, T_1, \ldots T_k)$, where $\pi$ is a pattern,
    $o$ is a path,
    $\pi\vert_o$ is a variable,
    $c_1,\ldots c_k$ are constructors,
    and $T_i$ is a pdt with pattern $\pi[c_i(X_1,\ldots X_n)]_o$ where $n$ is the arity of $c_i$,
    and $X_1,\ldots X_n$ are fresh variables.\\
    $\ $\\
    Given a constructor rewrite system $R$,
    $T$ is a \emph{definitional tree}\index{definitional tree} for function symbol $f$ if
    $T$ is a partial definitional tree, and each leaf in $T$
    corresponds to exactly one rule rooted by $f$.
    A rewrite system is \emph{inductively sequential}\index{inductively sequential}
    if there exists a definitional tree for every function symbol.
\end{definition}

The name ``inductively sequential'' is justified because there 
is a narrowing strategy that only reduces needed redexes for any of these systems.
We show an example to clarify the definition.
In figure \ref{fig:defTree} we show the definitional tree for the $+, \le,$ and $=$ rules.
The idea is that, at each branch, we decide which variable to inspect.
Then we decide what child to follow based on the constructor of that branch.
This gives us a simple algorithm for outermost rewriting with definitional trees.
However, we need to extend this to narrowing.


\begin{figure}
  \begin{subfigure}{.4\textwidth}
    \begin{tabular}{lcl}
        $0    + y$      & $\to$ & $y$       \\
        $S(x) + y$      & $\to$ & $S(x+y)$  \\
  \end{tabular}
  \end{subfigure}
  \begin{subfigure}{.6\textwidth}
  \Tree[.$x+y$ [.$0+y$ $y$ ]
               [.$S(x)+y$ $S(x+y)$ ] ]
  \end{subfigure} \\
  \begin{subfigure}{.4\textwidth}
  \begin{tabular}{lcl}
        $0    \le y$    & $\to$ & $True$    \\
        $S(x) \le 0$    & $\to$ & $False$    \\
        $S(x) \le S(y)$ & $\to$ & $x < y$   \\
  \end{tabular}
  \end{subfigure}
  \begin{subfigure}{.6\textwidth}
  \Tree[.$x\le y$ [.$0\le y$ $True$ ] 
                   [.$S(x)\le y$ [.$S(x)\le 0$ $False$ ]
                                 [.$S(x)\le S(y)$ $x\le y$ ] ] ] 
  \end{subfigure} \\
  \begin{subfigure}{.4\textwidth}
  \begin{tabular}{lcl}
        $0    = 0   $   & $\to$ & $True$  \\
        $S(x) = 0   $   & $\to$ & $False$ \\
        $0    = S(y)$   & $\to$ & $False$ \\
        $S(x) = S(y)$   & $\to$ & $x = y$ \\
  \end{tabular}
  \end{subfigure}
  \begin{subfigure}{.6\textwidth}
  \Tree[.$x=y$ [.$0=y$ [.$0=0$ $True$ ]
                       [.$0=S(y)$ $False$ ] ]
               [.$S(x)=y$ [.$S(x)=0$ $False$ ]
                          [.$S(x)=S(y)$ $x=y$ ] ] ]
  \end{subfigure} 
  \caption{Definitional trees for $ + $, $ \le $, and $ = $.}
  \label{fig:defTree}
\end{figure}


In order to extend the strategy from rewriting to narrowing we need
to figure out how to compute a substitution,
and we need to define what it means for a narrowing step to be needed.
The earliest definition involved finding a most general unifier for the substitution.
This has some nice properties.
There is a well known algorithm for computing mgu's, which are unique up to renaming of variables.
However, this turned out to be the wrong approach.
Computing mgu's is too restrictive.
Consider the step $x \le y + z \rightsquigarrow_{2\cdot \epsilon,R_1,\{y \mapsto 0\}} x \le z$.  
Without further substitutions $x \le z$ is a normal form, and $\{y \mapsto 0\}$ is an mgu.
Therefore this should be a needed step.
But if we were to instead narrow $x$, 
we have $x \le y + z \rightsquigarrow_{\epsilon,R_8,\{x \mapsto 0\}} True$.
This step never needs to compute a substitution for $y$.
Therefore we need a definition that isn't dependent on substitutions that might be computed later.


\theoremstyle{definition}
\begin{definition}
    A narrowing step $t \rightsquigarrow_{p, R, \sigma} s$ is needed, 
    iff, for every $\eta \ge \sigma$,
    there is a needed redex at $p$ in $\eta(t)$.
\end{definition}

Here we don't require that $\sigma$ be an mgu, but, for any less general substitution,
it must be the case that we're rewriting a needed redex.
So our example, $x \le y + z \rightsquigarrow_{2\dot \epsilon,R_1,\{y \mapsto 0\}} x \le z$,
isn't a needed narrowing step because $x \le y + z \rightsquigarrow_{2\dot \epsilon,R_1,\{x \mapsto 0, y \mapsto 0\}} 0 \le z$,
Isn't a needed rewriting step.

Unfortunately, this definition raises a new problem.
Since we are no longer using mgu's for our unifiers, we may not have a unique step for an expression.
For example, $x < y \rightsquigarrow_{\epsilon, R_8, \{x\mapsto 0\}} True $, and
$x < y \rightsquigarrow_{\epsilon, R_9, \{x\rightarrow S(u), t \mapsto S(v)\}} u \le v $
are both possible needed narrowing steps.

Therefore we define a \emph{Narrowing Strategy}\index{narrowing strategy} 
$\mathcal{S}$ as a function from terms
to a set of triples of a position, rule, and substitution, such that if $(p, R, \sigma) \in \mathcal{S}(t)$,
then $\sigma(t)\vert_p$ is a redex for rule $R$.

At this point we have everything we need to define a needed narrowing strategy.

\theoremstyle{definition}
\begin{definition}
    Let $t$ be a term rooted by function symbol $f$,
    $T$ be the definitional tree for $f$,
    and ``$?$'' be a distinguished symbol to denote that no rule could be found.
    $$\lambda(t,T) \in  
    \begin{cases}
        (\epsilon, R, mgu(t, \pi))   & \text{if}\ T = rule(\pi, R) \\
        (\epsilon, ?, mgu(t, \pi))   & \text{if}\ T = exempt(\pi) \\
        (p, R, \sigma)               & \text{if}\ T = branch(\pi, o, T_1, \ldots T_n) \\
                                     & t\ \text{unifies with}\ T_i \\
                                     & (p, R, \sigma) \in \lambda(t, T_i) \\
        (o:p, R, \sigma \circ \tau)  & \text{if}\ T = branch(\pi, o, T_1, \ldots T_n) \\
                                     & t\ \text{does not unifies with any}\ T_i \\
                                     & \tau = mgu(t, \pi) \\
                                     & T'\ \text{is the definitional tree for}\ t\vert_o \\
                                     & (p, R, \sigma) \in \lambda(t\vert_o, T') \\
    \end{cases}
    $$
\end{definition}

The function $\lambda$ is a narrowing strategy.
It takes an expression rooted by $f$, and the definition tree for $f$,
and it returns a position, rule and substitution for a narrowing step.
If we reach a rule node, then we can just rewrite;
if we reach an exempt node, then there is no possible rewrite;
if we reach a branch node, then we match a constructor;
but if the subterm we're looking at isn't a constructor, then we need to narrow that subterm first.


\begin{theorem}
    $\lambda$ is a needed narrowing strategy.
    Furthermore, $\lambda$ is sound and complete.
\end{theorem}

It should be noted that while $\lambda$ is complete with respect to finding substitutions
and selecting rewrite rules \cite{Needed},
this says nothing about the underlying completeness of the rewrite system we're narrowing.
We may still have non-terminating derivations.

This needed narrowing strategy is important in developing the evaluation strategy for Curry programs.
In fact, one of the early stages of a Curry compiler is to construct definitional trees
for each function defined.
However, if we were to implement our compiler using terms, it would be needlessly inefficient.
We solve this problem with graph rewriting.

\section{Graph Rewriting}
As mentioned above term rewriting is too inefficient to implement Curry.
Consider the rule $double(x) = x + x$.
Term rewriting requires this rule to make a copy of $x$, no matter how large it is,
whereas we can share the variable if we use a graph.
In programming languages, this distinction moves the evaluation strategy from
``call by name'' to ``call by need'', and it is what we mean when we refer to ``lazy evaluation''.


As a brief review of relevant graph theory:
A \emph{graph}\index{graph} $G = (V,E)$ is a pair of vertices $V$ and edges $E \subseteq V \times V$.
We will only deal with directed graphs, so the order of the edge matters.
A \emph{rooted graph}\index{rooted graph} is a graph with a specific vertex $r$ designated as the \emph{root}\index{root}.
The \emph{neighborhood}\index{neighborhood} of $v$, written $N(v)$ is the set of vertices adjacent to $v$.
That is, $N(v) = \{u\ \vert\ (v,u) \in E\}$.
A \emph{path}\index{path} $p$ from vertex $u$ to vertex $v$ is a sequence 
$u = p_1, p_2 \ldots p_n = v$ where $(p_i,p_{i+1}) \in E$.
A rooted graph is \emph{connected}\index{connected} 
if there is a path from the root to every other vertex in the graph.
A graph is \emph{strongly connected}\index{strongly connected} if, 
for each pair of vertices $(u,v)$, there is a path from $u$ to $v$
and a path form $v$ to $u$.
A path $p$ is a cycle
\footnote{Some authors will use walk and tour and
          reserve path and cycle for the cases where there are no repeated vertices.
          This distinction isn't relevant for our work.}
if its endpoints are the same.
A graph is acyclic if it contains no cycles.
Such graphs are referred to as Directed Acyclic Graphs, or DAG's.
A graph $H$ is a \emph{subgraph}\index{subgraph} of $G$, $H \subseteq G$ if, and only if, $V_H \subseteq V_G$
and $E_H \subseteq E_G$.
A strongly connected component $S$ of $G$ is a subgraph that is strongly connected.
We will use the well-known facts that strongly connected components partition a graph.
The component graph, which is obtained by shrinking the strongly connected components 
to a single vertex, is a DAG.
To avoid confusion with variables, we will refer to vertices of graphs as nodes.


We define term graphs in a similar way to terms.
Let $\Sigma = C \uplus F$ be an alphabet of constructor and function names respectively,
and $V$ be a countably infinite set of variables.
A \emph{term graph}\index{term graph} is a rooted graph $G$ with nodes in
$N$ where each node $n$ has a label in $\Sigma \cup V$.
We'll write $L(n)$ to refer to the label of a node.
If $(n, s) \in E$ is an edge, then $s$ is a successor of $n$.
In most applications the order of the outgoing edges doesn't matter, 
however it is very important in term graphs.
So, we will refer to the first successor, second successor and so on.
We denote this the same way we did with terms $n_i$ is the $i$th successor of $n$.
The arity of a node is the number of successors.
Finally, no two nodes can be labeled by the same variable.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% EXAMPLES (\label{termGraphs}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}
\begin{enumerate}
    \item $
          \begin{tikzcd}
              & +_1 \ar[ld] \ar[rd] & \\
              /_2 \ar[rd, bend right=50] \ar[rd] & & /_4 \ar[ld] \ar[ld, bend left=50]\\
              & x_3 & \\
          \end{tikzcd}
          $
    \item $
          \begin{tikzcd}
              double_1 \ar[d] \\
              x_2
          \end{tikzcd} \ \ \ \Rightarrow \ \ \ 
          \begin{tikzcd}
              +_3 \ar[d, bend right=50] \ar[d, bend left=50] \\
              x_2        
          \end{tikzcd}
          $
    \item $
          \begin{tikzcd}
              & +_1 \ar[ld] \ar[loop, out = -50, in = 50, distance = 5em] \\
            4_2 & \\
          \end{tikzcd}
          $
    \item $
          \begin{tikzcd}
              +_1 \ar[rd] \ar[dd] &             \\
                                  & S_4 \ar[ld] \\
              S_2 \ar[d]          &             \\
              0_3                 &
          \end{tikzcd}
          \ \ \ \ \Rightarrow\ \ \ \ 
          \begin{tikzcd}
              S_5 \ar[d]                          &             \\
              +_6 \ar[ddd, bend right=20] \ar[rd] &             \\
                                                  & S_4 \ar[ld] \\
              S_2 \ar[d]                          &             \\
              0_3                                 &
          \end{tikzcd}
          $
\end{enumerate}
\caption{1. $1:+(2:/(3:x,3), 4:/(3,3))$,\\
         2. $1:double(2:x) \Rightarrow 3:+(2:x, 2)$\\
         3. $1:+(2:4, 1)$\\
         4. $1:+(2:S(3:0), 4:S(2)) \Rightarrow 5:S(6:+(3:0), 4:S(2:S(3)))$}
\label{fig:termGraph}
\end{figure}



While the nodes in a term graph are abstract, 
in reality, they connected using pointers in the implementation.
It can be helpful to keep this in mind. 
As we define more operations on our term graphs, 
there exists a natural implementation using pointers.

We will often use a linear notation to represent graphs.
This has two advantages.
The first is that it is exact.
There are many different ways to draw the same graph,
but there is only one way to write it out a linear representation\cite{graphRewriting}
The second is that this representation corresponds closely to the representation in a computer.
The notation these graphs is given by the following grammar,
where the set of nodes and the set of labels are disjoint.
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{10}{@{}>{\hspre}c<{\hspost}@{}}%
\column{10E}{@{}l@{}}%
\column{14}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Conid{Graph}{}\<[10]%
\>[10]{}\to {}\<[10E]%
\>[14]{}\Conid{Node}{}\<[E]%
\\
\>[3]{}\Conid{Node}{}\<[10]%
\>[10]{}\to {}\<[10E]%
\>[14]{}\Varid{n}\mathbin{:}\Conid{L}\;(\Conid{Node},\ldots \Conid{Node}){}\<[E]%
\\
\>[10]{}\mid {}\<[10E]%
\>[14]{}\Varid{n}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
We start with the root node, and for each node in the graph, If we haven't encountered
it yet, then we write down the node, the label, and the list of successors.
If we have seen it, then we just write down the node.
If a node doesn't have any successors, then we'll omit the parentheses entirely,
and just write down the label.

A few examples are shown in figure \ref{fig:termGraph}.
Example 1 shows an expression where a single variable is shared several times.
Example 2 shows how a rewrite can introduce sharing.
Example 3 shows an example of an expression with a loop.
These examples would require an infinitely large term, so they cannot be represented
in term rewrite systems.
Example 4 shows how reduction changes from terms to graphs.
In a term rewrite system, if a node is in the pattern of a redex, then it can safely be discarded.
However, in graph rewriting this is no longer true.

\theoremstyle{definition}
\begin{definition}
Let $p$ be a node in $G$, then the \emph{subgraph} $G\vert_p$ is a new graph rooted by $p$.
The nodes are restricted to only those reachable from $p$.
\end{definition}

Notice that we don't define subgraphs by paths like we did with subterms.
This is because there may be more than one path to the node $p$.
It may be the case that $G\vert_p$ and $G$ have the same nodes, such as if the root of $G$ is in a loop.

\theoremstyle{definition}
\begin{definition}
A \emph{replacement}\index{replacement} of node $p$ by graph $u$ in $g$ 
(written $g[p \to u]$) is given by the following procedure.
For each edge $(n,p) \in E_g$ replace it with an edge $(n, root_u)$.
Add all other edges from $E_g$ and $E_u$.
If $p$ is the root of $g$, then $root_u$ is now the root.
\end{definition}

It should be noted that when implementing Curry, we don't actually change
any of the pointers when doing a replacement.
Traversing the graph to find all of the pointers to $p$ would be horribly inefficient.
Instead we change the contents of $p$ to be the contents of $u$.

We can define matching in a similar way to terms, but we need to be more careful.
When matching terms the structure of the term needed to be the same,
however when matching graphs the structure can be wildly different.
Consider the following graph.

$$
\begin{tikzcd}
    and \ar[d, bend right=50] \ar[d, bend left=50] \\
    True
\end{tikzcd}
$$

Here the graph should match the rule $and(True,True) \rightarrow True$.
But $and(True,True)$ is a term, so they no longer have the same structure.
Therefore we must be more careful about what we mean by matching.
We define matching inductively on the structure of the term.


\theoremstyle{definition}
\begin{definition}
A graph $K$ \emph{matches} a term $T$ if, and only if,
$T$ is a variable,
or $T = l(T_1,T_2\ldots T_n)$, the root of $K$ is labeled with $l$,
and for each $i \in \{1\ldots n\}$, $K_i$ matches $T_i$.
\end{definition}

Now, it may be the case that we have multiple successors pointing to the same node
when checking if a graph matches a pattern, but this is OK.
As long as the node matches each sub pattern, then the graph will match.
We extend substitutions to graphs in the obvious way.
A substitution $\sigma$ maps variables to Nodes.
In this definition for matching $\sigma$ may have multiple variables map to the same node,
but this doesn't cause a problem.

\theoremstyle{definition}
\begin{definition}
A \emph{rewrite rule}\index{rewrite rule} is a pair $L \to R$ where $L$ is a 
term, and $R$ is a term graph.
A graph $G$ matches the rule if there exists subgraph $K$
where $K$ matches $L$ with matcher $\sigma$.
A \emph{rewrite} is a triple $(K, L \to R, \sigma)$,
and we apply the rewrite with $G[K \to \sigma(R)]$.
\end{definition}


From here we can define narrowing similarly to how we did for terms.
We do not give the definitions here, because they are similar to the definitions
in term rewriting.
At this point we have discussed the difference between graphs and terms,
and how a replacement can be done in a graph.
For our purposes in this compiler, that is all that is needed,
but the definition of narrowing and properties about inductively sequential GRS's
can be found in Echaned and Janodet \cite{graphRewriting}.
They also show that the needed narrowing strategy is still valid for graph rewriting systems.

\section{Previous Work}
This was not meant to be an exhaustive examination of rewriting, but rather an introduction to the concepts,
since they form this theoretical basis of the Curry language.
Most work on term rewriting up through 1990 has been summarized by Klop \cite{termRewriting},
and Baader and Nipkow \cite{termAndAllThat}.
The notation and ideas in this section largely come from
Ohlebusch \cite{AdvancedTRS}, although they are very similar to the previous two summaries.
The foundations of term rewriting were laid by Church, Rosser, Curry, Feys, Newman. 
\cite{churchRosser, CombLogic, Newman}
Most of the work on rewriting has centered on confluence and termination. \cite{termRewriting}
Narrowing has been developed by Slagle \cite{narrowing}.
Sequential strategies were developed by Huet and Levy \cite{StrongSequential},
who gave a decidable criteria for a subset of sequential systems.
This led to the work of Antoy on inductively sequential systems \cite{DefinitionalTrees}.
The needed narrowing strategy came from Hanus, Antoy, and Echahed \cite{Needed}.
Graph rewriting is a bit more disconnected.  
Currently there isn't a consensus on how to represent graphs mathematically.
We went with the presentation in \cite{graphRewriting}, 
but there are also alternatives in \cite{termRewriting, termAndAllThat, AdvancedTRS}

Here we saw how we can rewrite terms and graphs.
We'll use this idea in the next chapter to rewrite entire programs.
This will become the semantics for our language.
Now that we have some tools, It's time to find out how to make Curry!


\chapter{The Curry Language} \label{ch:The Curry Language}


The Curry language grew out of the efforts to combine the functional and 
logic programming paradigms \cite{multiparadigm}.
Originally there were two approaches to combine these paradigms,
adding functional features to logic languages,
and adding logic features to functional languages.
The latter approach was very popular and spawned several new languages
including Ciao-Prolog \cite{ciao}, Mercury \cite{mercury}, HAL \cite{hal}, and Oz \cite{oz}.
The extension of functional languages lead to fewer new languages,
but it did lead to libraries like the logict monad in Haskell \cite{logict}.

Ultimately the solution came from the work on automated theorem proving \cite{narrowing}.
Instead of adding features from one paradigm to another,
it was discovered that narrowing was a good abstraction for combining 
the features from both paradigms.
This spawned the Curry \cite{IntegrationFunLog} and Toy \cite{toy} languages.

In this chapter we explore the Curry language syntax and semintics.
We give example programs to show how programming in Curry differs from Prolog and Haskell.
Then we discuss the choices we made in our implementation compared to previous implementations.
Finally we give an example of generated code to demonstrate how we compile Curry programs.

\section{The Curry Language} \label{The Curry Language}

In order to write a compiler for Curry, we need to understand how Curry works.
We'll start by looking at some examples of Curry programs.
We'll see how Curry programs differ from Haskell and Prolog programs.
Then we'll move on to defining a small interpreter for Curry.
Finally we'll use this interpreter to define equivalent C code.

Curry combines the two most popular paradigms of declarative programming:
Functional languages and logic languages.
Curry programs are composed of defining equations like Haskell or ML,
but we are allowed to have non-deterministic expressions and free variables like Prolog.
This will not be an introduction to modern declarative programming languages.
The reader is expected to be familiar with functional languages such as Haskell or ML,
and logic languages such as Prolog.
For an introduction to programming in Curry see \cite{CurryTutorial}.
For an exhaustive explanation of the syntax and semantics of Curry see \cite{CurryReport}.

To demonstrate the features of Curry, we will examine a small Haskell program to permute a list.
Then we will simplify the program by adding features of Curry.
This will demonstrate the features of Curry that we need to handle in the compiler,
and also give a good basis for how we can write the compiler.

First, let's consider an example of a permutation function.
This is not the only way to permute a list in Haskell,
and you could easily argue that it's not the most elegant way,
but I chose it for two reasons.
There is no syntactic sugar,
and the only two library functions are \ensuremath{\Varid{concat}} and \ensuremath{\Varid{map}}, both very common functions.
and the algorithm for permuting a list is similar to the algorithm we will use in Curry.
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{5}{@{}>{\hspre}l<{\hspost}@{}}%
\column{7}{@{}>{\hspre}l<{\hspost}@{}}%
\column{17}{@{}>{\hspre}l<{\hspost}@{}}%
\column{24}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{perms}{}\<[17]%
\>[17]{}\mathbin{::}[\mskip1.5mu \Varid{a}\mskip1.5mu]\to [\mskip1.5mu [\mskip1.5mu \Varid{a}\mskip1.5mu]\mskip1.5mu]{}\<[E]%
\\
\>[3]{}\Varid{perms}\;[\mskip1.5mu \mskip1.5mu]{}\<[17]%
\>[17]{}\mathrel{=}[\mskip1.5mu [\mskip1.5mu \mskip1.5mu]\mskip1.5mu]{}\<[E]%
\\
\>[3]{}\Varid{perms}\;(\Varid{x}\mathbin{:}\Varid{xs}){}\<[17]%
\>[17]{}\mathrel{=}\Varid{concat}\;(\Varid{map}\;(\Varid{insert}\;\Varid{x})\;(\Varid{perms}\;\Varid{xs})){}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mathbf{where}{}\<[E]%
\\
\>[5]{}\hsindent{2}{}\<[7]%
\>[7]{}\Varid{insert}\;\Varid{x}\;[\mskip1.5mu \mskip1.5mu]{}\<[24]%
\>[24]{}\mathrel{=}[\mskip1.5mu [\mskip1.5mu \Varid{x}\mskip1.5mu]\mskip1.5mu]{}\<[E]%
\\
\>[5]{}\hsindent{2}{}\<[7]%
\>[7]{}\Varid{insert}\;\Varid{x}\;(\Varid{y}\mathbin{:}\Varid{ys}){}\<[24]%
\>[24]{}\mathrel{=}(\Varid{x}\mathbin{:}\Varid{y}\mathbin{:}\Varid{ys})\mathbin{:}\Varid{map}\;(\Varid{y}\mathbin{:})\;(\Varid{insert}\;\Varid{x}\;\Varid{ys}){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
The algorithm itself is broken into two parts.
The \ensuremath{\Varid{insert}} function will return a list of lists,
where \ensuremath{\Varid{x}} is inserted into \ensuremath{\Varid{ys}} at every possible position.
For example: \ensuremath{\Varid{insert}\;\mathrm{1}\;[\mskip1.5mu \mathrm{2},\mathrm{3}\mskip1.5mu]} returns \ensuremath{[\mskip1.5mu [\mskip1.5mu \mathrm{1},\mathrm{2},\mathrm{3}\mskip1.5mu],[\mskip1.5mu \mathrm{2},\mathrm{1},\mathrm{3}\mskip1.5mu],[\mskip1.5mu \mathrm{2},\mathrm{3},\mathrm{1}\mskip1.5mu]\mskip1.5mu]}.
The \ensuremath{\Varid{perms}} function splits the list into a head \ensuremath{\Varid{x}} and tail \ensuremath{\Varid{xs}}.
First, it computes all permutations of \ensuremath{\Varid{xs}}, then it will insert \ensuremath{\Varid{x}} into every possible position
of every permutation.

While this algorithm is not terribly complex, it's really more complex than it needs to be.
The problem is that we need to keep track of all of the permutations we generate.
This doesn't seem like a big problem here.
We just put each permutation in a list, and return the whole list of permutations.
However, now every part of the program has to deal with the entire list of results.
As our programs grow, we will need more data structures for this plumbing, and this problem will grow too.
This is not new.
Many languages have spent a lot of time trying to resolve this issue.
In fact, several of Haskell's most successful concepts,
such as monads, arrows, and lenses, are designed strictly to reduce this sort of plumbing.

We take a different approach in Curry.
Instead of generating every possible permutation, and searching for the right one,
we will non-deterministically generate a single permutation.
This seems like a trivial difference, but its really quite substantial.
We offload generating all of the possibilities onto the language itself.

We can simplify our code with the non-deterministic \textit{choice} operator \ensuremath{\mathbin{?}}.
Choice is defined by the rules:\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{x}\mathbin{?}\Varid{y}\mathrel{=}\Varid{x}{}\<[E]%
\\
\>[3]{}\Varid{x}\mathbin{?}\Varid{y}\mathrel{=}\Varid{y}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
Now our permutation example becomes a little easier.
We only generate a single permutation,
and when we insert \ensuremath{\Varid{x}} into \ensuremath{\Varid{ys}}, we only insert into a single arbitrary position.

\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{5}{@{}>{\hspre}l<{\hspost}@{}}%
\column{7}{@{}>{\hspre}l<{\hspost}@{}}%
\column{16}{@{}>{\hspre}l<{\hspost}@{}}%
\column{24}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{perm}{}\<[16]%
\>[16]{}\mathbin{::}[\mskip1.5mu \Varid{a}\mskip1.5mu]\to [\mskip1.5mu \Varid{a}\mskip1.5mu]{}\<[E]%
\\
\>[3]{}\Varid{perm}\;[\mskip1.5mu \mskip1.5mu]{}\<[16]%
\>[16]{}\mathrel{=}[\mskip1.5mu \mskip1.5mu]{}\<[E]%
\\
\>[3]{}\Varid{perm}\;(\Varid{x}\mathbin{:}\Varid{xs}){}\<[16]%
\>[16]{}\mathrel{=}\Varid{insert}\;\Varid{x}\;(\Varid{perm}\;\Varid{xs}){}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mathbf{where}{}\<[E]%
\\
\>[5]{}\hsindent{2}{}\<[7]%
\>[7]{}\Varid{insert}\;\Varid{x}\;[\mskip1.5mu \mskip1.5mu]{}\<[24]%
\>[24]{}\mathrel{=}[\mskip1.5mu \Varid{x}\mskip1.5mu]{}\<[E]%
\\
\>[5]{}\hsindent{2}{}\<[7]%
\>[7]{}\Varid{insert}\;\Varid{x}\;(\Varid{y}\mathbin{:}\Varid{ys}){}\<[24]%
\>[24]{}\mathrel{=}\Varid{x}\mathbin{:}\Varid{y}\mathbin{:}\Varid{ys}\mathbin{?}\Varid{y}\mathbin{:}\Varid{insert}\;\Varid{x}\;\Varid{ys}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
In many cases functions that return multiple results can lead to much simpler code.
Curry has another feature that's just as useful.
We can declare a \textit{free variable} in Curry.
This is a variable that hasn't been assigned a value.
We can then constrain the value of a variable later in the program.
In the following example \ensuremath{\Varid{begin}}, \ensuremath{\Varid{x}}, and \ensuremath{\Varid{end}} are all free variables,
but they're constrained by the guard so that \ensuremath{\Varid{begin}\plus [\mskip1.5mu \Varid{x}\mskip1.5mu]\plus \Varid{end}} is equal to \ensuremath{\Varid{xs}}.
Our algorithm then becomes: pick an arbitrary \ensuremath{\Varid{x}} in the list,
move it to the front, and permute the rest of the list.
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{4}{@{}>{\hspre}l<{\hspost}@{}}%
\column{12}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{perm}{}\<[12]%
\>[12]{}\mathbin{::}[\mskip1.5mu \Varid{a}\mskip1.5mu]\to [\mskip1.5mu \Varid{a}\mskip1.5mu]{}\<[E]%
\\
\>[3]{}\Varid{perm}\;[\mskip1.5mu \mskip1.5mu]{}\<[12]%
\>[12]{}\mathrel{=}[\mskip1.5mu \mskip1.5mu]{}\<[E]%
\\
\>[3]{}\Varid{perm}\;\Varid{xs}{}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mid \Varid{xs}\Varid{==}(\Varid{begin}\plus [\mskip1.5mu \Varid{x}\mskip1.5mu]\plus \Varid{end})\mathrel{=}\Varid{x}\mathbin{:}\Varid{perm}\;(\Varid{begin}\plus \Varid{end}){}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mathbf{where}\;\Varid{begin},\Varid{x},\Varid{end}\;\textbf{free} {}\<[E]%
\ColumnHook
\end{hscode}\resethooks
Look at that.
We've reduced the number of lines of code by 25\%.
In fact, this pattern of declaring free variables, and then immediately constraining them
is used so often in Curry that we have syntactic sugar for it.
A \textit{functional pattern} is any pattern that contains a function that is not at the
root.\footnote{
    This isn't completely correct.  While the above code would fully evaluate the list,
    a functional pattern is allowed to be more lazy.
    Since the elements don't need to be checked for equality, they can be left unevaluated.
}
We can use functional patterns to simplify our \ensuremath{\Varid{perm}} function even further.

\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{27}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{perm}{}\<[27]%
\>[27]{}\mathbin{::}[\mskip1.5mu \Varid{a}\mskip1.5mu]\to [\mskip1.5mu \Varid{a}\mskip1.5mu]{}\<[E]%
\\
\>[3]{}\Varid{perm}\;[\mskip1.5mu \mskip1.5mu]{}\<[27]%
\>[27]{}\mathrel{=}[\mskip1.5mu \mskip1.5mu]{}\<[E]%
\\
\>[3]{}\Varid{perm}\;(\Varid{begin}\plus [\mskip1.5mu \Varid{x}\mskip1.5mu]\plus \Varid{end}){}\<[27]%
\>[27]{}\mathrel{=}\Varid{x}\mathbin{:}\Varid{perm}\;(\Varid{begin}\plus \Varid{end}){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
Now the real work of our algorithm is a single line.
Even better, it's easy to read what this line means.
Decompose the list into \ensuremath{\Varid{begin}}, \ensuremath{\Varid{x}}, and \ensuremath{\Varid{end}}, then put \ensuremath{\Varid{x}} at the front, and permute \ensuremath{\Varid{begin}} and \ensuremath{\Varid{end}}.
This is almost exactly how we would describe the algorithm in English.

There is one more important feature of Curry.
We can let expressions fail.
In fact we've already seen it, but a more explicit example would be helpful.
We've shown how we can generate all permutations of a list by generating an arbitrary permutation,
and letting the language take care of the exhaustive search.
However, we usually don't need, or even want, every permutation.
So, how do we filter out the permutations we don't want?
The answer is surprisingly simple.  We just let expressions fail.
An expression fails if it cannot be reduced to a constructor form.
The common example here is \ensuremath{\Varid{head}\;[\mskip1.5mu \mskip1.5mu]}, but a more useful example might be sorting a list.
We can build a sorting algorithm by permuting a list, and only keeping the permutation that's sorted.
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{4}{@{}>{\hspre}l<{\hspost}@{}}%
\column{5}{@{}>{\hspre}l<{\hspost}@{}}%
\column{22}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{sort}\mathbin{::}(\Conid{Ord}\;\Varid{a})\Rightarrow [\mskip1.5mu \Varid{a}\mskip1.5mu]\to [\mskip1.5mu \Varid{a}\mskip1.5mu]{}\<[E]%
\\
\>[3]{}\Varid{sort}\;\Varid{xs}\mid \Varid{sorted}\;\Varid{ys}\mathrel{=}\Varid{ys}{}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mathbf{where}{}\<[E]%
\\
\>[4]{}\hsindent{1}{}\<[5]%
\>[5]{}\Varid{ys}\mathrel{=}\Varid{perm}\;\Varid{xs}{}\<[E]%
\\
\>[4]{}\hsindent{1}{}\<[5]%
\>[5]{}\Varid{sorted}\;[\mskip1.5mu \mskip1.5mu]{}\<[22]%
\>[22]{}\mathrel{=}\Conid{True}{}\<[E]%
\\
\>[4]{}\hsindent{1}{}\<[5]%
\>[5]{}\Varid{sorted}\;[\mskip1.5mu \Varid{x}\mskip1.5mu]{}\<[22]%
\>[22]{}\mathrel{=}\Conid{True}{}\<[E]%
\\
\>[4]{}\hsindent{1}{}\<[5]%
\>[5]{}\Varid{sorted}\;(\Varid{x}\mathbin{:}\Varid{y}\mathbin{:}\Varid{ys}){}\<[22]%
\>[22]{}\mathrel{=}\Varid{x}\leq \Varid{y}\mathrel{\wedge}\Varid{sorted}\;(\Varid{y}\mathbin{:}\Varid{ys}){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
In this example every permutation of \ensuremath{\Varid{xs}} that isn't sorted will fail in the guard.
Once an expression has failed, computation on it stops, and other alternatives are tried.
As we'll see later on, this ability to conditionally execute a function will 
become crucial when developing optimizations.

These are some of the useful programming constructs in Curry.
While they are convenient for programming, we need to understand how they work
if we are going to implement them in a compiler.

\section{Semantics} \label{Semantics}

As we've seen, the syntax of Curry is very similar to Haskell.
Functions are declared by defining equations, and new data types are declared as algebraic data types.
Function application is represented by juxtaposition,
so \ensuremath{\Varid{f}\;\Varid{x}} represents the function \ensuremath{\Varid{f}} applied to the variable \ensuremath{\Varid{x}}.
Curry also allows for declaring new infix operators.
In fact, Curry really only adds two new pieces of syntax to Haskell, \textbf{fcase} and \textbf{free}.
However, the main difference between Curry and Haskell is not immediately clear from the syntax.
Curry allows for overlapping rules and free variables.
Specifically Curry programs are represented as 
\emph{Limited Overlapping Inductively Sequential (LOIS)}
\index{Limited Overlapping Inductively Sequential} Rewrite systems.
These are is indicatively sequential systems with a single overlapping rule.
On the other hand, Haskell programs are transformed into non-overlapping systems.

To see the difference consider the usual definition of factorial.
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{fac}\mathbin{::}\Conid{Int}\to \Conid{Int}{}\<[E]%
\\
\>[3]{}\Varid{fac}\;\mathrm{0}\mathrel{=}\mathrm{1}{}\<[E]%
\\
\>[3]{}\Varid{fac}\;\Varid{n}\mathrel{=}\Varid{n}\mathbin{*}\Varid{fac}\;(\Varid{n}\mathbin{-}\mathrm{1}){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
This seems like an innocuous Haskell program, 
however It's non-terminating for every possible input for Curry.
The reason is that \ensuremath{\Varid{fac}\;\mathrm{0}} could match either rule.
In Haskell all defining equations are ordered sequentially,
which results in control flow similar to the following C implementation.
\begin{tabbing}\ttfamily
~int~fac\char40{}int~n\char41{}\\
\ttfamily ~\char123{}\\
\ttfamily ~~~~~if\char40{}n~\char61{}\char61{}~0\char41{}\\
\ttfamily ~~~~~\char123{}\\
\ttfamily ~~~~~~~~~return~1\char59{}\\
\ttfamily ~~~~~\char125{}\\
\ttfamily ~~~~~else\\
\ttfamily ~~~~~\char123{}\\
\ttfamily ~~~~~~~~~return~n~\char42{}~fac\char40{}n\char45{}1\char41{}\char59{}\\
\ttfamily ~~~~~\char125{}\\
\ttfamily ~\char125{}
\end{tabbing}
In fact, every rule with multiple defining equations follows this pattern.
In the following equations let \ensuremath{\Varid{p}_{\Varid{i}}} be a pattern and \ensuremath{\Conid{E}_{\Varid{i}}} be an expression.\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{10}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{f}\;\Varid{p}_{\mathrm{1}}{}\<[10]%
\>[10]{}\mathrel{=}\Conid{E}_{\mathrm{1}}{}\<[E]%
\\
\>[3]{}\Varid{f}\;\Varid{p}_{\mathrm{2}}{}\<[10]%
\>[10]{}\mathrel{=}\Conid{E}_{\mathrm{2}}{}\<[E]%
\\
\>[3]{}\ldots {}\<[E]%
\\
\>[3]{}\Varid{f}\;\Varid{p}_{\Varid{n}}{}\<[10]%
\>[10]{}\mathrel{=}\Conid{E}_{\Varid{n}}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
Then this is semantically equivalent to the following.
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{14}{@{}>{\hspre}l<{\hspost}@{}}%
\column{33}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{f}\;\Varid{p}_{\mathrm{1}}{}\<[33]%
\>[33]{}\mathrel{=}\Conid{E}_{\mathrm{1}}{}\<[E]%
\\
\>[3]{}\Varid{f}\;\Varid{not}\;\Varid{p}_{\mathrm{1}}{}\<[14]%
\>[14]{}\mathrel{\wedge}\Varid{p}_{\mathrm{2}}{}\<[33]%
\>[33]{}\mathrel{=}\Conid{E}_{\mathrm{2}}{}\<[E]%
\\
\>[3]{}\ldots {}\<[E]%
\\
\>[3]{}\Varid{f}\;\Varid{not}\;\Varid{p}_{\mathrm{1}}{}\<[14]%
\>[14]{}\mathrel{\wedge}\Varid{not}\;\Varid{p}_{\mathrm{2}}\mathrel{\wedge}\Varid{p}_{\Varid{n}}{}\<[33]%
\>[33]{}\mathrel{=}\Conid{E}_{\Varid{n}}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
Here \ensuremath{\Varid{not}\;\Varid{p}_{\Varid{i}}} means that we don't match pattern \ensuremath{\Varid{i}}.
This ensures that we will only ever reduce to a single expression.
Specifically we reduce to the first expression where we match the pattern.


Curry rules, on the other hand, are unordered.
If we could match multiple patterns, such as in the case of \ensuremath{\Varid{fac}}, 
then we non-deterministically return both expressions.
This means that \ensuremath{\Varid{fac}\;\mathrm{0}} reduces to both \ensuremath{\mathrm{1}} and \ensuremath{\Varid{fac}\;(\mathbin{-}\mathrm{1})}.
Exactly how Curry reduces an expression non-deterministically will be discussed throughout this dissertation,
but for now we can think in terms of sets.
If the expression \ensuremath{\Varid{e}\to \Varid{e}_{\mathrm{1}}} and \ensuremath{\Varid{e}\to \Varid{e}_{\mathrm{2}}},
\ensuremath{\Varid{e}_{\mathrm{1}}\rightarrow^* \Varid{v}_{\mathrm{1}}} and \ensuremath{\Varid{e}_{\mathrm{2}}\rightarrow^* \Varid{v}_{\mathrm{2}}}, then 
\ensuremath{\Varid{e}\rightarrow^* \{\mskip1.5mu \Varid{v}_{\mathrm{1}},\Varid{v}_{\mathrm{2}}\mskip1.5mu\}}.\footnote{This should really be thought of as a multiset, since it's possible for \ensuremath{\Varid{v}_{\mathrm{1}}} and \ensuremath{\Varid{v}_{\mathrm{2}}} to be the same value.}

This addition of non-determinism can lead to problems if we're not careful.
Consider the following example:\\
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{coin}\mathrel{=}\mathrm{0}\mathbin{?}\mathrm{1}{}\<[E]%
\\
\>[3]{}\Varid{double}\;\Varid{x}\mathrel{=}\Varid{x}\mathbin{+}\Varid{x}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
We would expect that for any \ensuremath{\Varid{x}}, \ensuremath{\Varid{double}\;\Varid{x}} should be an even number.
However, if we were to rewrite \ensuremath{\Varid{double}\;\Varid{coin}} using ordinary term rewriting,
then we could have the derivation.\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{double}\;\Varid{coin}\Rightarrow \Varid{coin}\mathbin{+}\Varid{coin}\Rightarrow (\mathrm{0}\mathbin{?}\mathrm{1})\mathbin{+}(\mathrm{0}\mathbin{?}\mathrm{1})\Rightarrow \mathrm{0}\mathbin{+}(\mathrm{0}\mathbin{?}\mathrm{1})\Rightarrow \mathrm{0}\mathbin{+}\mathrm{1}\Rightarrow \mathrm{1}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
This is clearly not the derivation we want.
The problem here is that when we reduced \ensuremath{\Varid{double}\;\Varid{coin}},
we made a copy of the non-deterministic expression \ensuremath{\Varid{coin}}.
This ability to clone non-deterministic expressions to get different answers
is known as run-time choice semantics. \cite{callTimeChoice}.

The alternative to this is call-time choice semantics.
When a non-deterministic expression is reduced,
all instances of the expression take the same value.
One way to enforce this is to represent expressions as graphs instead of terms.
Since no expressions are ever duplicated, all instances of \ensuremath{\Varid{coin}} will reduce the same way.
This issue of run-time choice semantics will appear throughout the compiler.


\subsection{FlatCurry} \label{FlatCurry}

The first step in the compiler pipeline is to parse a Curry program into FlatCurry\index{FlatCurry}.
The definition is given in figure \ref{fig:flatSyntax}.
The FlatCurry language is the standard for representing Curry programs
in compilers \cite{pakcs, kics2, Kics2Theory, sprite}, 
and has been used to define the semantics of Curry programs \cite{currySemantics}.



The semantics of Curry have already been studied extensively \cite{currySemantics},
so we informally recall some of the more important points.
A FlatCurry program consists of datatype and function definitions.
For simplicity we assume that all programs are self contained,
because the module system isn't relevant to our work.
However, the Rice compiler does support modules.
A FlatCurry function contains a single rule, 
which is responsible for pattern matching and rewriting an expression.
Pattern matching is converted into case and choice expressions as defined in \cite{currySemantics}.
A function returns a new expression graph constructed out of \ensuremath{\mathbf{let}\;,\textbf{free} ,\Varid{f}_{\Varid{k}},\Conid{C}_{\Varid{k}},\mathbin{?},\Varid{l},\Varid{v}}
expressions.

Our presentation of FlatCurry differs from \cite{currySemantics} in three notable ways.
First, function and constructor applications
contain a count of the arguments they still need in order to be fully applied.
The application \ensuremath{\Varid{f}_{\Varid{k}}\;\Varid{e}_{\mathrm{1}}\;\Varid{e}_{\mathrm{2}}\ldots \Varid{e}_{\Varid{n}}} means that \ensuremath{\Varid{f}} is applied to \ensuremath{\Varid{n}} arguments,
but it needs \ensuremath{\Varid{k}} more to be fully applied,
so the arity of \ensuremath{\Varid{f}} is \ensuremath{\Varid{n}\mathbin{+}\Varid{k}}.
Second, we include \ensuremath{\mathbf{let}\;\{\mskip1.5mu \Varid{v}\mskip1.5mu\}\;\textbf{free} } to represent free variables.
This was not needed in \cite{currySemantics, kics2} because free variables we translated
to non-deterministic generators.
Since we narrow free variables instead of doing this transformation, 
we must represent free variables in FlatCurry.
Finally, we add an explicit failure expression \ensuremath{\bot } to represent a branch
that is not present in the definitional tree.
While this is meant to simply represent a failing computation,
we've also occasionally found it useful in optimization.

\subsection{Evaluation} \label{Evaluation}

Each program contains a special function \ensuremath{\Varid{main}} that takes no arguments.
The program executes by reducing the expression \ensuremath{\Varid{main}} 
to a \emph{Constructor Normal 
Form}\index{Constructor Normal Form}\footnote{This is constructor normal form, and not simply a normal form,
              because a failing expression, like \ensuremath{\Varid{head}\;[\mskip1.5mu \mskip1.5mu]}, is a normal form,
              since it can't be rewritten, but it contains a function at the root.} 
as defined in figure \ref{fig:normalForm}.
Similar to Kics2, Pakcs, and Sprite, \cite{kics2, pakcs, sprite}
we compute constructor normal form by first reducing the \ensuremath{\Varid{main}} to 
\emph{Head Constructor Form}\index{Head Constructor Form}.
That is where the expression is rooted by a constructor.
Then each child of the root is reduced to constructor normal form.

\begin{figure}
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{15}{@{}>{\hspre}c<{\hspost}@{}}%
\column{15E}{@{}l@{}}%
\column{19}{@{}>{\hspre}l<{\hspost}@{}}%
\column{60}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{f}{}\<[15]%
\>[15]{}\Rightarrow {}\<[15E]%
\>[19]{}\Varid{f}\;\{\mskip1.5mu \Varid{v}\mskip1.5mu\}\mathrel{=}\Varid{e}{}\<[E]%
\\
\>[3]{}\Varid{e}{}\<[15]%
\>[15]{}\Rightarrow {}\<[15E]%
\>[19]{}\Varid{v}\;{}\<[60]%
\>[60]{}\Conid{Variable}{}\<[E]%
\\
\>[15]{}\mid {}\<[15E]%
\>[19]{}\Varid{l}\;{}\<[60]%
\>[60]{}\Conid{Literal}{}\<[E]%
\\
\>[15]{}\mid {}\<[15E]%
\>[19]{}\Varid{e}_{\mathrm{1}}\mathbin{?}\Varid{e}_{\mathrm{2}}\;{}\<[60]%
\>[60]{}\Conid{Choice}{}\<[E]%
\\
\>[15]{}\mid {}\<[15E]%
\>[19]{}\bot \;{}\<[60]%
\>[60]{}\Conid{Failed}{}\<[E]%
\\
\>[15]{}\mid {}\<[15E]%
\>[19]{}\Varid{f}_{\Varid{k}}\;\{\mskip1.5mu \Varid{e}\mskip1.5mu\}\;{}\<[60]%
\>[60]{}\Conid{Function}\;\Conid{Application}{}\<[E]%
\\
\>[15]{}\mid {}\<[15E]%
\>[19]{}\Conid{C}_{\Varid{k}}\;\{\mskip1.5mu \Varid{e}\mskip1.5mu\}\;{}\<[60]%
\>[60]{}\Conid{Constructor}\;\Conid{Application}{}\<[E]%
\\
\>[15]{}\mid {}\<[15E]%
\>[19]{}\mathbf{let}\;\{\mskip1.5mu \Varid{v}\mathrel{=}\Varid{e}\mskip1.5mu\}\;\mathbf{in}\;\Varid{e}\;{}\<[60]%
\>[60]{}\Conid{Variable}\;\Conid{Declaration}{}\<[E]%
\\
\>[15]{}\mid {}\<[15E]%
\>[19]{}\mathbf{let}\;\{\mskip1.5mu \Varid{v}\mskip1.5mu\}\;\textbf{free} \;\mathbf{in}\;\Varid{e}\;{}\<[60]%
\>[60]{}\Conid{Free}\;\Conid{Variable}\;\Conid{Declaration}{}\<[E]%
\\
\>[15]{}\mid {}\<[15E]%
\>[19]{}\mathbf{case}\;\Varid{e}\;\mathbf{of}\;\{\mskip1.5mu \Varid{p}\to \Varid{e}\mskip1.5mu\}\;{}\<[60]%
\>[60]{}\Conid{Case}\;\Conid{Expression}{}\<[E]%
\\
\>[3]{}\Varid{p}{}\<[15]%
\>[15]{}\Rightarrow {}\<[15E]%
\>[19]{}\Conid{C}\;\{\mskip1.5mu \Varid{v}\mskip1.5mu\}\;{}\<[60]%
\>[60]{}\Conid{Constructor}\;\Conid{Pattern}{}\<[E]%
\\
\>[15]{}\mid {}\<[15E]%
\>[19]{}\Varid{l}\;{}\<[60]%
\>[60]{}\Conid{Literal}\;\Conid{Pattern}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\caption{Syntax definition for FlatCurry\\
This is largely the same as other presentations \cite{currySemantics,icurry}
but we have elected to add more information that will become relevant for optimizations later.
The notation \ensuremath{\{\mskip1.5mu \Varid{e}\mskip1.5mu\}} refers to a variable length list \ensuremath{\Varid{e}_{\mathrm{1}}\;\Varid{e}_{\mathrm{2}}\ldots \Varid{e}_{\Varid{n}}}.}
\label{fig:flatSyntax}
\end{figure}

\begin{figure}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{5}{@{}>{\hspre}c<{\hspost}@{}}%
\column{5E}{@{}l@{}}%
\column{9}{@{}>{\hspre}l<{\hspost}@{}}%
\column{26}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{n}\Rightarrow {}\<[9]%
\>[9]{}\Varid{l}\;{}\<[26]%
\>[26]{}\Varid{literal}{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mid {}\<[5E]%
\>[9]{}\Conid{C}_{\Varid{k}}\;\Varid{n}_{\mathrm{1}}\ldots \Varid{n}_{\Varid{k}}\;{}\<[26]%
\>[26]{}\Varid{constructor}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\caption{constructor normal forms in FlatCurry.\\
         A CNF is an expression that contains only constructor and literal symbols.
         All CNFs are normal forms in our system.}
\label{fig:normalForm}
\end{figure}

Most of the work of evaluation is reducing an expression to head constructor form.
Kics2 and Pakcs are able to transform FlatCurry programs into an equivalent rewrite
system, and reduce expressions using graph rewriting \cite{kics2, pakcs}.
The transformation simply created a new function for every nested case expression.
This created a series of tail calls for larger functions.

To see this transformation in action, we can examine the FlatCurry function \ensuremath{\Varid{==}} on lists \ref{fig:eqList}.
This function is inductively sequential, however both Pakcs and Kics2 will transform it
into a series of flat function calls with a single case at the root.
Since this would drastically increase the number of function calls, we avoid this transformation.
It would also defeat much of the purpose of an optimizing compiler 
if we weren't allowed to inline functions.

\begin{figure}
Original FlatCurry representation of \ensuremath{\Varid{==}} on lists.\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{22}{@{}>{\hspre}l<{\hspost}@{}}%
\column{24}{@{}>{\hspre}l<{\hspost}@{}}%
\column{34}{@{}>{\hspre}l<{\hspost}@{}}%
\column{39}{@{}>{\hspre}l<{\hspost}@{}}%
\column{41}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}(\Varid{==})\;\Varid{v}_{\mathrm{2}}\;\Varid{v}_{\mathrm{3}}\mathrel{=}\mathbf{case}\;{}\<[24]%
\>[24]{}\Varid{v}_{\mathrm{2}}\;\mathbf{of}{}\<[E]%
\\
\>[3]{}\hsindent{19}{}\<[22]%
\>[22]{}[\mskip1.5mu \mskip1.5mu]\to \mathbf{case}\;{}\<[34]%
\>[34]{}\Varid{v}_{\mathrm{3}}\;\mathbf{of}{}\<[E]%
\\
\>[34]{}[\mskip1.5mu \mskip1.5mu]\to \Conid{True}{}\<[E]%
\\
\>[34]{}\Varid{v}_{\mathrm{4}}\mathbin{:}\Varid{v}_{\mathrm{5}}\to \Conid{False}{}\<[E]%
\\
\>[3]{}\hsindent{19}{}\<[22]%
\>[22]{}\Varid{v}_{\mathrm{6}}\mathbin{:}\Varid{v}_{\mathrm{7}}\to \mathbf{case}\;{}\<[41]%
\>[41]{}\Varid{v}_{\mathrm{3}}\;\mathbf{of}{}\<[E]%
\\
\>[22]{}\hsindent{17}{}\<[39]%
\>[39]{}[\mskip1.5mu \mskip1.5mu]\to \Conid{False}{}\<[E]%
\\
\>[22]{}\hsindent{17}{}\<[39]%
\>[39]{}\Varid{v}_{\mathrm{8}}\mathbin{:}\Varid{v}_{\mathrm{9}}\to \Varid{v}_{\mathrm{6}}\Varid{==}\Varid{v}_{\mathrm{8}}\mathrel{\wedge}\Varid{v}_{\mathrm{7}}\Varid{==}\Varid{v}_{\mathrm{9}}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
Transformed FlatCurry representation of \ensuremath{\Varid{==}} on lists.\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{22}{@{}>{\hspre}l<{\hspost}@{}}%
\column{24}{@{}>{\hspre}l<{\hspost}@{}}%
\column{25}{@{}>{\hspre}l<{\hspost}@{}}%
\column{31}{@{}>{\hspre}l<{\hspost}@{}}%
\column{34}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}(\Varid{==})\;\Varid{v}_{\mathrm{2}}\;\Varid{v}_{\mathrm{3}}\mathrel{=}\mathbf{case}\;{}\<[24]%
\>[24]{}\Varid{v}_{\mathrm{2}}\;\mathbf{of}{}\<[E]%
\\
\>[3]{}\hsindent{19}{}\<[22]%
\>[22]{}[\mskip1.5mu \mskip1.5mu]\to \Varid{eqListNil}\;\Varid{v}_{\mathrm{3}}{}\<[E]%
\\
\>[3]{}\hsindent{19}{}\<[22]%
\>[22]{}\Varid{v}_{\mathrm{6}}\mathbin{:}\Varid{v}_{\mathrm{7}}\to \Varid{eqListCons}\;\Varid{v}_{\mathrm{3}}\;\Varid{v}_{\mathrm{6}}\;\Varid{v}_{\mathrm{7}}{}\<[E]%
\\
\>[3]{}\Varid{eqListNil}\;\Varid{v}_{\mathrm{3}}\mathrel{=}\mathbf{case}\;{}\<[25]%
\>[25]{}\Varid{v}_{\mathrm{3}}\;\mathbf{of}{}\<[E]%
\\
\>[3]{}\hsindent{21}{}\<[24]%
\>[24]{}[\mskip1.5mu \mskip1.5mu]\to \Conid{True}{}\<[E]%
\\
\>[3]{}\hsindent{21}{}\<[24]%
\>[24]{}\Varid{v}_{\mathrm{4}}\mathbin{:}\Varid{v}_{\mathrm{5}}\to \Conid{False}{}\<[E]%
\\
\>[3]{}\Varid{eqListCons}\;\Varid{v}_{\mathrm{3}}\;\Varid{v}_{\mathrm{6}}\;\Varid{v}_{\mathrm{7}}\mathrel{=}\mathbf{case}\;{}\<[34]%
\>[34]{}\Varid{v}_{\mathrm{3}}\;\mathbf{of}{}\<[E]%
\\
\>[3]{}\hsindent{28}{}\<[31]%
\>[31]{}[\mskip1.5mu \mskip1.5mu]\to \Conid{False}{}\<[E]%
\\
\>[3]{}\hsindent{28}{}\<[31]%
\>[31]{}\Varid{v}_{\mathrm{8}}\mathbin{:}\Varid{v}_{\mathrm{9}}\to \Varid{v}_{\mathrm{6}}\Varid{==}\Varid{v}_{\mathrm{8}}\mathrel{\wedge}\Varid{v}_{\mathrm{7}}\Varid{==}\Varid{v}_{\mathrm{9}}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks

\caption{Transformation of FlatCurry \ensuremath{\Varid{==}} function into a flat representation
         for Pakcs and Kics2.}
\label{fig:eqList}
\end{figure}

\subsection{Non-determinism} \label{Non-determinism}


Currently there are three approaches to evaluating non-deterministic expression in Curry:
\emph{backtracking}\index{backtracking}, 
\emph{Pull-Tabbing}\index{pull-tabbing}\cite{pulltab}, and 
\emph{Bubbling}\index{bubbling}\cite{bubbling}.
At this time there are complete strategies for evaluating Curry programs,
so we have elected to use backtracking.
It is the simplest to implement, and it's well understood.

In our system, backtracking is implemented in the usual way.
When an expression rooted by a node \ensuremath{\Varid{n}} with label by \ensuremath{\Varid{f}} 
is rewritten to an expression rooted by \ensuremath{\Varid{e}},
we push the rewrite \ensuremath{(\Varid{n},\Varid{n}_{\Varid{f}},\Conid{Continue})} onto a backtracking stack, where \ensuremath{\Varid{n}_{\Varid{f}}}
is a copy of the original node labeled by \ensuremath{\Varid{f}}.
If the expression is labeled by a choice \ensuremath{\Varid{e}_{\mathrm{1}}\mathbin{?}\Varid{e}_{\mathrm{2}}}, and it is rewritten to the left hand side \ensuremath{\Varid{e}_{\mathrm{1}}},
then we push \ensuremath{(\Varid{n},\Varid{n}_?,\Conid{Stop})} onto the backtracking stack to denote that this 
was an alternative, and we should stop backtracking.

Unfortunately, while backtracking is well defined for rewriting systems,
our representation of FlatCurry programs isn't a graph rewrite system.
This is because we don't flatten our FlatCurry functions like Pakcs and Kics2.
As an example of why FlatCurry programs aren't a graph rewriting system,
consider the FlatCurry function \ensuremath{\Varid{weird}} \ref{fig:weird}.
This function defines a local variables \ensuremath{\Varid{x}} which is used in a case expression.
If this were a rewrite system, then we would be able to translate the
\ensuremath{\mathbf{case}} expression into pattern matching, but a rule can't pattern match on a locally defined variable.
We show the reduction of \ensuremath{\Varid{wierd}} in figure \ref{fig:weirdEval}.

\begin{figure}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{11}{@{}>{\hspre}l<{\hspost}@{}}%
\column{20}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{weird}\mathrel{=}\mathbf{let}\;\Varid{x}\mathrel{=}\Conid{False}\mathbin{?}\Conid{True}{}\<[E]%
\\
\>[3]{}\hsindent{8}{}\<[11]%
\>[11]{}\mathbf{in}\;\mathbf{case}\;{}\<[20]%
\>[20]{}\Varid{x}\;\mathbf{of}{}\<[E]%
\\
\>[20]{}\Conid{False}\to \Conid{True}{}\<[E]%
\\
\>[20]{}\Conid{True}\to \Conid{False}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\caption{The function \ensuremath{\Varid{weird}}\\
         This can't be expressed as rewrite rules, because the expression
         we're pattern matching on is defined locally.}
\label{fig:weird}
\end{figure}

\begin{figure}
\noindent
\begin{itemize}
   \item We start with a root \ensuremath{\Varid{r}} labeled by \ensuremath{\Varid{weird}}.
   \item Node \ensuremath{\Varid{n}_{\mathrm{1}}} labeled by \ensuremath{\mathbin{?}} is created with children \ensuremath{[\mskip1.5mu \Conid{False},\Conid{True}\mskip1.5mu]}.
   \item \ensuremath{\Varid{n}_{\mathrm{1}}} is rewritten to \ensuremath{\Conid{False}} and \ensuremath{(\Varid{n}_{\mathrm{1}},\Conid{True},\Conid{Stop})} is pushed on the backtracking stack.
   \item \ensuremath{\Varid{r}} is rewritten to \ensuremath{\Conid{True}} and \ensuremath{(\Varid{r},\Varid{weird},\Conid{Continue})} is pushed on the backtracking stack.
   \item \ensuremath{\Varid{r}} is a constructor normal form.
   \item backtracking to the closest alternative.
   \item The backtracking stack is \ensuremath{[\mskip1.5mu (\Varid{r},\Varid{weird},\Conid{Continue}),(\Varid{n}_{\mathrm{1}},\Conid{True},\Conid{Stop})\mskip1.5mu]}.
   \item reduce \ensuremath{\Varid{r}}.
   \item Node \ensuremath{\Varid{n}_{\mathrm{2}}} labeled by \ensuremath{\mathbin{?}} is created with children \ensuremath{[\mskip1.5mu \Conid{False},\Conid{True}\mskip1.5mu]}.
   \item $\ldots$
\end{itemize}
\caption{Evaluation of the function \ensuremath{\Varid{weird}}.}
\label{fig:weirdEval}
\end{figure}


We've entered an infinite loop of computing the same rewrite.
The problem is that when we're backtracking,
and replacing nodes with their original versions, we're going too far
back in the computation.
In this example, when backtracking \ensuremath{\Varid{weird}}, we want to backtrack to a point
where \ensuremath{\Varid{x}} has been created, and we just want to evaluate the case again.

We solve this problem by creating a new function for each case expression in our original function.
Figure \ref{fig:caseFuncs} show an example for \ensuremath{\Varid{weird}} and \ensuremath{\Varid{==}} which were defined above.
This is actually very similar to how Pakcs and Kics2 transformed their programs into
rewrite systems by flattening them.
The difference is that we don't need to make any extra function calls unless
we are already backtracking.
There is no efficiency cost in either time or space with our solution.
The only cost is a little more complexity in the code generator,
and an increase in the generated code size.
This seems like an acceptable trade off, 
since our programs are still similar in size to equivalent programs compiled with GHC.

\begin{figure}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{12}{@{}>{\hspre}l<{\hspost}@{}}%
\column{21}{@{}>{\hspre}l<{\hspost}@{}}%
\column{24}{@{}>{\hspre}l<{\hspost}@{}}%
\column{32}{@{}>{\hspre}l<{\hspost}@{}}%
\column{35}{@{}>{\hspre}l<{\hspost}@{}}%
\column{44}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{weird}\mathrel{=}{}\<[12]%
\>[12]{}\mathbf{let}\;\Varid{x}\mathrel{=}\Conid{False}\mathbin{?}\Conid{True}{}\<[E]%
\\
\>[12]{}\mathbf{in}\;\mathbf{case}\;{}\<[21]%
\>[21]{}\Varid{x}\;\mathbf{of}{}\<[E]%
\\
\>[21]{}\Conid{False}\to \Conid{True}{}\<[E]%
\\
\>[21]{}\Conid{True}\to \Conid{False}{}\<[E]%
\\[\blanklineskip]%
\>[3]{}\Varid{weird}_{\mathrm{1}}\;\Varid{x}\mathrel{=}\mathbf{case}\;{}\<[21]%
\>[21]{}\Varid{x}\;\mathbf{of}{}\<[E]%
\\
\>[21]{}\Conid{False}\to \Conid{True}{}\<[E]%
\\
\>[21]{}\Conid{True}\to \Conid{False}{}\<[E]%
\\[\blanklineskip]%
\>[3]{}(\Varid{==})\;\Varid{v}_{\mathrm{2}}\;\Varid{v}_{\mathrm{3}}\mathrel{=}\mathbf{case}\;{}\<[24]%
\>[24]{}\Varid{v}_{\mathrm{2}}\;\mathbf{of}{}\<[E]%
\\
\>[24]{}[\mskip1.5mu \mskip1.5mu]{}\<[35]%
\>[35]{}\to \mathbf{case}\;{}\<[44]%
\>[44]{}\Varid{v}_{\mathrm{3}}\;\mathbf{of}{}\<[E]%
\\
\>[44]{}[\mskip1.5mu \mskip1.5mu]\to \Conid{True}{}\<[E]%
\\
\>[44]{}\Varid{v}_{\mathrm{4}}\mathbin{:}\Varid{v}_{\mathrm{5}}\to \Conid{False}{}\<[E]%
\\
\>[24]{}\Varid{v}_{\mathrm{6}}\mathbin{:}\Varid{v}_{\mathrm{7}}{}\<[35]%
\>[35]{}\to \mathbf{case}\;{}\<[44]%
\>[44]{}\Varid{v}_{\mathrm{3}}\;\mathbf{of}{}\<[E]%
\\
\>[44]{}[\mskip1.5mu \mskip1.5mu]\to \Conid{False}{}\<[E]%
\\
\>[44]{}\Varid{v}_{\mathrm{8}}\mathbin{:}\Varid{v}_{\mathrm{9}}\to \Varid{v}_{\mathrm{6}}\Varid{==}\Varid{v}_{\mathrm{8}}\mathrel{\wedge}\Varid{v}_{\mathrm{7}}\Varid{==}\Varid{v}_{\mathrm{9}}{}\<[E]%
\\[\blanklineskip]%
\>[3]{}\Varid{eqList}_{\mathrm{1}}\;\Varid{v}_{\mathrm{3}}\mathrel{=}\mathbf{case}\;{}\<[24]%
\>[24]{}\Varid{v}_{\mathrm{3}}\;\mathbf{of}{}\<[E]%
\\
\>[24]{}[\mskip1.5mu \mskip1.5mu]\to \Conid{True}{}\<[E]%
\\
\>[24]{}\Varid{v}_{\mathrm{4}}\mathbin{:}\Varid{v}_{\mathrm{5}}\to \Conid{False}{}\<[E]%
\\[\blanklineskip]%
\>[3]{}\Varid{eqList}_{\mathrm{2}}\;\Varid{v}_{\mathrm{6}}\;\Varid{v}_{\mathrm{7}}\;\Varid{v}_{\mathrm{3}}\mathrel{=}\mathbf{case}\;{}\<[32]%
\>[32]{}\Varid{v}_{\mathrm{3}}\;\mathbf{of}{}\<[E]%
\\
\>[32]{}[\mskip1.5mu \mskip1.5mu]\to \Conid{False}{}\<[E]%
\\
\>[32]{}\Varid{v}_{\mathrm{8}}\mathbin{:}\Varid{v}_{\mathrm{9}}\to \Varid{v}_{\mathrm{6}}\Varid{==}\Varid{v}_{\mathrm{8}}\mathrel{\wedge}\Varid{v}_{\mathrm{7}}\Varid{==}\Varid{v}_{\mathrm{9}}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\caption{Functions at case for \ensuremath{\Varid{weird}} and \ensuremath{\Varid{==}} for lists.}
\label{fig:caseFuncs}
\end{figure}



As far as we're aware, this is a novel approach for improving the efficiency of backtracking
in rewriting systems.
The correctness of this method follows 
from the redex contraction theorem, which is proved later.


\subsection{Free Variables} \label{Free Variables}

Free variables are similar to non-deterministic expressions.
In fact, in both Kics2 and Sprite \cite{kics2,sprite} they are replaced
by non-deterministic generators of the appropriate type \cite{OverlappingRules}.
However, in Rice, free variables are instantiated by narrowing.
If a free variable is the scrutinee of a case expression, then 
we push copies of the remaining patterns onto the stack along with another 
copy of the variable.
If the free variable is replaced by a constructor with arguments, such as \ensuremath{\Conid{Just}},
then we instantiate the arguments with free variables.


\begin{figure}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{20}{@{}>{\hspre}l<{\hspost}@{}}%
\column{28}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{data}\;\Conid{Light}\mathrel{=}\Conid{Red}\mid \Conid{Yellow}\mid \Conid{Green}{}\<[E]%
\\[\blanklineskip]%
\>[3]{}\Varid{change}\;\Varid{x}\mathrel{=}\mathbf{case}\;{}\<[20]%
\>[20]{}\Varid{x}\;\mathbf{of}{}\<[E]%
\\
\>[20]{}\Conid{Red}{}\<[28]%
\>[28]{}\to \Conid{Green}{}\<[E]%
\\
\>[20]{}\Conid{Green}{}\<[28]%
\>[28]{}\to \Conid{Yellow}{}\<[E]%
\\
\>[20]{}\Conid{Yellow}{}\<[28]%
\>[28]{}\to \Conid{Red}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\caption{A simple traffic light program}
\label{fig:light}
\end{figure}

This is easier to see with an example.
Consider the traffic light function in figure \ref{fig:light}.
The \ensuremath{\Varid{change}} function moves the light from \ensuremath{\Conid{Red}} to \ensuremath{\Conid{Green}} to \ensuremath{\Conid{Yellow}}.
When calling this function with a free variable, we have the derivation below in figure \ref{fig:lightEval}.

\begin{figure}
\begin{itemize}
   \item We start with root \ensuremath{\Varid{r}} labeled by \ensuremath{\Varid{change}}, with a child \ensuremath{\Varid{x}} labeled by \ensuremath{\Varid{free}}.
   \item \ensuremath{\Varid{x}} is rewritten to \ensuremath{\Conid{Red}} and \ensuremath{(\Varid{x},\Conid{Green},\Conid{Stop}),(\Varid{x},\Conid{Yellow},\Conid{Stop}),(\Varid{x},\Varid{free},\Conid{Continue})} 
         are all pushed on the stack
   \item \ensuremath{\Varid{r}} is rewritten to \ensuremath{\Conid{Green}}, and \ensuremath{(\Varid{r},\Varid{change},\Conid{Continue})} is pushed on the stack
   \item \ensuremath{\Varid{r}} is a constructor normal form
   \item backtracking to the closest alternative
   \item backtracking stack is 
         \ensuremath{[\mskip1.5mu (\Varid{r},\Varid{change},\Conid{Continue}),(\Varid{x},\Conid{Green},\Conid{Stop}),(\Varid{x},\Conid{Yellow},\Conid{Stop}),(\Varid{x},\Varid{free},\Conid{Continue})\mskip1.5mu]}.
   \item reduce \ensuremath{\Varid{r}}
   \item \ensuremath{\Varid{x}} is labeled by \ensuremath{\Conid{Green}}
   \item \ensuremath{\Varid{r}} is rewritten to \ensuremath{\Conid{Yellow}}, and \ensuremath{(\Varid{r},\Varid{change},\Conid{Continue})} is pushed on the stack
   \item \ensuremath{\Varid{r}} is a constructor normal form
   \item backtracking to the closest alternative
   \item backtracking stack is 
         \ensuremath{[\mskip1.5mu (\Varid{r},\Varid{change},\Conid{Continue}),(\Varid{x},\Conid{Yellow},\Conid{Stop}),(\Varid{x},\Varid{free},\Conid{Continue})\mskip1.5mu]}
   \item reduce \ensuremath{\Varid{r}}
   \item \ensuremath{\Varid{x}} is labeled by \ensuremath{\Conid{Yellow}}
   \item \ensuremath{\Varid{r}} is rewritten to \ensuremath{\Conid{Red}}, and \ensuremath{(\Varid{r},\Varid{change},\Conid{Continue})} is pushed on the stack
   \item \ensuremath{\Varid{r}} is a constructor normal form
   \item backtracking to the closest alternative
   \item backtracking stack is 
         \ensuremath{[\mskip1.5mu (\Varid{r},\Varid{change},\Conid{Continue}),(\Varid{x},\Varid{free},\Conid{Continue})\mskip1.5mu]}
   \item Both rewrites are popped, and the stack is empty with no alternatives.
\end{itemize}
\caption{Evaluation of \ensuremath{\Varid{change}\;\Varid{x}\;\mathbf{where}\;\Varid{x}\;\textbf{free} }}
\label{fig:lightEval}
\end{figure}

\subsection{Higher Order Functions} \label{Higher Order Functions}

Now that we have a plan for the logic features of Curry, we move on to higher order functions.
This subject has been extensively studied by the function languages community,
and we take the approach of \cite{fastCurry}.
Higher order functions are represented using defunctionalization \cite{defunctionalization}.
Recall that in FlatCurry, an expression $f_k$\index{$f_k$} represents a partial application
that is missing \ensuremath{\Varid{k}} arguments.
We introduce an \ensuremath{\Varid{apply}} function that has an unspecified arity,
where \ensuremath{\Varid{apply}\;\Varid{f}_{\Varid{k}}\;\Varid{e}_{\mathrm{1}}\;\Varid{e}_{\mathrm{2}}\ldots \Varid{e}_{\Varid{n}}} applies \ensuremath{\Varid{f}_{\Varid{k}}} to the arguments \ensuremath{\Varid{e}_{\mathrm{1}}\;\Varid{e}_{\mathrm{2}}\ldots \Varid{e}_{\Varid{n}}}.

The behavior of \ensuremath{\Varid{apply}} is specified below.
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{4}{@{}>{\hspre}l<{\hspost}@{}}%
\column{14}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{apply}\;\Varid{f}_{\Varid{k}}\;\Varid{x}_{\mathrm{1}}\ldots \Varid{x}_{\Varid{n}}{}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mid \Varid{k}\mathbin{>}\Varid{n}{}\<[14]%
\>[14]{}\mathrel{=}f_{k-n}\;\Varid{x}_{\mathrm{1}}\ldots \Varid{x}_{\Varid{n}}{}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mid \Varid{k}\Varid{==}\Varid{n}{}\<[14]%
\>[14]{}\mathrel{=}\Varid{f}\;\Varid{x}_{\mathrm{1}}\ldots \Varid{x}_{\Varid{n}}{}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mid \Varid{k}\mathbin{<}\Varid{n}{}\<[14]%
\>[14]{}\mathrel{=}\Varid{apply}\;(\Varid{f}\;\Varid{x}_{\mathrm{1}}\ldots \Varid{x}_{\Varid{k}})\;x_{k+1}\ldots \Varid{x}_{\Varid{n}}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
If the first argument \ensuremath{\Varid{f}} of \ensuremath{\Varid{apply}} is not partially applied,
then evaluate \ensuremath{\Varid{f}} until it is, and proceed as above.
In the case that \ensuremath{\Varid{f}} is a free variable, then we return \ensuremath{\bot }, 
because we don't support higher order narrowing.

\subsection{Backtracking Performance} \label{Backtracking Performance}

Now that we've established a method for implementing non-determinism,
we would like to improve the performance.
Currently we push nodes on the backtracking stack for every rewrite.
Often, we don't need to push most of these rewrites.
Consider the following code for computing Fibonacci numbers:
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{16}{@{}>{\hspre}l<{\hspost}@{}}%
\column{17}{@{}>{\hspre}l<{\hspost}@{}}%
\column{24}{@{}>{\hspre}l<{\hspost}@{}}%
\column{28}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{fib}\;\Varid{n}\mathrel{=}\mathbf{case}\;{}\<[17]%
\>[17]{}\Varid{n}\mathbin{<}\mathrm{2}\;\mathbf{of}{}\<[E]%
\\
\>[17]{}\Conid{True}{}\<[24]%
\>[24]{}\to \Varid{n}{}\<[E]%
\\
\>[17]{}\Conid{False}{}\<[24]%
\>[24]{}\to {}\<[28]%
\>[28]{}\Varid{fib}\;(\Varid{n}\mathbin{-}\mathrm{1})\mathbin{+}\Varid{fib}\;(\Varid{n}\mathbin{-}\mathrm{2}){}\<[E]%
\\[\blanklineskip]%
\>[3]{}\Varid{main}\mathrel{=}\mathbf{case}\;{}\<[16]%
\>[16]{}\Varid{fib}\;\mathrm{20}\Varid{==}(\mathrm{1}\mathbin{?}\mathrm{6765})\;\mathbf{of}{}\<[E]%
\\
\>[16]{}\Conid{True}\to \Varid{putStrLn}\;\text{\ttfamily \char34 found~answer\char34}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
This program will compute \ensuremath{\Varid{fib}\;\mathrm{20}}, pushing all of those rewrites onto the stack as it does,
and then, when it discoverers that \ensuremath{\Varid{fib}\;\mathrm{20}\not\equiv \mathrm{1}}, it will undo all of those computations,
only to redo them immediately afterwards!
This is clearly not what we want.
Since \ensuremath{\Varid{fib}} is a deterministic function, we would like to avoid pushing these rewrites onto the stack.
Unfortunately, this isn't as simple as it would first seems for two reasons.
First, determining if a function is non-deterministic in general is undecidable,
so any algorithm we developed would push rewrites for some deterministic computations.
Second, a function may have a non-deterministic argument.
For example, we could easily change the above program to:
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{16}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{main}\mathrel{=}\mathbf{case}\;{}\<[16]%
\>[16]{}\Varid{fib}\;(\mathrm{1}\mathbin{?}\mathrm{20})\Varid{==}\mathrm{6765}\;\mathbf{of}{}\<[E]%
\\
\>[16]{}\Conid{True}\to \Varid{putStrLn}\;\text{\ttfamily \char34 found~answer\char34}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
Now the expression with \ensuremath{\Varid{fib}} is no longer deterministic.
We sidestep the whole issue by noticing that while it's impossible to tell 
if an expression is non-deterministic at compile time,
it's very easy to tell if it is at run time.

As far as we're aware, this is another novel solution.
Each expression contains a Boolean flag that marks if it is non-deterministic.
We called these \emph{nondet}\index{nondet} flags,
and we refer to an expression whose root node is marked with a nondet flag as nondet.
The rules for determining if an expression \ensuremath{\Varid{e}} is nondet are:
if \ensuremath{\Varid{e}} is labeled by a choice, then \ensuremath{\Varid{e}} is nondet;
if \ensuremath{\Varid{e}} is labeled by a function that has a case who's scrutinee is nondet,
or is a forward to a nondet, then \ensuremath{\Varid{e}} is nondet;
if \ensuremath{\Varid{e'}\rightarrow^* \Varid{e}} and \ensuremath{\Varid{e'}} is nondet, then \ensuremath{\Varid{e}} is nondet.

Any node not marked as nondet doesn't need to be pushed on the stack
because it's not part of a choice, 
all of its case statements scrutinized deterministic nodes,
and it's not forwarding to a non-deterministic node.
However proving this is a more substantial problem.

We prove this for the class of limited overlapping inductively sequential graph rewriting systems, 
with the understanding our system is equivalent.
This proof is based on a corresponding proof for set functions in Curry \cite{setFunctions}[Lemma 2].
The original proof was concerned with a deterministic derivation from an expression to a value.
While the idea is similar, we don't want to necessarily derive an expression to a value.
Instead we define a deterministic redex, and deterministic step below, and show that there
is an analogous theorem for a derivation of deterministic steps, even if it doesn't compute a value.

\begin{definition}
Given a rewrite system $R$ with fixed strategy $\phi$, 
a \emph{computation space}\index{computation space} \cite{setFunctions} of expression $e$, 
$C(e)$\index{$C(e)$} is finitely branching tree defined inductively the rule
$C(e) = \langle e, C(e_1), C(e_2) \ldots C(e_n)\rangle$.
\end{definition}
\label{def:computationSpace}

We now need the notions of a deterministic redex and a deterministic rewrite.
Ultimately we want to show that if we have a deterministic reduction,
then we can perform that computation at any point without affecting the results.
One implication of this would be that performing a deterministic computation before
a non-deterministic choice was made would be the same as performing the computation
after the choice.
This would justify our fast backtracking scheme, because it would be equivalent
to performing the computation before the choice was made.

\begin{definition}
A redex $n$ in expression $e$ is deterministic if there is at most
one rewrite rule that could apply to $e\vert_n$.
A rewrite $e \to_n e'$ is deterministic if $n$ is a deterministic redex.
\end{definition} \label{def:deterministic}

Next we rephrase our notion of nondet for a LOIS system.

\begin{definition}
let $e \to e_1 \to \ldots v$ be a derivation for $e$ to $v$.
A node $n$ in $e_i$ is  \emph{nondet} iff\\
1. $n$ is labeled by a choice.\\
2. A node in the redex pattern \cite{bubblingCorrect} of $n$ is \emph{nondet}.\\
3. There exists some $j < i$ where $n$ is a subexpression of $e_j$ and $n$ is \emph{nondet}.
\end{definition}

The first property is that all choice nodes are nondet.
The second property is equivalent to the condition that any node 
that scrutinizes a nondet node should be nondet.
Finally, the third property is that nondet should be a persistent attribute.
This corresponds to the definition we gave for nondet nodes above.

If $n$ is a redex that isn't marked as nondet,
then $n$ can't be labeled by a choice.
Since choice is the only rule in a LOIS system that is non-deterministic,
$n$ must be a deterministic redex.
We recall a theorem used to prove the correctness of set function.\cite{setFunctions}[Def. 1, Lemma 1]

\begin{lemma}
Given an expression $e$ where $e \to_{n_1} e_1$ and $e \to_{n_2} e_2$,
if $n_1 \ne n_2$, then there exists a $u_1$ and $u_2$ where
$t_1 \to^= u_1$ and $t_2 \to^= u_2$ and $u_1 = u_2$ up to renaming of nodes.
\end{lemma}

This leads directly to our first important theorem.
If $n$ is a deterministic redex in a derivation, then we can move it earlier in the derivation.

\begin{theorem}[Redex Compression Theorem\index{Redex Compression Theorem}]
if $n$ is a deterministic redex of $e$ where $n \to n'$, and $e \to e_1 \to_n e_2$.
Then there exists a derivation $e[n \to n'] \to^= e'$ where $e_2 = e'$ up to renaming of nodes.
\end{theorem}

\begin{proof}
By definition of rewriting $e \to_n e[n\to n']$.
Since $n$ is a deterministic redex, it must be the case that the redex in $e \to e_1$
was not $n$. So by the previous lemma, we can swap the order of the rewrites.
\end{proof}

Finally we show that if $a$ is a subexpression of $e$ and $a \to^* b$ using only deterministic redexes,
then $e[a \to b]$ rewrites to the same values.

\begin{theorem}[Path Compression Theorem\index{Path Compression Theorem}]
if $a$ is a subexpression of $e$ and $a \to^* b$ using only deterministic rewrites,
and $e \to e_1 \to \ldots e_n$ is a derivation where $b$ is a subexpression of $e_n$,
then there is a derivation $e[a\to b] \to^* e_n$.
\end{theorem}

\begin{proof}
This follows by induction on the length of the derivation.
In the base case $a = b$, and there is nothing to prove.
In the inductive case $a \to_p a' \to^* b$.
Since $a \to_p a'$ is deterministic by assumption,
we can apply the path compression theorem and say that $e[a \to a'] \to^* e_n$.
By the inductive hypotheses we can say that $e[a \to a'][a' \to b] \to^* e_n$.
Therefore $e[a \to b] \to^* e_n$.
This establishes our result.
\end{proof}



\subsection{Collapsing Functions} \label{Collapsing Functions}

While this result is great, and it allows us to avoid creating a large number of stack frames,
there's a subtle aspect of graph rewriting that gets in the way.
If a node \ensuremath{\Varid{n}_{\mathrm{1}}} labeled by function \ensuremath{\Varid{f}} is rewritten to \ensuremath{\Varid{n}_{\mathrm{2}}},
then the definition of applying a rewrite rule \cite{graphRewriting}[Def. 8, Def. 10, Def. 19]
would require us to traverse the graph, and find every node that has \ensuremath{\Varid{n}_{\mathrm{1}}} as a child,
and redirect that pointer to \ensuremath{\Varid{n}_{\mathrm{2}}}.
This is clearly inefficient, so this isn't done in practice.
A much faster method is to simply replace the contents, the label and children, of \ensuremath{\Varid{n}_{\mathrm{1}}}
with the contents of \ensuremath{\Varid{n}_{\mathrm{2}}}.
This works most of the time, but we run into a problem when
a function can rewrite to a single variable, such as the \ensuremath{\Varid{id}} function.
We call these functions \emph{collapsing functions}\index{collapsing functions}.
One option to solve this problem is to evaluate the contractum 
to head constructor form, and copy the constructor
to the root \cite{gmachine}.
This is commonly used in lazy functional languages,
however it does not work for Curry programs.
Consider the expression following expression.
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{7}{@{}>{\hspre}l<{\hspost}@{}}%
\column{11}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{f}\mathrel{=}\mathbf{let}\;\Varid{x}\mathrel{=}\Conid{True}\mathbin{?}\Conid{False}{}\<[E]%
\\
\>[3]{}\hsindent{8}{}\<[11]%
\>[11]{}\Varid{y}\mathrel{=}\Varid{id}\;\Varid{x}{}\<[E]%
\\
\>[3]{}\hsindent{4}{}\<[7]%
\>[7]{}\mathbf{in}\;\Varid{not}\;\Varid{y}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
When \ensuremath{\Varid{y}} is evaluated, then it will evaluate \ensuremath{\Varid{x}}, and \ensuremath{\Varid{x}} will evaluate to \ensuremath{\Conid{True}}.
If we then copy the \ensuremath{\Conid{True}} constructor to \ensuremath{\Varid{y}}, then we have two copies of \ensuremath{\Conid{True}}.
But, since \ensuremath{\Varid{y}} is deterministic, we don't need to undo \ensuremath{\Varid{y}} when backtracking.
So, \ensuremath{\Varid{y}} will remain \ensuremath{\Conid{True}} after backtracking, instead of returning to \ensuremath{\Varid{id}\;\Varid{x}}.
While constructor copying is definitely invalid with fast backtracking,
it's unclear if it would be valid with a normal backtracking algorithm.

We can solve this problem by using forwarding nodes\index{forwarding node}, 
sometimes called indirection nodes
\cite{lazyFunctionalCompilers}.
The idea is that when we rewrite an expression rooted by a collapsing function,
instead of copying the constructor, we just replace the root with a special forwarding node,
$FORWARD(x)$\index{$FORWARD$}, where \ensuremath{\Varid{x}} is the variable that the function collapses to.

There is one more possibility to address before we move on.
One performance optimization with forwarding nodes is \emph{path compression}\index{path compression}.
If we have a chain of forwarding nodes $FORWARD(FORWARD(FORWARD(x)))$, 
we want to collapse this to simply $FORWARD(x)$.
This is unequivocally invalid in non-deterministic backtracking systems.
Consider the following function.
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{8}{@{}>{\hspre}l<{\hspost}@{}}%
\column{13}{@{}>{\hspre}l<{\hspost}@{}}%
\column{19}{@{}>{\hspre}l<{\hspost}@{}}%
\column{34}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{f}\mathrel{=}{}\<[8]%
\>[8]{}\mathbf{let}\;{}\<[13]%
\>[13]{}\Varid{x}\mathrel{=}\Conid{True}\mathbin{?}\Conid{False}{}\<[E]%
\\
\>[13]{}\Varid{y}\mathrel{=}\Varid{id}\;\Varid{x}{}\<[E]%
\\
\>[8]{}\mathbf{in}\;{}\<[13]%
\>[13]{}\mathbf{case}\;{}\<[19]%
\>[19]{}\Varid{y}\;\mathbf{of}{}\<[E]%
\\
\>[19]{}\Conid{False}\to \mathbf{case}\;{}\<[34]%
\>[34]{}\Varid{x}\;\mathbf{of}{}\<[E]%
\\
\>[34]{}\Conid{False}\to (){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
When reducing this function, we create two forwarding nodes
that are represented by the variables $x$ and $y$.
We refer to these nodes as $FORWARD_x$ and $FORWARD_y$ respectively.
While evaluating \ensuremath{\Varid{y}} in the case expression, we create two forwarding nodes
that are represented by the variables $x$ and $y$ respectively.
We refer to these nodes as $FORWARD_x$ and $FORWARD_y$ respectively.
So $x$ is reduced to $FORWARD_x(True)$, and $y$ is reduced to $FORWARD_y(FORWARD_x(True))$.
If we contract \ensuremath{\Varid{y}} to $FORWARD_y(True)$,
then when we backtrack we replace \ensuremath{\Varid{x}} with $FORWARD_x(False)$, and \ensuremath{\Varid{y}}
is replaced with $id(True)$.
The reason that $y$ doesn't change to $id(False)$ is because $y$ 
has lost its reference to $x$.
Now, not only do we fail to find a solution for \ensuremath{\Varid{f}}, we've ended up in a state
where \ensuremath{\Varid{x}} and \ensuremath{\Varid{y}} have different values.



In this chapter we've discussed the Curry language, and overviewed the semantics of Curry programs.
We've shown different approaches to implementing a system for running Curry programs,
and we've discussed the choices we've made.
When a decision needed to be made, we prioritized correctness, then efficient execution,
and then ease of implementation.
In the next chapter we discuss the implementation at a low level.
This will give us an idea of what the code we want to generate should look like.


\chapter{The Generated Code} \label{ch:The Generated Code}


Now that we've examined all of the different choices to make in constructing a compiler,
we can start to design the generated code and runtime system for the compiler.
In this capter we give examples of generated code to implement Curry functions,
and discuss the low level details of the Rice runtime.
We start with a first order deterministic subset of Curry,
then we add higher order function,
finally we add non-determinism and free variables.
Throughout this section we will use \texttt{teletype font} to represent generated
C code to distinguish it from Curry or FlatCurry code.


We will introduce the generated code by looking at the \ensuremath{\Varid{not}} function defined below.
We choose this function, because it's small enough to be understandable,
but it still demonstrates most of the decisions in designing the generated code
and runtime system.
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{17}{@{}>{\hspre}l<{\hspost}@{}}%
\column{24}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{not}\;\Varid{x}\mathrel{=}\mathbf{case}\;{}\<[17]%
\>[17]{}\Varid{x}\;\mathbf{of}{}\<[E]%
\\
\>[17]{}\Conid{False}{}\<[24]%
\>[24]{}\to \Conid{True}{}\<[E]%
\\
\>[17]{}\Conid{True}{}\<[24]%
\>[24]{}\to \Conid{False}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
Before we discuss generated code, 
we need to discuss expressions and the runtime system for programs.

When a FlatCurry module is compiled, it's translated into a C program.
Every function \ensuremath{\Varid{f}} defined in the FlatCurry module is compiled into
a C function that can reduce an expression, rooted by a node labeled with \ensuremath{\Varid{f}},
into head constructor form.
These functions are called \texttt{f\_hnf}\index{\texttt{f\_hnf}} for historical reasons \cite{pakcs}.

An expression in our compiled code is a rooted labeled graph.
nodes\index{\texttt{node}} in the graph are given the definition in figure \ref{fig:node}.

\begin{figure}
\begin{tabbing}\ttfamily
~typedef~struct~Node\\
\ttfamily ~\char123{}\\
\ttfamily ~~~~~int~missing\char59{}\\
\ttfamily ~~~~~bool~nondet\char59{}\\
\ttfamily ~~~~~Symbol\char42{}~symbol\char59{}\\
\ttfamily ~~~~~field~children\char91{}4\char93{}\char59{}\\
\ttfamily ~\char125{}~Node\char59{}
\end{tabbing}
\caption{Definition of a node.}
\label{fig:node}
\end{figure}

A \texttt{field}\index{\texttt{field}} is a union of a \texttt{Node*} and the representations
of the primitive types \texttt{Int}, \texttt{Float}, and \texttt{Char},
as well as a \texttt{field*} to be described shortly.
The use of fields instead of nodes for the children will be justified when we
discuss primitive values and unboxing in chapter \ref{ch:Memory Optimizations}
The \texttt{children}\index{\texttt{children}} field contains an array of children for this node.
If a node could have more than three children, such as a node representing
the \ensuremath{(,,,,,,)} constructor, then \texttt{children[3]} holds a pointer
to a variable length array that holds the rest of the children.
This leads to non-uniform indexing into nodes.
For example \texttt{n->children[1]} returns the second child of the node,
but the sixth child must be retrieved with \texttt{n->children[3].a[2]}.
We use a \texttt{child\_at} macro to simplify the code,
so \texttt{child\_at(n,5)} returns the sixth child.
The \texttt{symbol} field is a pointer to the static information
of the node.
This includes the name, arity, and \texttt{tag}\index{\texttt{tag}} for the node,
as well as a function pointer responsible for reducing the node to 
head constructor from.
We include a \texttt{TAG} macro to access the tag of a node.
This is purely for convenience.
For a node labeled by function \ensuremath{\Varid{f}}, this is a pointer to \texttt{f\_hnf}.
Because the calling convention is complicated, we hide this detail with an
\texttt{HNF} macro, so \texttt{HNF(f)} evaluated the node labeled by \ensuremath{\Varid{f}}
to head constructor from.
The \texttt{missing} field represents a partial function application.
If \texttt{missing} is greater than 0, then \texttt f is partially applied.
The \texttt{nondet} field represents the nondet marker described in the
fast backtracking algorithm.

Each function and constructor generates a \texttt{set} and \texttt{make} function.
For the \ensuremath{\Varid{not}} function, we would generate 

\begin{tabbing}\ttfamily
~void~set\char95{}not\char40{}field~root\char44{}~field~x\char41{}\char59{}\\
\ttfamily ~field~make\char95{}not\char40{}field~x\char41{}\char59{}
\end{tabbing}

The \texttt{set\_not} function sets the \texttt{root} parameter to be a \ensuremath{\Varid{not}} node.
This is accomplished by changing the symbol and children for \texttt{root}.
The \texttt{make\_not} function allocates memory for a new \ensuremath{\Varid{not}} node.



Each program in our language defines an expression \ensuremath{\Varid{main}},
and runs until \ensuremath{\Varid{main}} is evaluated to constructor normal form.
This evaluation is broken up into two pieces.
The primary driver of a program is the \texttt{nf} function,
which is responsible for evaluating the main expression to constructor normal form.
The \texttt{nf} function computes this form by first evaluating an expression to
head constructor form.
When an expression is in head constructor from, \texttt{nf} evaluates each subexpression
to constructor normal from, producing the loop in figure \ref{fig:nf}.

\begin{figure}
\begin{tabbing}\ttfamily
~void~nf\char40{}field~expr\char41{}\\
\ttfamily ~\char123{}\\
\ttfamily ~~~~~HNF\char40{}expr\char41{}\char59{}\\
\ttfamily ~\\
\ttfamily ~~~~~for\char40{}int~i~\char61{}~0\char59{}~i~\char60{}~expr\char46{}n\char45{}\char62{}symbol\char45{}\char62{}arity\char59{}~i\char43{}\char43{}\char41{}\\
\ttfamily ~~~~~\char123{}\\
\ttfamily ~~~~~~~~~nf\char40{}child\char95{}at\char40{}expr\char44{}~i\char41{}\char41{}\char59{}\\
\ttfamily ~~~~~\char125{}\\
\ttfamily ~\char125{}
\end{tabbing}
\caption{algorithm for reducing a node to constructor normal form.}
\label{fig:nf}
\end{figure}

All that's missing here is the \texttt{hnf} functions.
We give a simplified version of the \texttt{not\_hnf} function in \ref{fig:notInit},
and we will fill in details as we progress.

\begin{figure}
\begin{tabbing}\ttfamily
~void~Prelude\char95{}not\char95{}hnf\char40{}field~root\char41{}~\char123{}\\
\ttfamily ~~~field~x~\char61{}~child\char95{}at\char40{}root\char44{}~0\char41{}\char59{}\\
\ttfamily ~\\
\ttfamily ~~~field~scrutenee~\char61{}~x\char59{}\\
\ttfamily ~~~while\char40{}true\char41{}~\char123{}\\
\ttfamily ~~~~~switch\char40{}TAG\char40{}scrutenee\char41{}\char41{}~\char123{}\\
\ttfamily ~~~~~~~case~FAIL\char95{}TAG\char58{}\\
\ttfamily ~~~~~~~~~fail\char40{}root\char41{}\char59{}\\
\ttfamily ~~~~~~~~~return\char59{}\\
\ttfamily ~~~~~~~case~FORWARD\char95{}TAG\char58{}\\
\ttfamily ~~~~~~~~~scrutenee~\char61{}~child\char95{}at\char40{}scrutenee\char44{}0\char41{}\char59{}\\
\ttfamily ~~~~~~~~~break\char59{}\\
\ttfamily ~~~~~~~case~FUNCTION\char95{}TAG\char58{}\\
\ttfamily ~~~~~~~~~HNF\char40{}scrutenee\char41{}\char59{}\\
\ttfamily ~~~~~~~~~break\char59{}\\
\ttfamily ~~~~~~~case~Prelude\char95{}True\char95{}TAG\char58{}\\
\ttfamily ~~~~~~~~~set\char95{}Prelude\char95{}False\char40{}root\char44{}~0\char41{}\char59{}\\
\ttfamily ~~~~~~~~~return\char59{}\\
\ttfamily ~~~~~~~case~Prelude\char95{}False\char95{}TAG\char58{}\\
\ttfamily ~~~~~~~~~set\char95{}Prelude\char95{}True\char40{}root\char44{}~0\char41{}\char59{}\\
\ttfamily ~~~~~~~~~return\char59{}\\
\ttfamily ~~~~~\char125{}\\
\ttfamily ~~~\char125{}\\
\ttfamily ~\char125{}
\end{tabbing}
\caption{Initial implementation of \ensuremath{\Varid{not}}}
\label{fig:notInit}
\end{figure}

We can see that the main driver of this function is the \texttt{while(true)} loop.
The loop looks up the tag of \texttt x, and if it's a function tag, when we evaluate it to
head constructor form.
If the tag for \texttt x is \texttt{FAIL}, which represents an exempt node, then
we set the root to \texttt{FAIL} and return.
If the tag is \texttt{Prelude\_True} or \texttt{Prelude\_False},
we set the root to the corresponding expression, and return from the loop.
Finally, in order to implement collapsing functions, we introduce a \texttt{FORWARD} tag.
If the tag is \texttt{FORWARD}, then we traverse the forwarding chain,
and continue evaluating the \texttt x.

Finally, while we are evaluating the node stored in the local variable \texttt x,
we introduce a new variable \texttt{scrutenee}.
This is because if \texttt{x} evaluates to a forwarding node,
we need to evaluate the child of \texttt x.
If we were to update \texttt x, and then return an expression containing \texttt x
later, then we would have compressed the forwarding path.
As mentioned previously, this is not valid.

At this point we have a strategy for how to compile first order deterministic Curry functions.
Next we show how we handle partial application and higher order functions.

\subsection{Higher Order Functions} \label{Higher Order Functions C}

Earlier we gave an interpretation of how to handle \ensuremath{\Varid{apply}} nodes,
but there are still a few details to work out.
Recall the semantics we gave for apply nodes:
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{4}{@{}>{\hspre}l<{\hspost}@{}}%
\column{14}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{apply}\;\Varid{f}_{\Varid{k}}\;[\mskip1.5mu \Varid{x}_{\mathrm{1}},\ldots \Varid{x}_{\Varid{n}}\mskip1.5mu]{}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mid \Varid{k}\mathbin{>}\Varid{n}{}\<[14]%
\>[14]{}\mathrel{=}f_{k-n}\;\Varid{x}_{\mathrm{1}}\ldots \Varid{x}_{\Varid{n}}{}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mid \Varid{k}\Varid{==}\Varid{n}{}\<[14]%
\>[14]{}\mathrel{=}\Varid{f}\;\Varid{x}_{\mathrm{1}}\ldots \Varid{x}_{\Varid{n}}{}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mid \Varid{k}\mathbin{<}\Varid{n}{}\<[14]%
\>[14]{}\mathrel{=}\Varid{apply}\;(\Varid{f}\;\Varid{x}_{\mathrm{1}}\ldots \Varid{x}_{\Varid{k}})\;[\mskip1.5mu x_{k+1},\ldots \Varid{x}_{\Varid{n}}\mskip1.5mu]{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
If \ensuremath{\Varid{f}} is missing any arguments, then we call \ensuremath{\Varid{f}} a partial application.
Let's look at a concrete example.
In the expression \ensuremath{foldr_2\;(+_2)}, \ensuremath{\Varid{foldr}} is a partial application that is missing 2 arguments.
We will write this as \ensuremath{\Varid{foldr}\;(+_2)\bullet \bullet } where \ensuremath{\bullet } denotes a missing argument.
Now, suppose that we want to apply the following expression.

\Tree[.\ensuremath{\Varid{apply}} [.\ensuremath{\Varid{foldr}} \ensuremath{\mathbin{+}} \ensuremath{\bullet } \ensuremath{\bullet } ] \ensuremath{\mathrm{0}} [.\ensuremath{\mathbin{:}} \ensuremath{\mathrm{1}} \ensuremath{\ldots } ] ]

Remember that each node represents either a function or a constructor,
and each node has a fixed arity.
For example, \ensuremath{\mathbin{+}} has an arity of 2, and \ensuremath{\Varid{foldr}} has an arity of 3.
This is true for every \ensuremath{\mathbin{+}} or \ensuremath{\Varid{foldr}} node we encounter.
However, it's not true for \ensuremath{\Varid{apply}} nodes.
In fact, an \ensuremath{\Varid{apply}} node may have any positive arity.
Furthermore, by definition, an \ensuremath{\Varid{apply}} node can't be missing any arguments.
For this reason, we use the \texttt{missing}\index{\texttt{missing}} field to hold the number of 
arguments the node is applied
to.\footnote{In reality we set missing to the 
             negative value of the arity to distinguish an 
             apply node from a partial application.}


The algorithm for reducing apply nodes is straightforward, but brittle.
There are several easy mistakes to make here.
The major problem with function application is getting the arguments in the correct positions.
To help alleviate this problem we make a non-obvious change to the structure of nodes.
We store the arguments in reverse order.
To see why this is helpful, let's consider the \ensuremath{\Varid{foldr}} example above.
But this time, let's decompose it into 3 apply nodes, so we have 
\ensuremath{\Varid{apply}\;(\Varid{apply}\;(\Varid{apply}\;foldr_3\;(+_2))\;\mathrm{0})\;[\mskip1.5mu \mathrm{1},\mathrm{2},\mathrm{3}\mskip1.5mu]}.
In our innermost apply node, which will be evaluated first, we apply \ensuremath{foldr_3} to \ensuremath{+_2} to get
\ensuremath{foldr_2\;(+_2)\bullet \bullet }.
This is straightforward.
We simply put \ensuremath{\mathbin{+}} as the first child.
However, when we apply \ensuremath{foldr_2\;(+_2)\bullet \bullet } to \ensuremath{\mathrm{0}}, we need to put \ensuremath{\mathrm{0}} in the second child slot.
In general, when we apply an arbitrary partial application \ensuremath{\Varid{f}} to \ensuremath{\Varid{x}}, what child do we put \ensuremath{\Varid{x}} in?
Well, if we're storing the arguments in reverse order, then we get a really handy result.
Given function \ensuremath{\Varid{f}_{\Varid{k}}} that is missing \ensuremath{\Varid{k}} arguments, then \ensuremath{\Varid{apply}\;\Varid{f}_{\Varid{k}}\;\Varid{x}} reduces to \ensuremath{f_{k-1}\;\Varid{x}} where \ensuremath{\Varid{x}}
is the \ensuremath{\Varid{k}\mathbin{-}\mathrm{1}} child.
The missing value for a function tells us exactly where to put the arguments.
This is completely independent of the arity of the function.\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{apply}\;(\Varid{apply}\;(\Varid{apply}\;(foldr_3\bullet \bullet \bullet )\;(+_2))\;\mathrm{0})\;[\mskip1.5mu \mathrm{1},\mathrm{2},\mathrm{3}\mskip1.5mu]{}\<[E]%
\\
\>[3]{}\Rightarrow \Varid{apply}\;(\Varid{apply}\;(foldr_2\bullet \bullet (+_2))\;\mathrm{0})\;[\mskip1.5mu \mathrm{1},\mathrm{2},\mathrm{3}\mskip1.5mu]{}\<[E]%
\\
\>[3]{}\Rightarrow \Varid{apply}\;(foldr_1\bullet \mathrm{0}\;(+_2))\;[\mskip1.5mu \mathrm{1},\mathrm{2},\mathrm{3}\mskip1.5mu]{}\<[E]%
\\
\>[3]{}\Rightarrow foldr_0\;[\mskip1.5mu \mathrm{1},\mathrm{2},\mathrm{3}\mskip1.5mu]\;\mathrm{0}\;(+_2)){}\<[E]%
\ColumnHook
\end{hscode}\resethooks

The algorithm is given in figure \ref{fig:apply}.
There are a few more complications to point out.
To avoid complications, we assume arguments that a function is being applied to are stored in the
array at \texttt{children[3]} of the apply node.
That gives us the structure \ensuremath{\Varid{apply}\;\Varid{f}\bullet \bullet \Varid{a}_{\Varid{n}}\ldots \Varid{a}_{\mathrm{1}}}.
This isn't done in the runtime system because it would be inefficient,
but it simplifies the code for this presentation.
We also make use of the \texttt{set\_child\_at} macro, which simplifies setting child nodes
and is similar to \texttt{child\_at}.
Finally, the loop to put the partial function in head constructor form uses
\texttt{while(f.n->missing <= 0)} instead of \texttt{while(true)}.
This is because our normal form is a partial application, which does not have its own tag.

We reduce an apply node in two steps.
First get the function \texttt f, which is the first child of an apply node.
Then, reduce it to a partial application.
If \texttt f came from a non-deterministic expression, the save the apply node on the stack.
We split the second step into two cases.
If \texttt f is under applied, or has exactly the right number of arguments,
then copy the contents of \texttt f into the root, and move the arguments over and reduce.
If \texttt f is over applied, then make a new copy of \texttt f,
and copy arguments into it until it's fully applied.
Finally we reduce the fully applied copy of \texttt f and apply the rest of the arguments.

\begin{figure}
\begin{tabbing}\ttfamily
~void~apply\char95{}hnf\char40{}field~root\char41{}~\char123{}\\
\ttfamily ~~~~~field~f~\char61{}~child\char95{}at\char40{}root\char44{}0\char41{}\char59{}\\
\ttfamily ~~~~~field\char42{}~children~\char61{}~root\char46{}n\char45{}\char62{}children\char91{}3\char93{}\char46{}a\char59{}\\
\ttfamily ~~~~~while\char40{}f\char46{}n\char45{}\char62{}missing~\char60{}\char61{}~0\char41{}~\char123{}\\
\ttfamily ~~~~~~~~~\char47{}\char47{}~Normal~HNF~loop\\
\ttfamily ~~~~~\char125{}\\
\ttfamily ~~~~~int~nargs~\char61{}~\char45{}root\char46{}n\char45{}\char62{}missing\char59{}\\
\ttfamily ~~~~~int~missing~\char61{}~f\char46{}n\char45{}\char62{}missing\char59{}\\
\ttfamily ~~~~~if\char40{}missing~\char60{}\char61{}~nargs\char41{}~\char123{}\\
\ttfamily ~~~~~~~~~set\char95{}copy\char40{}root\char44{}~f\char41{}\char59{}\\
\ttfamily ~~~~~~~~~for\char40{}int~i~\char61{}~nargs\char59{}~i~\char62{}~0\char59{}~i\char45{}\char45{}\char44{}~missing\char45{}\char45{}\char41{}~\char123{}\\
\ttfamily ~~~~~~~~~~~~~set\char95{}child\char95{}at\char40{}root\char44{}~missing\char45{}1\char44{}~children\char91{}i\char45{}1\char93{}\char41{}\char59{}\\
\ttfamily ~~~~~~~~~\char125{}\\
\ttfamily ~~~~~~~~~root\char46{}n\char45{}\char62{}missing~\char61{}~missing\char59{}\\
\ttfamily ~~~~~~~~~if\char40{}missing~\char61{}\char61{}~0\char41{}~\char123{}\\
\ttfamily ~~~~~~~~~~~~~HNF\char40{}root\char41{}\char59{}\\
\ttfamily ~~~~~~~~~\char125{}\\
\ttfamily ~~~~~\char125{}~else~\char123{}\\
\ttfamily ~~~~~~~~~field~newf~\char61{}~copy\char40{}f\char41{}\char59{}\\
\ttfamily ~~~~~~~~~while\char40{}missing~\char62{}~0\char41{}~\char123{}\\
\ttfamily ~~~~~~~~~~~~~set\char95{}child\char95{}at\char40{}newf\char44{}~missing\char45{}1\char44{}~children\char91{}nargs\char45{}1\char93{}\char41{}\char59{}\\
\ttfamily ~~~~~~~~~~~~~nargs\char45{}\char45{}\char59{}\\
\ttfamily ~~~~~~~~~~~~~missing\char45{}\char45{}\char59{}\\
\ttfamily ~~~~~~~~~\char125{}\\
\ttfamily ~~~~~~~~~newf\char46{}n\char45{}\char62{}missing~\char61{}~0\char59{}\\
\ttfamily ~~~~~~~~~HNF\char40{}newf\char41{}\char59{}\\
\ttfamily ~~~~~~~~~set\char95{}child\char95{}at\char40{}root\char44{}0\char44{}newf\char41{}\char59{}\\
\ttfamily ~~~~~~~~~root\char46{}n\char45{}\char62{}missing~\char61{}~\char45{}nargs\char59{}\\
\ttfamily ~~~~~~~~~apply\char95{}hnf\char40{}root\char41{}\char59{}\\
\ttfamily ~~~~~\char125{}\\
\ttfamily ~\char125{}
\end{tabbing}
\caption{The \texttt{apply\_hnf}  function}
\label{fig:apply}
\end{figure}


\subsection{Implementing Non-determinism} \label{Implementing Non-determinism}

Now, we that we can reduce a higher order functional language,
we would like to extend our implementation to handle features from logic languages.

The implementation doesn't change too much.
First we add two new tags \texttt{CHOICE} and \texttt{FREE}
to represent non-deterministic choice and free variable nodes respectively.
The choice nodes are treated in a similar manner to a function.
We call the \texttt{choose} function to reduce a choice to HCF,
and push the alternative on the stack.

The choose function in \ref{fig:choose} reduces a choice node to head constructor form.
Since choice is a collapsing rule, we return a forwarding node.
The function is also responsible for keeping track of which branch of the choice we should reduce,
and pushing the alternative on the backtracking stack.
We accomplish this by keeping a marker in the second child of a choice node.
This marker is 0 if we should reduce to the left hand side, and 1 if we should reduce to the righ
hand side.

\begin{figure}
\begin{tabbing}\ttfamily
~void~choose\char40{}field~root\char41{}\\
\ttfamily ~\char123{}\\
\ttfamily ~~~~~field~choices\char91{}2\char93{}~\char61{}~\char123{}child\char95{}at\char40{}root\char44{}0\char41{}\char44{}~child\char95{}at\char40{}root\char44{}1\char41{}\char125{}\char59{}\\
\ttfamily ~~~~~int~side~\char61{}~child\char95{}at\char40{}root\char44{}2\char41{}\char46{}i\char59{}\\
\ttfamily ~\\
\ttfamily ~~~~~field~saved\char59{}\\
\ttfamily ~~~~~saved\char46{}n~\char61{}~\char40{}Node\char42{}\char41{}alloc\char40{}sizeof\char40{}Node\char41{}\char41{}\char59{}\\
\ttfamily ~~~~~memcpy\char40{}saved\char46{}n\char44{}~root\char46{}n\char44{}~sizeof\char40{}Node\char41{}\char41{}\char59{}\\
\ttfamily ~\\
\ttfamily ~~~~~child\char95{}at\char95{}i\char40{}saved\char44{}2\char41{}~\char61{}~\char33{}side\char59{}\\
\ttfamily ~~~~~stack\char95{}push\char40{}bt\char95{}stack\char44{}~root\char44{}~saved\char44{}~side~\char61{}\char61{}~0\char41{}\char59{}\\
\ttfamily ~\\
\ttfamily ~~~~~set\char95{}forward\char40{}root\char44{}choices\char91{}side\char93{}\char41{}\char59{}\\
\ttfamily ~~~~~root\char46{}n\char45{}\char62{}nondet~\char61{}~true\char59{}\\
\ttfamily ~\\
\ttfamily ~\char125{}
\end{tabbing}
\caption{Implementation of the \texttt{choose} function.}
\label{fig:choose}
\end{figure}

Free variables are more interesting.
To narrow a free variable we pick a possible constructor,
and replace the \texttt{scrutinee} node with that constructor.
All arguments to the constructor are instantiated with free variables.
Then, we push a rewrite on the stack to replace \texttt{scrutinee} with a free variable
using the \texttt{push\_frame} function.
This is because after each possible choice has been exhausted, we want to reset
this node back to a free variable in case it is used in another non-deterministic branch
of the computation.
Finally, for every other constructor, we push an alternative on the backtracking stack
using the \texttt{push\_choice} function.

The only other necessary change is to push a rewrite onto the backtracking stack
when we reach either a fail, or constructor case.
The \texttt{Prelude\_not\_1} function is a function at a case expression discussed
in section \ref{Non-determinism}.
The changes to the \ensuremath{\Varid{not}} function are give in figure \ref{fig:notNondet}.
Due to space constraints not all sections are show.
The pieces of code that don't changed are omitted and replaced with \texttt{...}.

\begin{figure}
\begin{tabbing}\ttfamily
~void~Prelude\char95{}not\char95{}hnf\char40{}field~root\char41{}~\char123{}\\
\ttfamily ~~~field~x~\char61{}~child\char95{}at\char40{}root\char44{}~0\char41{}\char59{}\\
\ttfamily ~~~field~scrutenee~\char61{}~x\char59{}\\
\ttfamily ~~~while\char40{}true\char41{}~\char123{}\\
\ttfamily ~~~~~switch\char40{}TAG\char40{}scrutenee\char41{}\char41{}~\char123{}\\
\ttfamily ~~~~~~~case~FAIL\char95{}TAG\char58{}\\
\ttfamily ~~~~~~~~~push\char95{}frame\char40{}root\char44{}~make\char95{}Prelude\char95{}not\char95{}1\char40{}x\char41{}\char41{}\char59{}\\
\ttfamily ~~~~~~~~~fail\char40{}root\char41{}\char59{}\\
\ttfamily ~~~~~~~~~return\char59{}\\
\ttfamily ~~~~~~~\char46{}\char46{}\char46{}\\
\ttfamily ~~~~~~~case~CHOICE\char95{}TAG\char58{}\\
\ttfamily ~~~~~~~~~choose\char40{}scrutenee\char41{}\char59{}\\
\ttfamily ~~~~~~~~~break\char59{}\\
\ttfamily ~~~~~~~case~FREE\char95{}TAG\char58{}\\
\ttfamily ~~~~~~~~~push\char40{}bt\char95{}stack\char40{}free\char95{}var\char40{}\char41{}\char41{}choose\char40{}scrutenee\char41{}\char59{}\\
\ttfamily ~~~~~~~~~push\char95{}frame\char40{}scrutenee\char44{}~free\char95{}var\char40{}\char41{}\char41{}\char59{}\\
\ttfamily ~~~~~~~~~push\char95{}choice\char40{}scrutenee\char44{}~make\char95{}Prelude\char95{}False\char40{}0\char41{}\char41{}\char59{}\\
\ttfamily ~~~~~~~~~set\char95{}Prelude\char95{}True\char40{}scrutenee\char44{}~0\char41{}\char59{}\\
\ttfamily ~~~~~~~~~break\char59{}\\
\ttfamily ~~~~~~~case~Prelude\char95{}True\char95{}TAG\char58{}\\
\ttfamily ~~~~~~~~~push\char95{}frame\char40{}root\char44{}~make\char95{}Prelude\char95{}not\char95{}1\char40{}x\char41{}\char41{}\char59{}\\
\ttfamily ~~~~~~~~~set\char95{}Prelude\char95{}False\char40{}root\char44{}~0\char41{}\char59{}\\
\ttfamily ~~~~~~~~~return\char59{}\\
\ttfamily ~~~~~~~\char46{}\char46{}\char46{}\\
\ttfamily ~~~~~\char125{}\\
\ttfamily ~~~\char125{}\\
\ttfamily ~\char125{}
\end{tabbing}
\caption{Implementation of \ensuremath{\Varid{not}} with possible non-deterministic values.}
\label{fig:notNondet}
\end{figure}


\subsection{Fast Backtracking} \label{Fast Backtracking}

Finally we show how we implement the fast backtracking technique described earlier.
The implementation actually doesn't change much,
we simply make use of the \texttt{nondet} flag in each node.
While we're evaluating \texttt{scrutinee},
we keep track of whether or not we've seen
a non-deterministic node in a local variable, and if we have, we push
the root on the backtracking stack.
If we haven't seen a non-deterministic node,
then we can simply avoid pushing this rewrite.
The generated code for \ensuremath{\Varid{not}} is given in figure \ref{fig:notFull}.

\begin{figure}
\begin{tabbing}\ttfamily
~void~Prelude\char95{}not\char95{}hnf\char40{}field~root\char41{}~\char123{}\\
\ttfamily ~~~field~x~\char61{}~child\char95{}at\char40{}root\char44{}~0\char41{}\char59{}\\
\ttfamily ~~~field~scrutenee~\char61{}~x\char59{}\\
\ttfamily ~~~bool~nondet~\char61{}~false\char59{}\\
\ttfamily ~~~while\char40{}true\char41{}~\char123{}\\
\ttfamily ~~~~~nondet~\char124{}\char61{}~scrutenee\char45{}\char62{}nondet\char59{}\\
\ttfamily ~~~~~switch\char40{}TAG\char40{}scrutenee\char41{}\char41{}~\char123{}\\
\ttfamily ~~~~~~~case~FAIL\char95{}TAG\char58{}\\
\ttfamily ~~~~~~~~~if\char40{}nondet\char41{}~push\char95{}frame\char40{}root\char44{}~make\char95{}Prelude\char95{}not\char95{}1\char40{}x\char41{}\char41{}\char59{}\\
\ttfamily ~~~~~~~~~fail\char40{}root\char41{}\char59{}\\
\ttfamily ~~~~~~~~~return\char59{}\\
\ttfamily ~\\
\ttfamily ~~~~~~~\char46{}\char46{}\char46{}\\
\ttfamily ~~~~~~~case~CHOICE\char95{}TAG\char58{}\\
\ttfamily ~~~~~~~~~choose\char40{}scrutenee\char41{}\char59{}\\
\ttfamily ~~~~~~~~~nondet~\char61{}~true\char59{}\\
\ttfamily ~~~~~~~~~break\char59{}\\
\ttfamily ~~~~~~~case~FREE\char95{}TAG\char58{}\\
\ttfamily ~~~~~~~~~push\char95{}frame\char40{}scrutenee\char44{}~free\char95{}var\char40{}\char41{}\char41{}\char59{}\\
\ttfamily ~~~~~~~~~push\char95{}choice\char40{}scrutenee\char44{}~make\char95{}Prelude\char95{}False\char40{}0\char41{}\char41{}\char59{}\\
\ttfamily ~~~~~~~~~set\char95{}Prelude\char95{}True\char40{}scrutenee\char44{}~0\char41{}\char59{}\\
\ttfamily ~~~~~~~~~nondet~\char61{}~true\char59{}\\
\ttfamily ~~~~~~~~~break\char59{}\\
\ttfamily ~~~~~~~case~Prelude\char95{}True\char95{}TAG\char58{}\\
\ttfamily ~~~~~~~~~if\char40{}nondet\char41{}~push\char95{}frame\char40{}root\char44{}~make\char95{}Prelude\char95{}not\char95{}1\char40{}x\char41{}\char41{}\char59{}\\
\ttfamily ~~~~~~~~~set\char95{}Prelude\char95{}False\char40{}root\char44{}~0\char41{}\char59{}\\
\ttfamily ~~~~~~~~~return\char59{}\\
\ttfamily ~\\
\ttfamily ~~~~~~~\char46{}\char46{}\char46{}\\
\ttfamily ~~~~~\char125{}\\
\ttfamily ~~~\char125{}\\
\ttfamily ~\char125{}
\end{tabbing}
\caption{The full implementation of \ensuremath{\Varid{not}}.}
\label{fig:notFull}
\end{figure}

In the last two chapters we've discussed the choices we've made with 
our generated code, and given an idea with what the generated code should look like.
In some sense, we've given a recipe of how to translate Curry into C.
In the next chapter we introduce the tools to make this recipe.
We introduce a system for implementing transformations as rewrite rules.
We then show how this system can simplify the construction of a compiler,
and use it to transform FlatCurry programs into a form that is easier to optimize and compile to C.




\chapter{Generating and Altering Subexpressions} \label{ch:Generating and Altering Subexpressions}


In this chapter we introduce our engine for Generating and Altering Subexpressions, of the GAS system.
This system proves to be incredibly versatile and is the main workhorse of the compiler and optimizer.
We show how to construct, combine, and improve the efficiency of transformations,
as well as how the system in implemented.



\section{Building Optimizations}

Throughout this dissertation we look at the process of developing compiler optimizations.
For our purposes we are concerned with 
\emph{compile time optimizations}\index{compile time optimizations}.
These are transformations on a program, performed at compile time,
that are intended to produce more efficient code.
Most research in the Curry community has been done on \emph{run time optimizations}
\index{run time optimizations}, which are improvements to the evaluation of Curry programs.
This can include the development of new rewriting strategies, or improvements to
pull-tabbing and bubbling \cite{sprite,bubblingPractical}.
These improvements are important, but they are not our concern for this compiler.

Developing compile time optimizations is usually considered 
the most difficult aspect of writing a modern compiler.
It's easy to see why.
There are dozens of small optimizations to make, 
and each one needs to be written, shown correct, and tested.

Furthermore, there are several levels where an optimization can be applied.
Some optimizations apply to a programs AST, some to another intermediate representation,
some to the generated code, and even some to the runtime system.
There are even optimizations that are applied during transformations between representations.
For this chapter, we will be describing a system to apply optimizations to FlatCurry programs.
While this is not the only area of the compiler where we applied optimizations,
it is by far the most extensive, so it's worth understanding how our optimization engine works.

Generally speaking, most optimizations have the same structure.
Find an area in the AST where the optimization applies, and then replace it with the optimized version.
As an example, consider the code for the absolute value function defined below.
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{4}{@{}>{\hspre}l<{\hspost}@{}}%
\column{17}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{abs}\;\Varid{x}{}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mid \Varid{x}\mathbin{<}\mathrm{0}{}\<[17]%
\>[17]{}\mathrel{=}\mathbin{-}\Varid{x}{}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mid \Varid{otherwise}{}\<[17]%
\>[17]{}\mathrel{=}\Varid{x}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
This will be translated into FlatCurry as
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{17}{@{}>{\hspre}l<{\hspost}@{}}%
\column{24}{@{}>{\hspre}l<{\hspost}@{}}%
\column{33}{@{}>{\hspre}l<{\hspost}@{}}%
\column{40}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{abs}\;\Varid{x}\mathrel{=}\mathbf{case}\;{}\<[17]%
\>[17]{}(\Varid{x}\mathbin{<}\mathrm{0})\;\mathbf{of}{}\<[E]%
\\
\>[17]{}\Conid{True}{}\<[24]%
\>[24]{}\to \mathbin{-}\Varid{x}{}\<[E]%
\\
\>[17]{}\Conid{False}{}\<[24]%
\>[24]{}\to \mathbf{case}\;{}\<[33]%
\>[33]{}\Varid{otherwise}\;\mathbf{of}{}\<[E]%
\\
\>[33]{}\Conid{True}{}\<[40]%
\>[40]{}\to \Varid{x}{}\<[E]%
\\
\>[33]{}\Conid{False}{}\<[40]%
\>[40]{}\to \bot {}\<[E]%
\ColumnHook
\end{hscode}\resethooks
While this transformation is obviously inefficient, 
it is general and has a straightforward implementation.
A good optimizer should be able to recognize that \ensuremath{\Varid{otherwise}} reduces to \ensuremath{\Conid{True}},
and reduce the case-expression.
So for this one example, we have two different optimizations we need to implement.
We need to reduce \ensuremath{\Varid{otherwise}} to \ensuremath{\Conid{True}}, then we can reduce the second case expression to \ensuremath{\Varid{x}}.

There are two common approaches to solving this problem.
The first is to make a separate function for each optimization.
Each function will traverse the AST and try to apply its optimization.
The second option is to make a few large functions that attempt to apply several optimizations at once.
There are trade-offs for each.

The first option has the advantage that each optimization is easy to write and understand.
However, is suffers from a lot of code duplication,
and it's not very efficient.  We must traverse the entire AST every time we want to apply an optimization.
Both LLVM and the JVM fall into this category \cite{llvm, jvm}.
The second option is more efficient, and there is less code duplication,
but it leads to large functions that are difficult to maintain or extend.

Using these two options generally leads to optimizers that are difficult to maintain.
To combat this problem, many compilers will provide a language to describe optimization transformation.
Then the compiler writer can use this domain specific language to develop their optimizations.
With the optimization descriptions, the compiler can search the AST of a program to find
any places where optimizations apply.
However, it is difficult or impossible to write many common optimizations in this style \cite{playingByTheRules}.

The aim of our solution is to try to get the best of all three worlds.
We've developed an approach to simplify Generating and Altering Subexpressions (GAS)
\index{Generating and Altering Subexpressions (GAS)}.
Our approach was to do optimization entirely by rewriting.
This has several advantages, and might be the most useful result of this work.
First, developing new optimizations is simple.
We can write down new optimizations in this system within minutes.
It was often easier to write down the optimization and test it,
than it was to try to describe the optimization in English.
Second, any performance improvement we made to the optimization engine
would apply to every optimization.
Third, optimizations were easy to maintain and extend.
If one optimization didn't work, we could look at it and test it in isolation.
Fourth, this code is much smaller than a traditional optimizer.
This isn't really a fair comparison given the relative immaturity of our compiler,
but we were able to implement 16 optimizations and code transformations in under 150 lines of code.
This gives a sense of scale of how much easier it is to implement optimizations in this system.
Fifth, Since We're optimizing by rewrite rules,
the compiler can easily output what rule was used,
and the position where it was used.
This is enough information to entirely reconstruct the optimization derivation.
We found this very helpful in debugging.
Finally, optimizations are written in Curry.
We didn't need to develop a DSL to describe the optimizations,
and there are no new ideas for programmers to learn if they want to extend the compiler.

We should note that there are some potential disadvantages to the GAS system as well.
The first disadvantage is that there are some optimizations and transformations
that are not easily described by rewriting.
The second is that, while we've improved the efficiency of the algorithm considerably,
it still takes longer to optimize programs then we'd like.

The first problem isn't really a problem at all.
If there is an optimization that doesn't lend itself well to rewriting,
we can always write it as a traditional optimization.
Furthermore, as we'll see later, we don't have to stay strictly in the bounds of rewriting.
The second problem is actually more fundamental to Curry.
Our implementation relies on finding a single value from a set generated by a non-deterministic function.
Current implementations are inefficient, but there are new implementations being developed
\cite{synthesizedSetFunctions}.
We also believe that an optimizing compiler would help with this problem \cite{this}.

\subsection{The Structure of an Optimization}

The goal with GAS is to make optimizations simple to implement and easily readable.
While this is a challenging problem, we can actually leverage Curry here.
Remember that the semantics of Curry are already non-deterministic rewriting.

Each optimization is going to be a function from a FlatCurry expression to another FlatCurry expression.
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{type}\;\Conid{Opt}\mathrel{=}\Conid{Expr}\to \Conid{Expr}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
For readability we use the FlatCurry syntax defined in figure \ref{fig:flatSyntax},
While this version of FlatCurry is easier to read,
we will need the actual representation of FlatCurry programs to implement the compiler.
This representation is given in figure \ref{fig:flatRep}, and the transformation
from the FlatCurry syntax to the FlatCurry representation is given in figure \ref{fig:flatTranslate}.
We can describe an optimization by simply describing what it does to each expression.
As an example consider the definition for floating let-expressions:

\begin{figure}
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{5}{@{}>{\hspre}l<{\hspost}@{}}%
\column{14}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{type}\;\Conid{QName}\mathrel{=}(\Conid{String},\Conid{String}){}\<[E]%
\\
\>[3]{}\mathbf{type}\;\Conid{Arity}\mathrel{=}\Conid{Int}{}\<[E]%
\\
\>[3]{}\mathbf{type}\;\Conid{VarIndex}\mathrel{=}\Conid{Int}{}\<[E]%
\\
\>[3]{}\mathbf{data}\;\Conid{Visibility}\mathrel{=}\Conid{Public}\mid \Conid{Private}{}\<[E]%
\\[\blanklineskip]%
\>[3]{}\mathbf{data}\;\Conid{FuncDecl}\mathrel{=}\Conid{Func}\;\Conid{QName}\;\Conid{Arity}\;\Conid{Rule}{}\<[E]%
\\
\>[3]{}\mathbf{data}\;\Conid{Rule}{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mathrel{=}\Conid{Rule}\;[\mskip1.5mu \Conid{VarIndex}\mskip1.5mu]\;\Conid{Expr}{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mid \Conid{External}\;\Conid{String}{}\<[E]%
\\
\>[3]{}\mathbf{data}\;\Conid{CombType}\mathrel{=}\Conid{FuncCall}\mid \Conid{ConsCall}\mid \Conid{FuncPartCall}\;\Conid{Arity}\mid \Conid{ConsPartCall}\;\Conid{Arity}{}\<[E]%
\\
\>[3]{}\mathbf{data}\;\Conid{Expr}{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mathrel{=}\Conid{Var}\;\Conid{VarIndex}{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mid \Conid{Lit}\;\Conid{Literal}{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mid \Conid{Comb}\;\Conid{CombType}\;\Conid{QName}\;[\mskip1.5mu \Conid{Expr}\mskip1.5mu]{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mid \Conid{Let}\;[\mskip1.5mu (\Conid{VarIndex},\Conid{Expr})\mskip1.5mu]\;\Conid{Expr}{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mid \Conid{Free}\;[\mskip1.5mu \Conid{VarIndex}\mskip1.5mu]\;\Conid{Expr}{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mid \Conid{Or}\;\Conid{Expr}\;\Conid{Expr}{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mid \Conid{Case}\;\Conid{Expr}\;[\mskip1.5mu \Conid{BranchExpr}\mskip1.5mu]{}\<[E]%
\\
\>[3]{}\mathbf{data}\;\Conid{BranchExpr}\mathrel{=}\Conid{Branch}\;\Conid{Pattern}\;\Conid{Expr}{}\<[E]%
\\
\>[3]{}\mathbf{data}\;\Conid{Pattern}{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mathrel{=}\Conid{Pattern}\;\Conid{QName}\;[\mskip1.5mu \Conid{VarIndex}\mskip1.5mu]{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mid \Conid{LPattern}\;\Conid{Literal}{}\<[E]%
\\
\>[3]{}\mathbf{data}\;\Conid{Literal}{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mathrel{=}\Conid{Intc}\;{}\<[14]%
\>[14]{}\Conid{Int}{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mid \Conid{Floatc}\;\Conid{Float}{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mid \Conid{Charc}\;{}\<[14]%
\>[14]{}\Conid{Char}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\caption{Curry representation of FlatCurry programs\\
This is the standard representation of FlatCurry programs as defined in \cite{currySemantics},
We have removed \ensuremath{\Conid{CaseType}} and \ensuremath{\Conid{Typed}} from \ensuremath{\Conid{Expr}}, and 
\ensuremath{\Conid{TypeExpr}} and \ensuremath{\Conid{Visibility}} from \ensuremath{\Conid{FuncDecl}}, because they are not used in our translation.}
\label{fig:flatRep}
\end{figure}

\begin{figure}
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{12}{@{}>{\hspre}l<{\hspost}@{}}%
\column{20}{@{}>{\hspre}l<{\hspost}@{}}%
\column{25}{@{}>{\hspre}l<{\hspost}@{}}%
\column{34}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\llbracket \Varid{f}\;\{\mskip1.5mu \Varid{v}\mskip1.5mu\}\mathrel{=}\Varid{e}\rrbracket {}\<[34]%
\>[34]{}\mathrel{=}\Conid{FuncDecl}\;\Varid{f}\;\Varid{n}\;(\Conid{Rule}\;[\mskip1.5mu \{\mskip1.5mu \Varid{v}\mskip1.5mu\}\mskip1.5mu]\;\llbracket \Varid{e}\rrbracket ){}\<[E]%
\\
\>[3]{}\ {}\<[E]%
\\
\>[3]{}\llbracket \Varid{v}\rrbracket {}\<[34]%
\>[34]{}\mathrel{=}\Conid{Var}\;\Varid{v}{}\<[E]%
\\
\>[3]{}\llbracket \Varid{l}\rrbracket {}\<[34]%
\>[34]{}\mathrel{=}\Conid{Lit}\;\llbracket \Varid{l}\rrbracket {}\<[E]%
\\
\>[3]{}\llbracket \Varid{e}_{\mathrm{1}}\mathbin{?}\Varid{e}_{\mathrm{2}}\rrbracket {}\<[34]%
\>[34]{}\mathrel{=}\Conid{Or}\;\llbracket \Varid{e}_{\mathrm{1}}\rrbracket \;\llbracket \Varid{e}_{\mathrm{2}}\rrbracket {}\<[E]%
\\
\>[3]{}\llbracket \bot \rrbracket {}\<[34]%
\>[34]{}\mathrel{=}\Conid{Comb}\;\Conid{ConsCall}\;(\text{\ttfamily \char34 \char34},\text{\ttfamily \char34 FAIL\char34})\;[\mskip1.5mu \mskip1.5mu]{}\<[E]%
\\
\>[3]{}\llbracket \Varid{f}_{\Varid{k}}\;\{\mskip1.5mu \Varid{e}\mskip1.5mu\}\rrbracket {}\<[20]%
\>[20]{}\mid \Varid{k}\Varid{==}\mathrm{0}{}\<[34]%
\>[34]{}\mathrel{=}\Conid{Comb}\;\Conid{FuncCall}\;\Varid{f}\;[\mskip1.5mu \{\mskip1.5mu \llbracket \Varid{e}\rrbracket \mskip1.5mu\}\mskip1.5mu]{}\<[E]%
\\
\>[20]{}\mid \Varid{otherwise}{}\<[34]%
\>[34]{}\mathrel{=}\Conid{Comb}\;(\Conid{FuncPartCall}\;\Varid{k})\;\Varid{f}\;[\mskip1.5mu \{\mskip1.5mu \llbracket \Varid{e}\rrbracket \mskip1.5mu\}\mskip1.5mu]{}\<[E]%
\\
\>[3]{}\llbracket \Conid{C}_{\Varid{k}}\;\{\mskip1.5mu \Varid{e}\mskip1.5mu\}\rrbracket {}\<[20]%
\>[20]{}\mid \Varid{k}\Varid{==}\mathrm{0}{}\<[34]%
\>[34]{}\mathrel{=}\Conid{Comb}\;\Conid{ConsCall}\;\Varid{f}\;[\mskip1.5mu \{\mskip1.5mu \llbracket \Varid{e}\rrbracket \mskip1.5mu\}\mskip1.5mu]{}\<[E]%
\\
\>[20]{}\mid \Varid{otherwise}{}\<[34]%
\>[34]{}\mathrel{=}\Conid{Comb}\;(\Conid{ConsPartCall}\;\Varid{k})\;\Varid{f}\;[\mskip1.5mu \{\mskip1.5mu \llbracket \Varid{e}\rrbracket \mskip1.5mu\}\mskip1.5mu]{}\<[E]%
\\
\>[3]{}\llbracket \;\mathbf{let}\;\{\mskip1.5mu \Varid{v}\mathrel{=}\Varid{e}\mskip1.5mu\}\;\mathbf{in}\;\Varid{e'}\rrbracket {}\<[34]%
\>[34]{}\mathrel{=}\Conid{Let}\;[\mskip1.5mu \{\mskip1.5mu (\Varid{v},\llbracket \Varid{e}\rrbracket )\mskip1.5mu\}\mskip1.5mu]\;\llbracket \Varid{e'}\rrbracket {}\<[E]%
\\
\>[3]{}\llbracket \;\mathbf{let}\;\{\mskip1.5mu \Varid{v}\mskip1.5mu\}\;\textbf{free} \;\mathbf{in}\;\Varid{e}\rrbracket {}\<[34]%
\>[34]{}\mathrel{=}\Conid{Free}\;[\mskip1.5mu \{\mskip1.5mu \Varid{v}\mskip1.5mu\}\mskip1.5mu]\;\llbracket \Varid{e}\rrbracket {}\<[E]%
\\
\>[3]{}\llbracket \;\mathbf{case}\;\Varid{e}\;\mathbf{of}\;\Varid{alts}\rrbracket {}\<[34]%
\>[34]{}\mathrel{=}\Conid{Case}\;\Varid{e}\;\llbracket \Varid{alts}\rrbracket {}\<[E]%
\\
\>[3]{}\ {}\<[E]%
\\
\>[3]{}\llbracket \Varid{l}\to \Varid{e}\rrbracket {}\<[34]%
\>[34]{}\mathrel{=}\Conid{Branch}\;(\Conid{LPattern}\;\llbracket \Varid{l}\rrbracket )\;\llbracket \Varid{e}\rrbracket {}\<[E]%
\\
\>[3]{}\llbracket \Conid{C}\;\{\mskip1.5mu \Varid{v}\mskip1.5mu\}\to \Varid{e}\rrbracket {}\<[34]%
\>[34]{}\mathrel{=}\Conid{Branch}\;(\Conid{Pattern}\;\Conid{C}\;[\mskip1.5mu \{\mskip1.5mu \Varid{v}\mskip1.5mu\}\mskip1.5mu])\;\llbracket \Varid{e}\rrbracket {}\<[E]%
\\
\>[3]{}\ {}\<[E]%
\\
\>[3]{}\llbracket \Varid{l}\rrbracket {}\<[12]%
\>[12]{}\mid \Varid{isInt}\;\Varid{l}{}\<[25]%
\>[25]{}\mathrel{=}\Conid{Intc}\;\Varid{l}{}\<[E]%
\\
\>[12]{}\mid \Varid{isFloat}\;\Varid{l}{}\<[25]%
\>[25]{}\mathrel{=}\Conid{Floatc}\;\Varid{l}{}\<[E]%
\\
\>[12]{}\mid \Varid{isChar}\;\Varid{l}{}\<[25]%
\>[25]{}\mathrel{=}\Conid{Charc}\;\Varid{l}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\caption{Translation from FlatCurry syntax to the Curry representation of FlatCurry.}
\label{fig:flatTranslate}
\end{figure}


\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{float}\;(\Conid{Comb}\;\Varid{ct}\;\Varid{f}\;(\Varid{as}\plus [\mskip1.5mu \Conid{Let}\;\Varid{vs}\;\Varid{e}\mskip1.5mu]\plus \Varid{bs}))\mathrel{=}\Conid{Let}\;\Varid{vs}\;(\Conid{Comb}\;\Varid{ct}\;\Varid{f}\;(\Varid{as}\plus [\mskip1.5mu \Varid{e}\mskip1.5mu]\plus \Varid{bs})){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
This optimization tells us that, if an argument to a function application is a \ensuremath{\mathbf{let}} expression,
then we can move the let-expression outside.
This works for let-expressions, but what if there's a free variable declaration inside of a function?
Well, we can define that case with another rule.
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{44}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{float}\;(\Conid{Comb}\;\Varid{ct}\;\Varid{f}\;(\Varid{as}\plus [\mskip1.5mu \Conid{Let}\;\Varid{vs}\;\Varid{e}\mskip1.5mu]\plus \Varid{bs})){}\<[44]%
\>[44]{}\mathrel{=}\Conid{Let}\;\Varid{vs}\;(\Conid{Comb}\;\Varid{ct}\;\Varid{f}\;(\Varid{as}\plus [\mskip1.5mu \Varid{e}\mskip1.5mu]\plus \Varid{bs})){}\<[E]%
\\
\>[3]{}\Varid{float}\;(\Conid{Comb}\;\Varid{ct}\;\Varid{f}\;(\Varid{as}\plus [\mskip1.5mu \Conid{Free}\;\Varid{vs}\;\Varid{e}\mskip1.5mu]\plus \Varid{bs})){}\<[44]%
\>[44]{}\mathrel{=}\Conid{Free}\;\Varid{vs}\;(\Conid{Comb}\;\Varid{ct}\;\Varid{f}\;(\Varid{as}\plus [\mskip1.5mu \Varid{e}\mskip1.5mu]\plus \Varid{bs})){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
This is where the non-determinism comes in.
Suppose we have an expression:
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{f}\;(\mathbf{let}\;\Varid{x}\mathrel{=}\mathrm{1}\;\mathbf{in}\;\Varid{x})\;(\mathbf{let}\;\Varid{r}\;\textbf{free} \;\mathbf{in}\;\mathrm{2}){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
This could be matched by either rule.
The trick is that we don't care which rule matches, as long as they both do eventually.
This will be transformed into one of the following:
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;\Varid{r}\;\textbf{free} \;\mathbf{in}\;\mathbf{let}\;\Varid{x}\mathrel{=}\mathrm{1}\;\mathbf{in}\;\Varid{f}\;\Varid{x}\;\mathrm{2}{}\<[E]%
\\
\>[3]{}\mathbf{let}\;\Varid{x}\mathrel{=}\mathrm{1}\;\mathbf{in}\;\mathbf{let}\;\Varid{r}\;\textbf{free} \;\mathbf{in}\;\Varid{f}\;\Varid{x}\;\mathrm{2}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
Either of these options is acceptable.
In fact, we could remove the ambiguity by making our rules a confluent system,
as shown by the code below.
However, we will not worry about confluence for most optimizations.
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{44}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{float}\;(\Conid{Comb}\;\Varid{ct}\;\Varid{f}\;(\Varid{as}\plus [\mskip1.5mu \Conid{Let}\;\Varid{vs}\;\Varid{e}\mskip1.5mu]\plus \Varid{bs})){}\<[44]%
\>[44]{}\mathrel{=}\Conid{Let}\;\Varid{vs}\;(\Conid{Comb}\;\Varid{ct}\;\Varid{f}\;(\Varid{as}\plus [\mskip1.5mu \Varid{e}\mskip1.5mu]\plus \Varid{bs})){}\<[E]%
\\
\>[3]{}\Varid{float}\;(\Conid{Comb}\;\Varid{ct}\;\Varid{f}\;(\Varid{as}\plus [\mskip1.5mu \Conid{Free}\;\Varid{vs}\;\Varid{e}\mskip1.5mu]\plus \Varid{bs})){}\<[44]%
\>[44]{}\mathrel{=}\Conid{Free}\;\Varid{vs}\;(\Conid{Comb}\;\Varid{ct}\;\Varid{f}\;(\Varid{as}\plus [\mskip1.5mu \Varid{e}\mskip1.5mu]\plus \Varid{bs})){}\<[E]%
\\
\>[3]{}\Varid{float}\;(\Conid{Let}\;\Varid{vs}\;(\Conid{Free}\;\Varid{ws}\;\Varid{e})){}\<[44]%
\>[44]{}\mathrel{=}\Conid{Free}\;\Varid{ws}\;(\Conid{Let}\;\Varid{vs}\;\Varid{e}){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
Great, now we can make an optimization.
It was easy to write, but it's not a very complex optimization.
In fact, most optimizations we write won't be very complex.
The power of optimization comes from making small improvements several times.

Now that we can do simple examples, let's look at a more substantial transformation.
Let-expressions are deceptively complicated.
They allow us to make arbitrarily complex, mutually recursive, definitions.
However, most of the time a large let expression could be broken down into several small let expressions.
Consider the definition below:\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{8}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;{}\<[8]%
\>[8]{}\Varid{a}\mathrel{=}\Varid{b}{}\<[E]%
\\
\>[8]{}\Varid{b}\mathrel{=}\Varid{c}{}\<[E]%
\\
\>[8]{}\Varid{c}\mathrel{=}\Varid{d}\mathbin{+}\Varid{e}{}\<[E]%
\\
\>[8]{}\Varid{d}\mathrel{=}\Varid{b}{}\<[E]%
\\
\>[8]{}\Varid{e}\mathrel{=}\mathrm{1}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;{}\<[8]%
\>[8]{}\Varid{a}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
This is a perfectly valid definition,
but we could also break it up into the three nested let expressions below.
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{8}{@{}>{\hspre}l<{\hspost}@{}}%
\column{13}{@{}>{\hspre}l<{\hspost}@{}}%
\column{18}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;{}\<[8]%
\>[8]{}\Varid{e}\mathrel{=}\mathrm{1}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;{}\<[8]%
\>[8]{}\mathbf{let}\;{}\<[13]%
\>[13]{}\Varid{b}\mathrel{=}\Varid{c}{}\<[E]%
\\
\>[13]{}\Varid{c}\mathrel{=}\Varid{d}\mathbin{+}\Varid{e}{}\<[E]%
\\
\>[13]{}\Varid{d}\mathrel{=}\Varid{b}{}\<[E]%
\\
\>[8]{}\mathbf{in}\;{}\<[13]%
\>[13]{}\mathbf{let}\;{}\<[18]%
\>[18]{}\Varid{a}\mathrel{=}\Varid{b}{}\<[E]%
\\
\>[13]{}\mathbf{in}\;{}\<[18]%
\>[18]{}\Varid{a}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
It's debatable which version is better coding style, but the second version
is inarguably more useful for the compiler.
There are several optimizations that can be safely performed on a single let bound variable.
Unfortunately, splitting the let expression into blocks isn't trivial.
The algorithm involves making a graph out of all references in the let block,
then finding the strongly connected components of that reference graph,
and, finally, rebuilding the let expression from the component graph.
The full algorithm is given below in figure \ref{fig:blocks}

\begin{figure}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{5}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{blocks}\;(\Conid{Let}\;\Varid{vs}\;\Varid{e})\mid \Varid{numBlocks}\mathbin{>}\mathrm{1}\mathrel{=}\Varid{e'}{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mathbf{where}\;(\Varid{e'},\Varid{numBlocks})\mathrel{=}\Varid{makeBlocks}\;\Varid{es}\;\Varid{e}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{4}{@{}>{\hspre}l<{\hspost}@{}}%
\column{11}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{makeBlocks}\;\Varid{vs}\;\Varid{e}\mathrel{=}(\Varid{letExp},\Varid{length}\;\Varid{comps}){}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mathbf{where}\;{}\<[11]%
\>[11]{}\Varid{letExp}\mathrel{=}\Varid{foldr}\;\Varid{makeBlock}\;\Varid{e}\;\Varid{comps}{}\<[E]%
\\
\>[11]{}\Varid{makeBlock}\;\Varid{comp}\mathrel{=}\lambda \Varid{exp}\to \Conid{Let}\;(\Varid{map}\;\Varid{getExp}\;\Varid{comp})\;\Varid{exp}{}\<[E]%
\\
\>[11]{}\Varid{getExp}\;(\anonymous \plus [\mskip1.5mu (\Varid{n},\Varid{exp})\mskip1.5mu]\plus \anonymous )\mathrel{=}(\Varid{n},\Varid{exp}){}\<[E]%
\\[\blanklineskip]%
\>[11]{}\Varid{comps}\mathrel{=}\Varid{scc}\;(\Varid{vs}\bind \Varid{makeEdges}){}\<[E]%
\\
\>[11]{}\Varid{makeEdges}\;(\Varid{v},\Varid{exp})\mathrel{=}[\mskip1.5mu (\Varid{v},\Varid{f})\mid \Varid{f}\leftarrow \Varid{freeVars}\;\Varid{exp}\cap\Varid{map}\;\Varid{fst}\;\Varid{vs}\mskip1.5mu]{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\caption{Transformation for splitting let expressions into mutually recursive blocks.}
\label{fig:blocks}
\end{figure}

While this optimization is significantly more complicated then the \ensuremath{\Varid{float}} example,
We can still implement it in our system.
Furthermore, we're able to factor out the code for building the graph
and finding the strongly connected components.
This is the advantage of using Curry functions as opposed to strict rewrite rules.
We have much more freedom in constructing the right-hand side of our rules.

Now that we can create optimizations, what if we want both \ensuremath{\Varid{blocks}} and \ensuremath{\Varid{float}} to be able to run?
This is an important part of the compilation process to get expressions into a canonical form.
It turns out that combining two optimizations is simple.
We just make a non-deterministic choice between them.
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{floatBlocks}\mathrel{=}\Varid{float}\mathbin{?}\Varid{blocks}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
This is a new optimization that will apply either \ensuremath{\Varid{float}} or \ensuremath{\Varid{blocks}}.
The ability to compose optimizations with \ensuremath{\mathbin{?}} is the heart of the GAS system.
Each optimization can be developed and tested in isolation,
then they can be combined for efficiency.

\subsection{An Initial Attempt}

Our first attempt is quite simple, really.
We pick an arbitrary subexpression with \ensuremath{\Varid{subExpr}}
and apply an optimization.
We can then use a non-deterministic fix point operator to find
all transformations that can be applied to the current expression.
We can define the non-deterministic fix point operator using either
the Findall library, or Set Function \cite{findall, setFunctions}.
The full code is given in figure \ref{fig:optFirst}.

\begin{figure}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{4}{@{}>{\hspre}l<{\hspost}@{}}%
\column{23}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{fix}\mathbin{::}(\Varid{a}\to \Varid{a})\to \Varid{a}\to \Varid{a}{}\<[E]%
\\
\>[3]{}\Varid{fix}\;\Varid{f}\;\Varid{x}{}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mid \Varid{f}\;\Varid{x}\Varid{==}\emptyset {}\<[23]%
\>[23]{}\mathrel{=}\Varid{x}{}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mid \Varid{otherwise}{}\<[23]%
\>[23]{}\mathrel{=}\Varid{fix}\;\Varid{f}\;(\Varid{f}\;\Varid{x}){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{4}{@{}>{\hspre}l<{\hspost}@{}}%
\column{11}{@{}>{\hspre}l<{\hspost}@{}}%
\column{27}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{subExpr}\mathbin{::}\Conid{Expr}\to \Conid{Expr}{}\<[E]%
\\
\>[3]{}\Varid{subExpr}\;\Varid{e}{}\<[27]%
\>[27]{}\mathrel{=}\Varid{e}{}\<[E]%
\\
\>[3]{}\Varid{subExpr}\;(\Conid{Comb}\;\Varid{ct}\;\Varid{f}\;\Varid{vs}){}\<[27]%
\>[27]{}\mathrel{=}\Varid{subExpr}\;(\Varid{foldr1}\;(\mathbin{?})\;\Varid{es}){}\<[E]%
\\
\>[3]{}\Varid{subExpr}\;(\Conid{Let}\;\Varid{vs}\;\Varid{e}){}\<[27]%
\>[27]{}\mathrel{=}\Varid{subExpr}\;(\Varid{foldr1}\;(\mathbin{?})\;(\Varid{e}\mathbin{:}\Varid{map}\;\Varid{snd}\;\Varid{es})){}\<[E]%
\\
\>[3]{}\Varid{subExpr}\;(\Conid{Free}\;\Varid{vs}\;\Varid{e}){}\<[27]%
\>[27]{}\mathrel{=}\Varid{subExpr}\;\Varid{e}{}\<[E]%
\\
\>[3]{}\Varid{subExpr}\;(\Conid{Or}\;\Varid{e}_{\mathrm{1}}\;\Varid{e}_{\mathrm{2}}){}\<[27]%
\>[27]{}\mathrel{=}\Varid{subExpr}\;\Varid{e}_{\mathrm{1}}\mathbin{?}\Varid{subExpr}\;\Varid{e}_{\mathrm{2}}{}\<[E]%
\\
\>[3]{}\Varid{subExpr}\;(\Conid{Case}\;\Varid{e}\;\Varid{bs}){}\<[27]%
\>[27]{}\mathrel{=}\Varid{subExpr}\;(\Varid{e}\mathbin{:}\Varid{map}\;\Varid{branchExpr}\;\Varid{bs}){}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mathbf{where}\;{}\<[11]%
\>[11]{}\Varid{branchExpr}\;(\Conid{Branch}\;\anonymous \;\Varid{e})\mathrel{=}\Varid{e}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{reduce}\mathbin{::}\Conid{Opt}\to \Conid{Expr}\to \Conid{Expr}{}\<[E]%
\\
\>[3]{}\Varid{reduce}\;\Varid{opt}\;\Varid{e}\mathrel{=}\Varid{opt}\;(\Varid{subExpr}\;\Varid{e}){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{simplify}\mathbin{::}\Conid{Opt}\to \Conid{Expr}\to \Conid{Expr}{}\<[E]%
\\
\>[3]{}\Varid{simplify}\;\Varid{opt}\;\Varid{e}\mathrel{=}\Varid{fix}\;(\Varid{reduce}\;\Varid{opt})\;\Varid{e}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\caption{A first attempt at an optimization engine.
         Pick an arbitrary subexpression and try to optimize it.}
\label{fig:optFirst}
\end{figure}

While this attempt is short and readable,
there's a problem with it.
It is unusably slow.
While looking at the code, it's pretty clear to see what the problem is.
Every time we traverse the expression, we can only apply a single transformation.
This means that if we need to apply 100 transformations, which is not uncommon,
then we need to traverse the expression 100 times.

\subsection{A Second Attempt: Multiple Transformations Per Pass}

Our second attempt runs much faster.
Instead of picking an arbitrary subexpression,
we choose to traverse the expression manually.
Now, we can check at each node if an optimization applies.
We only need to make two changes.
The biggest is that we eliminate \ensuremath{\Varid{subExpr}} and change \ensuremath{\Varid{reduce}} to traverse the entire expression.
Now \ensuremath{\Varid{reduce}} can apply an optimization at every step.
We've also made \ensuremath{\Varid{reduce}} completely deterministic.
The second change is that since \ensuremath{\Varid{reduce}} is deterministic, we can change \ensuremath{\Varid{fix}}
to be a more traditional implementation of a fix point operator.
The new implementation is given in figure \ref{fig:optReduce}

\begin{figure}
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{4}{@{}>{\hspre}l<{\hspost}@{}}%
\column{11}{@{}>{\hspre}l<{\hspost}@{}}%
\column{20}{@{}>{\hspre}l<{\hspost}@{}}%
\column{26}{@{}>{\hspre}l<{\hspost}@{}}%
\column{34}{@{}>{\hspre}l<{\hspost}@{}}%
\column{35}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{fix}\mathbin{::}(\Varid{a}\to \Varid{a})\to \Varid{a}\to \Varid{a}{}\<[E]%
\\
\>[3]{}\Varid{fix}\;\Varid{f}\;\Varid{x}{}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mid \Varid{f}\;\Varid{x}\Varid{==}\Varid{x}\mathrel{=}\Varid{x}{}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mid \Varid{otherwise}\mathrel{=}\Varid{fix}\;\Varid{f}\;(\Varid{f}\;\Varid{x}){}\<[E]%
\\
\>[3]{}\ {}\<[E]%
\\
\>[3]{}\Varid{reduce}\mathbin{::}\Conid{Opt}\to \Conid{Expr}\to \Conid{Expr}{}\<[E]%
\\
\>[3]{}\Varid{reduce}\;\Varid{opt}\;(\Conid{Var}\;\Varid{v}){}\<[34]%
\>[34]{}\mathrel{=}\Varid{runOpts}\;\Varid{opt}\;(\Conid{Var}\;\Varid{v}){}\<[E]%
\\
\>[3]{}\Varid{reduce}\;\Varid{opt}\;(\Conid{Lit}\;\Varid{l}){}\<[34]%
\>[34]{}\mathrel{=}\Varid{runOpts}\;\Varid{opt}\;(\Conid{Lit}\;\Varid{l}){}\<[E]%
\\
\>[3]{}\Varid{reduce}\;\Varid{opt}\;(\Conid{Comb}\;\Varid{ct}\;\Varid{f}\;\Varid{es}){}\<[34]%
\>[34]{}\mathrel{=}\Varid{runOpts}\;\Varid{opt}\;(\Conid{Comb}\;\Varid{ct}\;\Varid{f}\;(\Varid{map}\;(\Varid{reduce}\;\Varid{opt})\;\Varid{es})){}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mathbf{where}\;{}\<[11]%
\>[11]{}\Varid{es'}\mathrel{=}\Varid{map}\;(\Varid{reduce}\;\Varid{opt})\;\Varid{es}{}\<[E]%
\\
\>[3]{}\Varid{reduce}\;\Varid{opt}\;(\Conid{Let}\;\Varid{vs}\;\Varid{e}){}\<[34]%
\>[34]{}\mathrel{=}\Varid{runOpts}\;\Varid{opt}\;\Conid{Let}\;(\Varid{map}\;\Varid{runLet}\;\Varid{vs})\;(\Varid{reduce}\;\Varid{opt}\;\Varid{e}){}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mathbf{where}\;{}\<[11]%
\>[11]{}\Varid{runLet}\;(\Varid{v},\Varid{e})\mathrel{=}(\Varid{v},\Varid{reduce}\;\Varid{opt}\;\Varid{e}){}\<[E]%
\\
\>[3]{}\Varid{reduce}\;\Varid{opt}\;(\Conid{Free}\;\Varid{vs}\;\Varid{e}){}\<[34]%
\>[34]{}\mathrel{=}\Varid{runOpts}\;\Varid{opt}\;(\Conid{Free}\;\Varid{vs}\;(\Varid{reduce}\;\Varid{opt}\;\Varid{e})){}\<[E]%
\\
\>[3]{}\Varid{reduce}\;\Varid{opt}\;(\Conid{Or}\;\Varid{a}\;\Varid{b}){}\<[34]%
\>[34]{}\mathrel{=}\Varid{runOpts}\;\Varid{opt}\;(\Conid{Or}\;(\Varid{reduce}\;\Varid{opt}\;\Varid{a})\;(\Varid{reduce}\;\Varid{opt}\;\Varid{a})){}\<[E]%
\\
\>[3]{}\Varid{reduce}\;\Varid{opt}\;(\Conid{Case}\;\Varid{e}\;\Varid{bs}){}\<[34]%
\>[34]{}\mathrel{=}\Varid{runOpts}\;\Varid{opt}\;(\Conid{Case}\;(\Varid{reduce}\;\Varid{opt}\;\Varid{e})\;\Varid{bs'}){}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mathbf{where}\;{}\<[11]%
\>[11]{}\Varid{runBranch}\;(\Conid{Branch}\;\Varid{p}\;\Varid{e})\mathrel{=}\Conid{Branch}\;\Varid{p}\;(\Varid{reduce}\;\Varid{opt}\;\Varid{e}){}\<[E]%
\\
\>[11]{}\Varid{bs'}\mathrel{=}\Varid{map}\;\Varid{runBranch}\;\Varid{bs}{}\<[E]%
\\
\>[3]{}\ {}\<[E]%
\\
\>[3]{}\Varid{runOpts}\mathbin{::}\Conid{Opt}\to \Conid{Expr}\to \Conid{Expr}{}\<[E]%
\\
\>[3]{}\Varid{runOpts}\;\Varid{opt}\;\Varid{e}\mathrel{=}{}\<[20]%
\>[20]{}\mathbf{case}\;{}\<[26]%
\>[26]{}\Varid{oneValue}\;(\Varid{opt}\;\Varid{e})\;\mathbf{of}{}\<[E]%
\\
\>[26]{}\Conid{Nothing}{}\<[35]%
\>[35]{}\to \Varid{e}{}\<[E]%
\\
\>[26]{}\Conid{Just}\;\Varid{e'}{}\<[35]%
\>[35]{}\to \Varid{e'}{}\<[E]%
\\
\>[3]{}\ {}\<[E]%
\\
\>[3]{}\Varid{simplify}\mathbin{::}\Conid{Opt}\to \Conid{Expr}\to \Conid{Expr}{}\<[E]%
\\
\>[3]{}\Varid{simplify}\;\Varid{opt}\;\Varid{e}\mathrel{=}\Varid{fix}\;(\Varid{reduce}\;\Varid{opt})\;\Varid{e}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\caption{A second attempt.
         Traverse the expression and, at each node, check if an optimization applies.}
\label{fig:optReduce}
\end{figure}

This approach is significantly better.
Aside from applying multiple rules in one pass,
we also limit our search space when applying our optimizations.
While there's still more we can do,
the new approach makes the GAS library usable on larger Curry programs,
like the standard Prelude.

\subsection{Adding More Information}

Rather surprisingly our current approach is actually sufficient for compiling FlatCurry.
However, to optimize Curry we're going to need more information when we apply a transformation.
Specifically, we'll be able to create new variables.
To simplify optimizations, we'll require that each variable name can only be used once.
Regardless, we need a way to know what is a safe variable name that we're allowed to use.
We may also need to know if we're rewriting the root of an expression.
Fortunately, all we need to change is to define \ensuremath{\Conid{Opt}} to accept more parameters.
For each optimization, we'll pass in an \ensuremath{\Varid{n}\mathbin{::}\Conid{Int}}
that represents the next variable \ensuremath{\Varid{v}_{\Varid{n}}} that is guaranteed to be fresh.
We'll also pass in a \ensuremath{\Varid{top}\mathbin{::}\Conid{Bool}} that tells us if we're at root of a function we're optimizing.
We also return a pair of \ensuremath{(\Conid{Expr},\Conid{Int})} to denote the optimized expression,
and the number of new variables we used.
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{type}\;\Conid{Opt}\mathrel{=}(\Conid{Int},\Conid{Bool})\to \Conid{Expr}\to (\Conid{Expr},\Conid{Int}){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
If we later decide that we want to add more information, then we just update the first parameter.
The only problem is, how do we make sure we're calling each optimization with the correct \ensuremath{\Varid{n}} and \ensuremath{\Varid{top}}?
We just need to update \ensuremath{\Varid{reduce}} and \ensuremath{\Varid{runOpt}}.
In order to keep track of the next available free variable we use the \ensuremath{\Conid{State}} monad.
We do need to make minor changes to \ensuremath{\Varid{fix}} and \ensuremath{\Varid{simplify}},
but this is just to make them compatible with \ensuremath{\Conid{State}}.
The full implementation is in figure \ref{fig:optAddInfo}.


\begin{figure}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{4}{@{}>{\hspre}l<{\hspost}@{}}%
\column{11}{@{}>{\hspre}l<{\hspost}@{}}%
\column{16}{@{}>{\hspre}l<{\hspost}@{}}%
\column{21}{@{}>{\hspre}l<{\hspost}@{}}%
\column{24}{@{}>{\hspre}l<{\hspost}@{}}%
\column{28}{@{}>{\hspre}l<{\hspost}@{}}%
\column{31}{@{}>{\hspre}l<{\hspost}@{}}%
\column{34}{@{}>{\hspre}l<{\hspost}@{}}%
\column{35}{@{}>{\hspre}l<{\hspost}@{}}%
\column{36}{@{}>{\hspre}l<{\hspost}@{}}%
\column{41}{@{}>{\hspre}l<{\hspost}@{}}%
\column{42}{@{}>{\hspre}l<{\hspost}@{}}%
\column{45}{@{}>{\hspre}l<{\hspost}@{}}%
\column{46}{@{}>{\hspre}l<{\hspost}@{}}%
\column{47}{@{}>{\hspre}l<{\hspost}@{}}%
\column{48}{@{}>{\hspre}l<{\hspost}@{}}%
\column{55}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{reduce}\mathbin{::}\Conid{Opt}\to \Conid{Bool}\to \Conid{Expr}\to \Conid{State}\;\Conid{Int}\;\Conid{Expr}{}\<[E]%
\\
\>[3]{}\Varid{reduce}\;\Varid{opt}\;\Varid{top}\;(\Conid{Var}\;\Varid{v}){}\<[35]%
\>[35]{}\mathrel{=}\Varid{runOpts}\;\Varid{opt}\;\Varid{top}\;(\Conid{Var}\;\Varid{v}){}\<[E]%
\\
\>[3]{}\Varid{reduce}\;\Varid{opt}\;\Varid{top}\;(\Conid{Lit}\;\Varid{l}){}\<[35]%
\>[35]{}\mathrel{=}\Varid{runOpts}\;\Varid{opt}\;\Varid{top}\;(\Conid{Lit}\;\Varid{l}){}\<[E]%
\\
\>[3]{}\Varid{reduce}\;\Varid{opt}\;\Varid{top}\;(\Conid{Comb}\;\Varid{ct}\;\Varid{f}\;\Varid{es}){}\<[35]%
\>[35]{}\mathrel{=}\mathbf{do}\;{}\<[41]%
\>[41]{}\Varid{es'}\leftarrow \Varid{mapM}\;(\Varid{reduce}\;\Varid{opt}\;\Conid{False}\;\Varid{es}){}\<[E]%
\\
\>[41]{}\Varid{runOpts}\;\Varid{opt}\;\Varid{top}\;(\Conid{Comb}\;\Varid{ct}\;\Varid{f}\;\Varid{es'}){}\<[E]%
\\
\>[3]{}\Varid{reduce}\;\Varid{opt}\;\Varid{top}\;(\Conid{Let}\;\Varid{vs}\;\mathbf{in}\;\Varid{e}){}\<[35]%
\>[35]{}\mathrel{=}\mathbf{do}\;{}\<[41]%
\>[41]{}\Varid{vs'}{}\<[46]%
\>[46]{}\leftarrow \Varid{mapM}\;\Varid{runVar}\;\Varid{vs}{}\<[E]%
\\
\>[41]{}\Varid{e'}{}\<[46]%
\>[46]{}\leftarrow \Varid{mapM}\;\Varid{reduce}\;\Varid{opt}\;\Conid{False}\;\Varid{e}{}\<[E]%
\\
\>[41]{}\Varid{runOpts}\;\Varid{opt}\;\Varid{top}\;(\Conid{Let}\;\Varid{vs'}\;\mathbf{in}\;\Varid{e'}){}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mathbf{where}\;{}\<[11]%
\>[11]{}\Varid{runVar}\;(\Varid{v},\Varid{e})\mathrel{=}\mathbf{do}\;{}\<[31]%
\>[31]{}\Varid{e'}\leftarrow \Varid{reduce}\;\Varid{opt}\;\Conid{False}\;\Varid{e}{}\<[E]%
\\
\>[31]{}\Varid{return}\;(\Varid{v},\Varid{e'}){}\<[E]%
\\
\>[3]{}\Varid{reduce}\;\Varid{opt}\;\Varid{top}\;(\Conid{Free}\;\Varid{vs}\;\Varid{e}){}\<[35]%
\>[35]{}\mathrel{=}\mathbf{do}\;{}\<[41]%
\>[41]{}\Varid{e'}\leftarrow \Varid{reduce}\;\Varid{opt}\;\Conid{False}\;\Varid{e}{}\<[E]%
\\
\>[41]{}\Varid{runOpts}\;\Varid{opt}\;\Varid{top}\;(\Conid{Free}\;\Varid{vs}\;\Varid{e'}){}\<[E]%
\\
\>[3]{}\Varid{reduce}\;\Varid{opt}\;\Varid{top}\;(\Conid{Or}\;\Varid{a}\;\Varid{b}){}\<[35]%
\>[35]{}\mathrel{=}\mathbf{do}\;{}\<[41]%
\>[41]{}\Varid{a'}{}\<[45]%
\>[45]{}\leftarrow \Varid{reduce}\;\Varid{opt}\;\Conid{False}\;\Varid{a}{}\<[E]%
\\
\>[41]{}\Varid{b'}{}\<[45]%
\>[45]{}\leftarrow \Varid{reduce}\;\Varid{opt}\;\Conid{False}\;\Varid{b}{}\<[E]%
\\
\>[41]{}\Varid{runOpts}\;\Varid{opt}\;(\Conid{Or}\;\Varid{a'}\;\Varid{b'}){}\<[E]%
\\
\>[3]{}\Varid{reduce}\;\Varid{opt}\;\Varid{top}\;(\Conid{Case}\;\Varid{e}\;\Varid{bs}){}\<[35]%
\>[35]{}\mathrel{=}\mathbf{do}\;{}\<[41]%
\>[41]{}\Varid{e'}{}\<[47]%
\>[47]{}\leftarrow \Varid{reduce}\;\Varid{opt}\;\Conid{False}\;\Varid{e}{}\<[E]%
\\
\>[41]{}\Varid{bs'}{}\<[47]%
\>[47]{}\leftarrow \Varid{mapM}\;\Varid{runBranch}\;\Varid{bs}{}\<[E]%
\\
\>[41]{}\Varid{runOpts}\;\Varid{opt}\;(\Conid{Case}\;\Varid{e'}\;\Varid{bs'}){}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mathbf{where}\;\Varid{runBranch}\;(\Conid{Branch}\;\Varid{pat}\;\Varid{e}){}\<[36]%
\>[36]{}\mathrel{=}\mathbf{do}\;{}\<[42]%
\>[42]{}\Varid{e'}\leftarrow \Varid{reduce}\;\Varid{opt}\;\Conid{False}\;\Varid{e}{}\<[E]%
\\
\>[42]{}\Varid{return}\;(\Conid{Branch}\;\Varid{pat}\;\Varid{e'}){}\<[E]%
\\
\>[3]{}\ {}\<[E]%
\\
\>[3]{}\Varid{runOpts}\mathbin{::}\Conid{Opt}\to \Conid{Bool}\to \Conid{Expr}\to \Conid{State}\;\Conid{Int}\;\Conid{Expr}{}\<[E]%
\\
\>[3]{}\Varid{runOpts}\;\Varid{opt}\;\Varid{top}\;\Varid{e}\mathrel{=}{}\<[24]%
\>[24]{}\mathbf{do}\;{}\<[28]%
\>[28]{}\Varid{v}\leftarrow \Varid{get}{}\<[E]%
\\
\>[28]{}\mathbf{case}\;{}\<[34]%
\>[34]{}\Varid{opt}\;(\Varid{v},\Varid{top})\;\Varid{e}\;\mathbf{of}{}\<[E]%
\\
\>[34]{}\Conid{Nothing}{}\<[48]%
\>[48]{}\to \Varid{return}\;\Varid{e}{}\<[E]%
\\
\>[34]{}\Conid{Just}\;(\Varid{e'},\Varid{dv}){}\<[48]%
\>[48]{}\to \mathbf{do}\;{}\<[55]%
\>[55]{}\Varid{put}\;(\Varid{v}\mathbin{+}\Varid{dv}){}\<[E]%
\\
\>[55]{}\Varid{return}\;\Varid{e'}{}\<[E]%
\\
\>[3]{}\Varid{fix}\mathbin{::}(\Varid{a}\to \Conid{State}\;\Varid{b}\;\Varid{a})\to \Varid{a}\to \Varid{b}\to \Varid{a}{}\<[E]%
\\
\>[3]{}\Varid{fix}\;\Varid{f}\;\Varid{x}\;\Varid{s}\mathrel{=}{}\<[16]%
\>[16]{}\mathbf{let}\;{}\<[21]%
\>[21]{}(\Varid{x'},\Varid{s'})\mathrel{=}\Varid{runState}\;(\Varid{f}\;\Varid{x})\;\Varid{s}{}\<[E]%
\\
\>[16]{}\mathbf{in}\;{}\<[21]%
\>[21]{}\mathbf{if}\;\Varid{x}\Varid{==}\Varid{x'}\;\mathbf{then}\;\Varid{x}\;\mathbf{else}\;\Varid{fix}\;\Varid{f}\;\Varid{x'}\;\Varid{s'}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\caption{A third attempt.
         keep track of the next fresh variable, and if we're at the root.}
\label{fig:optAddInfo}
\end{figure}


\subsection{Reconstruction}

Right now we have everything we need to write all of our optimizations.
However, we've found it useful to be able to 
track which optimizations were applied and where they were applied.
This helps with testing, debugging, and designing optimizations,
as well as generating optimization derivations that we'll see later in this dissertation.
It is difficult to overstate just how helpful this addition was in building this compiler.

If we want to add this, then we need to make a few changes.
First, we need to decide on a representation for a rewrite derivation.
Traditionally a rewrite derivation is a sequence of rewrite steps,
where each step contains the rule and position of the rewrite.
We describe paths in figure \ref{fig:path}.
To make reconstruction easier, we also include the expression that is the result of the rewrite.
This gives us the type:\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{type}\;\Conid{Path}\mathrel{=}[\mskip1.5mu \Conid{Int}\mskip1.5mu]{}\<[E]%
\\
\>[3]{}\mathbf{type}\;\Conid{Step}\mathrel{=}(\Conid{String},\Conid{Path},\Conid{Expr}){}\<[E]%
\\
\>[3]{}\mathbf{type}\;\Conid{Derivation}\mathrel{=}[\mskip1.5mu \Conid{Step}\mskip1.5mu]{}\<[E]%
\ColumnHook
\end{hscode}\resethooks

\begin{figure}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{4}{@{}>{\hspre}l<{\hspost}@{}}%
\column{28}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{ndpath}\;\Varid{e}{}\<[28]%
\>[28]{}\mathrel{=}[\mskip1.5mu \mskip1.5mu]{}\<[E]%
\\
\>[3]{}\Varid{ndpath}\;(\Conid{Comb}\;\Varid{ct}\;\Varid{f}\;\Varid{es}){}\<[28]%
\>[28]{}\mathrel{=}\Varid{anymap}\;\Varid{argPath}\;\Varid{es}{}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mathbf{where}\;\Varid{argPath}\;(\Varid{i},\Varid{e})\mathrel{=}\Varid{i}\mathbin{:}\Varid{ndpath}\;\Varid{e}_{\Varid{i}}{}\<[E]%
\\
\>[3]{}\Varid{ndpath}\;(\Conid{Or}\;\Varid{e}_{\mathrm{0}}\;\Varid{e}_{\mathrm{1}}){}\<[28]%
\>[28]{}\mathrel{=}\mathrm{0}\mathbin{:}\Varid{ndpath}\;\Varid{e}_{\mathrm{0}}\mathbin{?}\mathrm{1}\mathbin{:}\Varid{ndpath}\;\Varid{e}_{\mathrm{1}}{}\<[E]%
\\
\>[3]{}\Varid{ndpath}\;(\Conid{Let}\;\Varid{vs}\;\Varid{e}_{-1}){}\<[28]%
\>[28]{}\mathrel{=}\Varid{anymap}\;\Varid{letPath}\;\Varid{es}{}\<[E]%
\\
\>[28]{}\mathbin{?}\mathbin{-}\mathrm{1}\mathbin{:}\Varid{ndpath}\;\Varid{e}_{-1}{}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mathbf{where}\;\Varid{letPath}\;(\Varid{i},(\anonymous ,\Varid{e}))\mathrel{=}\Varid{i}\mathbin{:}\Varid{ndpath}\;\Varid{e}{}\<[E]%
\\
\>[3]{}\Varid{ndpath}\;(\Conid{Case}\;\Varid{e}\;\mathbf{of}\;\Varid{alts}){}\<[28]%
\>[28]{}\mathrel{=}\mathbin{-}\mathrm{1}\mathbin{:}\Varid{ndpath}\;\Varid{e}{}\<[E]%
\\
\>[28]{}\mathbin{?}\Varid{anymap}\;\Varid{altPath}\;\Varid{alts}{}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mathbf{where}\;\Varid{altPath}\;(\Varid{i},\Conid{Branch}\;\anonymous \;\Varid{e})\mathrel{=}\Varid{i}\mathbin{:}\Varid{ndpath}\;\Varid{e}{}\<[E]%
\\
\>[3]{}\ {}\<[E]%
\\
\>[3]{}\Varid{anymap}\;\Varid{f}\mathrel{=}\Varid{anyof}\mathbin{\circ}\Varid{map}\;\Varid{f}\mathbin{\circ}\Varid{zip}\;[\mskip1.5mu \mathrm{1}\mathinner{\ldotp\ldotp}\mskip1.5mu]{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\caption{The definition of a path for Curry expressions.\\
         This function non-deterministically returns a path to a subexpression.}
\label{fig:path}
\end{figure}


This leads to the last change we need to make to our \ensuremath{\Conid{Opt}} type.
We need each optimization to also tell us its name.
This is good practice in general, 
because it forces us to come up with unique names for each optimization.
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{type}\;\Conid{Opt}\mathrel{=}(\Conid{Int},\Conid{Bool})\to \Conid{Expr}\to (\Conid{Expr},\Conid{String},\Conid{Int}){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
We only need to make a few change to the algorithm.
Instead of using the \ensuremath{\Conid{State}} monad, we use a combination of the \ensuremath{\Conid{State}} and \ensuremath{\Conid{Writer}} monads,
so we can keep track of the derivation.
We've elected to call this the \ensuremath{\Conid{ReWriter}} 
monad.
We add a function \ensuremath{\Varid{update}\mathbin{::}\Conid{Expr}\to \Conid{Step}\to \Conid{Int}\to \Conid{ReWriter}\;\Conid{Expr}} 
that is similar to \ensuremath{\Varid{put}} from \ensuremath{\Conid{State}}.  This updates the state variable, and creates a single step.
The \ensuremath{\Varid{reduce}} function requires few changes.
We change the Boolean variable \ensuremath{\Varid{top}} to a more general \ensuremath{\Conid{Path}}.
Because of this change, we need to add the correct subexpression position,
instead of just changing \ensuremath{\Varid{top}} to \ensuremath{\Conid{False}}.
The \ensuremath{\Conid{RunOpts}} function is similar.  We just change \ensuremath{\Varid{top}} to a \ensuremath{\Conid{Path}},
and check if it's null.
Finally \ensuremath{\Varid{fix}} and \ensuremath{\Varid{simplify}} are modified to remember the rewrite steps we've already computed.
We change the return type of \ensuremath{\Varid{simplify}} so that we have the list of steps.
The full implementation is in figure \ref{fig:reconstruct}

\begin{figure}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{4}{@{}>{\hspre}l<{\hspost}@{}}%
\column{11}{@{}>{\hspre}l<{\hspost}@{}}%
\column{22}{@{}>{\hspre}l<{\hspost}@{}}%
\column{26}{@{}>{\hspre}l<{\hspost}@{}}%
\column{27}{@{}>{\hspre}l<{\hspost}@{}}%
\column{32}{@{}>{\hspre}l<{\hspost}@{}}%
\column{38}{@{}>{\hspre}l<{\hspost}@{}}%
\column{41}{@{}>{\hspre}l<{\hspost}@{}}%
\column{43}{@{}>{\hspre}l<{\hspost}@{}}%
\column{44}{@{}>{\hspre}l<{\hspost}@{}}%
\column{51}{@{}>{\hspre}c<{\hspost}@{}}%
\column{51E}{@{}l@{}}%
\column{55}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{reduce}\mathbin{::}\Conid{Opt}\to \Conid{Path}\to \Conid{Expr}\to \Conid{ReWriter}\;\Conid{Expr}{}\<[E]%
\\
\>[3]{}\Varid{reduce}\;\Varid{opt}\;\Varid{p}\;(\Conid{Var}\;\Varid{v}){}\<[32]%
\>[32]{}\mathrel{=}\Varid{return}\;(\Conid{Var}\;\Varid{v}){}\<[E]%
\\
\>[3]{}\Varid{reduce}\;\Varid{opt}\;\Varid{p}\;(\Conid{Lit}\;\Varid{l}){}\<[32]%
\>[32]{}\mathrel{=}\Varid{return}\;(\Conid{Lit}\;\Varid{l}){}\<[E]%
\\
\>[3]{}\Varid{reduce}\;\Varid{opt}\;\Varid{p}\;(\Conid{Comb}\;\Varid{ct}\;\Varid{f}\;\Varid{es}){}\<[32]%
\>[32]{}\mathrel{=}\mathbf{do}\;{}\<[38]%
\>[38]{}\Varid{es'}\leftarrow \Varid{mapM}\;\Varid{runArg}\;(\Varid{zip}\;[\mskip1.5mu \mathrm{0}\mathinner{\ldotp\ldotp}\mskip1.5mu]\;\Varid{es}){}\<[E]%
\\
\>[38]{}\Varid{runOpts}\;\Varid{opt}\;\Varid{p}\;(\Conid{Comb}\;\Varid{ct}\;\Varid{f}\;\Varid{es}){}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mathbf{where}\;{}\<[11]%
\>[11]{}\Varid{runArg}\;(\Varid{n},\Varid{e}){}\<[32]%
\>[32]{}\mathrel{=}\Varid{reduce}\;\Varid{opt}\;(\Varid{n}\mathbin{:}\Varid{p})\;\Varid{e}{}\<[E]%
\\
\>[3]{}\Varid{reduce}\;\Varid{opt}\;\Varid{p}\;(\Conid{Let}\;\Varid{vs}\;\Varid{e}){}\<[32]%
\>[32]{}\mathrel{=}\mathbf{do}\;{}\<[38]%
\>[38]{}\Varid{vs'}{}\<[43]%
\>[43]{}\leftarrow \Varid{mapM}\;\Varid{runVar}\;(\Varid{zip}\;[\mskip1.5mu \mathrm{0}\mathinner{\ldotp\ldotp}\mskip1.5mu]\;\Varid{vs}){}\<[E]%
\\
\>[38]{}\Varid{e'}{}\<[43]%
\>[43]{}\leftarrow \Varid{mapM}\;\Varid{reduce}\;\Varid{opt}\;(\mathbin{-}\mathrm{1}\mathbin{:}\Varid{p})\;\Varid{e}{}\<[E]%
\\
\>[38]{}\Varid{runOpts}\;\Varid{opt}\;\Varid{p}\;(\Conid{Let}\;\Varid{vs'}\;\Varid{e'}){}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mathbf{where}\;{}\<[11]%
\>[11]{}\Varid{runVar}\;(\Varid{n},(\Varid{v},\Varid{e})){}\<[32]%
\>[32]{}\mathrel{=}\Varid{fmap}\;(\lambda \Varid{x}\to (\Varid{v},\Varid{x}))\;(\Varid{reduce}\;\Varid{opt}\;(\Varid{n}\mathbin{:}\Varid{p})\;\Varid{e}){}\<[E]%
\\
\>[3]{}\Varid{reduce}\;\Varid{opt}\;\Varid{p}\;(\Conid{Free}\;\Varid{vs}\;\mathbf{in}\;\Varid{e}){}\<[32]%
\>[32]{}\mathrel{=}\mathbf{do}\;{}\<[38]%
\>[38]{}\Varid{e'}\leftarrow \Varid{reduce}\;\Varid{opt}\;(\mathrm{0}\mathbin{:}\Varid{p})\;\Varid{e}{}\<[E]%
\\
\>[38]{}\Varid{runOpts}\;\Varid{opt}\;\Varid{p}\;(\Conid{Free}\;\Varid{vs}\;\Varid{e'}){}\<[E]%
\\
\>[3]{}\Varid{reduce}\;\Varid{opt}\;\Varid{p}\;(\Conid{Or}\;\Varid{a}\;\Varid{b}){}\<[32]%
\>[32]{}\mathrel{=}\mathbf{do}\;{}\<[38]%
\>[38]{}\Varid{a}{}\<[41]%
\>[41]{}\leftarrow \Varid{reduce}\;\Varid{opt}\;(\mathrm{0}\mathbin{:}\Varid{p})\;\Varid{a}{}\<[E]%
\\
\>[38]{}\Varid{b}{}\<[41]%
\>[41]{}\leftarrow \Varid{reduce}\;\Varid{opt}\;(\mathrm{1}\mathbin{:}\Varid{p})\;\Varid{b}{}\<[E]%
\\
\>[38]{}\Varid{runOpts}\;\Varid{opt}\;(\Conid{Or}\;(\Varid{a'}\mathbin{?}\Varid{b'})){}\<[E]%
\\
\>[3]{}\Varid{reduce}\;\Varid{opt}\;\Varid{p}\;(\Conid{Case}\;\Varid{e}\;\Varid{bs}){}\<[32]%
\>[32]{}\mathrel{=}\mathbf{do}\;{}\<[38]%
\>[38]{}\Varid{e'}{}\<[44]%
\>[44]{}\leftarrow \Varid{reduce}\;\Varid{opt}\;(\mathbin{-}\mathrm{1}\mathbin{:}\Varid{p})\;\Varid{e}{}\<[E]%
\\
\>[38]{}\Varid{bs'}{}\<[44]%
\>[44]{}\leftarrow \Varid{mapM}\;\Varid{runBranch}\;(\Varid{zip}\;[\mskip1.5mu \mathrm{0}\mathinner{\ldotp\ldotp}\mskip1.5mu]\;\Varid{bs}){}\<[E]%
\\
\>[38]{}\Varid{runOpts}\;\Varid{opt}\;(\Conid{Case}\;\Varid{e'}\;\Varid{bs'}){}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mathbf{where}\;\Varid{runBranch}\;(\Varid{n},(\Conid{Branch}\;\Varid{pat}\;\Varid{e})){}\<[41]%
\>[41]{}\mathrel{=}\Varid{fmap}\;(\Conid{Branch}\;\Varid{pat})\;(\Varid{reduce}\;\Varid{opt}\;(\Varid{n}\mathbin{:}\Varid{p})\;\Varid{e}){}\<[E]%
\\[\blanklineskip]%
\>[3]{}\ {}\<[E]%
\\
\>[3]{}\Varid{runOpts}\mathbin{::}\Conid{Opt}\to \Conid{Path}\to \Conid{Expr}\to \Conid{ReWriter}\;\Conid{Expr}{}\<[E]%
\\
\>[3]{}\Varid{runOpts}\;\Varid{opt}\;\Varid{p}\;\Varid{e}\mathrel{=}{}\<[22]%
\>[22]{}\mathbf{do}\;{}\<[26]%
\>[26]{}\Varid{v}\leftarrow \Varid{get}{}\<[E]%
\\
\>[26]{}\mathbf{case}\;{}\<[32]%
\>[32]{}\Varid{oneValue}\;(\Varid{opt}\;(\Varid{v},\Varid{null}\;\Varid{p}))\;\mathbf{of}{}\<[E]%
\\
\>[32]{}\Conid{Nothing}{}\<[51]%
\>[51]{}\to {}\<[51E]%
\>[55]{}\Varid{return}\;\Varid{e}{}\<[E]%
\\
\>[32]{}\Conid{Just}\;(\Varid{e'},\Varid{rule},\Varid{dv}){}\<[51]%
\>[51]{}\to {}\<[51E]%
\>[55]{}\mathbf{do}\;\Varid{update}\;(\Varid{e'},\Varid{rule},\Varid{p})\;\Varid{dv}{}\<[E]%
\\
\>[55]{}\Varid{return}\;\Varid{e'}{}\<[E]%
\\
\>[3]{}\Varid{fix}\mathbin{::}(\Varid{a}\to \Conid{ReWriter}\;\Varid{a})\to \Varid{a}\to \Conid{Int}\to [\mskip1.5mu \Conid{Step}\mskip1.5mu]\to (\Varid{a},[\mskip1.5mu \Conid{Step}\mskip1.5mu]){}\<[E]%
\\
\>[3]{}\Varid{fix}\;\Varid{f}\;\Varid{x}\;\Varid{n}\;\Varid{steps}\mathrel{=}{}\<[22]%
\>[22]{}\mathbf{let}\;{}\<[27]%
\>[27]{}(\Varid{x'},\Varid{n'},\Varid{steps'})\mathrel{=}\Varid{runRewriter}\;(\Varid{f}\;\Varid{x})\;\Varid{n}{}\<[E]%
\\
\>[22]{}\mathbf{in}\;{}\<[27]%
\>[27]{}\mathbf{if}\;\Varid{x}\Varid{==}\Varid{x'}\;\mathbf{then}\;\Varid{x}\;\mathbf{else}\;\Varid{fix}\;\Varid{f}\;\Varid{x'}\;\Varid{n'}\;(\Varid{steps}\plus \Varid{steps'}){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\caption{The final version of GAS with reconstruction.}
\label{fig:reconstruct}
\end{figure}

Now that we've computed the rewrite steps, it's a simple process to reconstruct them into a string.
The \ensuremath{\Varid{pPrint}} function comes from the FlatCurry Pretty Printing Library.
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{43}{@{}>{\hspre}l<{\hspost}@{}}%
\column{47}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{reconstruct}\mathbin{::}\Conid{Expr}\to [\mskip1.5mu \Conid{Step}\mskip1.5mu]\to \Conid{String}{}\<[E]%
\\
\>[3]{}\Varid{reconstruct}\;\anonymous \;[\mskip1.5mu \mskip1.5mu]\mathrel{=}\text{\ttfamily \char34 \char34}{}\<[E]%
\\
\>[3]{}\Varid{reconstruct}\;\Varid{e}\;((\Varid{rule},\Varid{p},\Varid{rhs})\mathbin{:}\Varid{steps})\mathrel{=}{}\<[43]%
\>[43]{}\mathbf{let}\;\Varid{e'}\mathrel{=}\Varid{e}[\Varid{p}\to\Varid{rhs}]{}\<[E]%
\\
\>[43]{}\mathbf{in}\;{}\<[47]%
\>[47]{}\text{\ttfamily \char34 =>\char95 \char34}\plus \Varid{rule}\plus \text{\ttfamily \char34 ~\char34}\plus (\Varid{show}\;\Varid{p})\plus \text{\ttfamily \char34 \char92 n\char34}\plus {}\<[E]%
\\
\>[47]{}\Varid{pPrint}\;\Varid{e'}\plus \text{\ttfamily \char34 \char92 n\char34}\plus {}\<[E]%
\\
\>[47]{}\Varid{reconstruct}\;\Varid{e'}\;\Varid{steps}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks

Now that our optimization engine is running and printing out optimization derivations,
there are a few tricks we can use to improve the efficiency.
Remember that our optimizing engine is going to run for every optimization,
so it's worth taking the time to tune it to be as efficient as possible.
The first trick is really simple.  We add a Boolean variable \ensuremath{\Varid{seen}} to the ReWriter monad.
This variable starts as \ensuremath{\Conid{False}}, and we set it to \ensuremath{\Conid{True}} if we apply any optimization.
This avoids the linear time check for every call of \ensuremath{\Varid{fix}} to see if we actually ran any optimizations.
The second quick optimization is to notice that variables, literals, and type expressions 
are never going to run an optimization, 
so we can immediately return in each of those cases without calling \ensuremath{\Varid{runOpt}}.
This is actually a much bigger deal than it might first appear.
All of the leaves are going to either be variables, literals, or constructors applied to no arguments.
For expression trees the leaves are often the majority of the nodes in the tree.
Finally, we can put a limit on the number of optimizations to apply.
If we ever reach that number, then we can immediately return.
This can stop our optimizer from taking too much time.

Now that the GAS system is in place, we can move onto compiling FlatCurry programs.
In This chapter we've introduced the GAS system that allows us to represent transformations 
In a simple form that's easy to extend and test.
We've seen how we can represent an optimization as a function from expressions to expressions.
Then we showed that we can extend this idea to create more powerful optimizations,
and automatically generate optimization derivations.
In the next chapter we put this system to work.
We use the GAS system to implement several transformations to turn FlatCurry code
in to a form that can be more easily compiled.
Then we show how to generate efficient C code for FlatCurry programs.
We also introduced the idea

\chapter{The Compiler Pipeline} \label{ch:The Compiler Pipeline}


In the last chapter we developed the GAS system for representing transformation.
In this chapter we show an extended example of using the GAS system to transform FlatCurry programs
into a canonical form.
We then show how to translate these canonical progras to the ICurry intermediate representation.
Finally, we compile the ICurry progrms to C code, as discussed in chapter 3.

This compiler, unsurprisingly, follows a traditional compiler pipeline.
While we start with an AST, there are still five phases left before we can generate C code.
First, we normalize FlatCurry to a canonical form. 
Second, we optimize the FlatCurry. 
Third, we sanitize the FlatCurry to simplify the process of generating C code.
Fourth, we compile the FlatCurry to ICurry, an intermediate representation that is closer to C.
Finally, we compile the ICurry to C.
These steps are referred to as pre-process, optimize, post-process, toICurry, and toC within the compiler
\cite{git}.

We give an example of a function as it passes through each of the stages of the 
compiler in figure \ref{fig:stages}.
After pre-processing, the let expression has been floated to the top,
and the missing branch has been filled in.
After optimization, code is organized into blocks, and functions have been reduced.
After post processing, let bound variables with a case expression have been factored
out into their own functions.
At this point the code is ready to be translated into ICurry and then C.

While there are several small details that are important to constructing a working Curry compiler,
we'll concern ourselves with the big picture here.

\begin{figure}
Curry function\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{f}\;\Conid{True}\mathrel{=}\Conid{False}{}\<[E]%
\\
\>[3]{}\Varid{f}\;\Varid{x}\mathrel{=}\Varid{not}\;(\mathbf{let}\;\Varid{y}\mathrel{=}\Varid{not}\;\Varid{x}\;\mathbf{in}\;\Varid{not}\;\Varid{y}){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
FlatCurry representation\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{12}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{f}\;\Varid{v}_{\mathrm{1}}\mathrel{=}{}\<[12]%
\>[12]{}(\mathbf{case}\;\Varid{v}_{\mathrm{1}}\;\mathbf{of}\;\Conid{True}\to \Conid{False})\mathbin{?}{}\<[E]%
\\
\>[12]{}(\Varid{not}\;(\mathbf{let}\;\Varid{v}_{\mathrm{2}}\mathrel{=}\Varid{not}\;\Varid{v}_{\mathrm{1}}\;\mathbf{in}\;\Varid{not}\;\Varid{v}_{\mathrm{2}})){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
After Pre-processing\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{12}{@{}>{\hspre}l<{\hspost}@{}}%
\column{16}{@{}>{\hspre}l<{\hspost}@{}}%
\column{23}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{f}\;\Varid{v}_{\mathrm{1}}\mathrel{=}{}\<[12]%
\>[12]{}\mathbf{let}\;\Varid{v}_{\mathrm{2}}\mathrel{=}\Varid{not}\;\Varid{v1\char95 }{}\<[E]%
\\
\>[12]{}\mathbf{in}\;{}\<[16]%
\>[16]{}(\mathbf{case}\;{}\<[23]%
\>[23]{}\Varid{v}_{\mathrm{1}}\;\mathbf{of}{}\<[E]%
\\
\>[23]{}\Conid{True}\to \Conid{False}{}\<[E]%
\\
\>[23]{}\Conid{False}\to \bot )\mathbin{?}(\Varid{not}\;(\Varid{not}\;\Varid{v2})){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
After Optimization\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{8}{@{}>{\hspre}l<{\hspost}@{}}%
\column{13}{@{}>{\hspre}l<{\hspost}@{}}%
\column{20}{@{}>{\hspre}l<{\hspost}@{}}%
\column{25}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;{}\<[8]%
\>[8]{}\Varid{v}_{\mathrm{4}}\mathrel{=}\mathbf{case}\;{}\<[20]%
\>[20]{}\Varid{v}_{\mathrm{1}}\;\mathbf{of}{}\<[E]%
\\
\>[20]{}\Conid{True}\to \Conid{False}{}\<[E]%
\\
\>[20]{}\Conid{False}\to \bot {}\<[E]%
\\
\>[3]{}\mathbf{in}\;{}\<[8]%
\>[8]{}\mathbf{let}\;{}\<[13]%
\>[13]{}\Varid{v}_{\mathrm{5}}\mathrel{=}\mathbf{case}\;{}\<[25]%
\>[25]{}\Varid{v}_{\mathrm{1}}\;\mathbf{of}{}\<[E]%
\\
\>[25]{}\Conid{True}\to \Conid{False}{}\<[E]%
\\
\>[25]{}\Conid{False}\to \Conid{True}{}\<[E]%
\\
\>[8]{}\mathbf{in}\;{}\<[13]%
\>[13]{}\Varid{v4}\mathbin{?}\Varid{v5}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
After Post-processing\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{12}{@{}>{\hspre}l<{\hspost}@{}}%
\column{17}{@{}>{\hspre}l<{\hspost}@{}}%
\column{20}{@{}>{\hspre}l<{\hspost}@{}}%
\column{22}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{f}\;\Varid{v}_{\mathrm{2}}\mathrel{=}{}\<[12]%
\>[12]{}\mathbf{let}\;{}\<[17]%
\>[17]{}\Varid{v}_{\mathrm{3}}\mathrel{=}\Varid{f}_{\mathrm{0}}\;\Varid{v}_{\mathrm{2}}{}\<[E]%
\\
\>[12]{}\mathbf{in}\;{}\<[17]%
\>[17]{}\mathbf{let}\;{}\<[22]%
\>[22]{}\Varid{v}_{\mathrm{4}}\mathrel{=}\Varid{f}_{\mathrm{1}}\;\Varid{v}_{\mathrm{2}}{}\<[E]%
\\
\>[17]{}\mathbf{in}\;{}\<[22]%
\>[22]{}\Varid{v}_{\mathrm{3}}\mathbin{?}\Varid{v}_{\mathrm{4}}{}\<[E]%
\\
\>[3]{}\Varid{f}_{\mathrm{0}}\;\Varid{v}_{\mathrm{2}}\mathrel{=}\textbf{fcase} \;{}\<[20]%
\>[20]{}\Varid{v}_{\mathrm{2}}\;\mathbf{of}{}\<[E]%
\\
\>[20]{}\Conid{True}\to \Conid{False}{}\<[E]%
\\
\>[20]{}\Conid{False}\to \bot {}\<[E]%
\\
\>[3]{}\Varid{f}_{\mathrm{1}}\;\Varid{v}_{\mathrm{2}}\mathrel{=}\textbf{fcase} \;{}\<[20]%
\>[20]{}\Varid{v}_{\mathrm{2}}\;\mathbf{of}{}\<[E]%
\\
\>[20]{}\Conid{True}\to \Conid{False}{}\<[E]%
\\
\>[20]{}\Conid{False}\to \Conid{True}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\caption{\ensuremath{\Varid{f}} at each stage of the optimizer.}
\label{fig:stages}
\end{figure}

\section{Canonical FlatCurry}

The pre-process and post-process steps of the compiler make heavy use the of GAS system,
and transform the FlatCurry program in to a form that is more amenable to C,
including removing case and let expression from inside function applications.
We will discuss the optimization phase in the next section,
but for now we can see how transformations work.

\begin{figure}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{6}{@{}>{\hspre}c<{\hspost}@{}}%
\column{6E}{@{}l@{}}%
\column{9}{@{}>{\hspre}l<{\hspost}@{}}%
\column{15}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{f}\;\Varid{v}_{\mathrm{1}}\;\Varid{v}_{\mathrm{2}}\ldots \Varid{v}_{\Varid{n}}\mathrel{=}\Varid{b}{}\<[E]%
\\[\blanklineskip]%
\>[3]{}\Varid{s}{}\<[6]%
\>[6]{}\mathrel{=}{}\<[6E]%
\>[9]{}\mathbf{case}\;{}\<[15]%
\>[15]{}\Varid{e}\;\mathbf{of}\;\{\mskip1.5mu \Conid{C}\;\Varid{v}_{\mathrm{1}}\ldots \Varid{v}_{\Varid{n}}\to \Varid{s}\mskip1.5mu\}{}\<[E]%
\\
\>[6]{}\mid {}\<[6E]%
\>[9]{}\mathbf{let}\;\{\mskip1.5mu \Varid{v}\mathrel{=}\Varid{e}\mskip1.5mu\}\;\mathbf{in}\;\Varid{s}{}\<[E]%
\\
\>[6]{}\mid {}\<[6E]%
\>[9]{}\mathbf{let}\;\{\mskip1.5mu \Varid{v}\mskip1.5mu\}\;\textbf{free} \;\mathbf{in}\;\Varid{s}{}\<[E]%
\\
\>[6]{}\mid {}\<[6E]%
\>[9]{}\Varid{e}{}\<[E]%
\\[\blanklineskip]%
\>[3]{}\Varid{e}{}\<[6]%
\>[6]{}\mathrel{=}{}\<[6E]%
\>[9]{}\Varid{v}{}\<[E]%
\\
\>[6]{}\mid {}\<[6E]%
\>[9]{}\Varid{l}{}\<[E]%
\\
\>[6]{}\mid {}\<[6E]%
\>[9]{}\Varid{f}_{\Varid{k}}\;\Varid{e}_{\mathrm{1}}\;\Varid{e}_{\mathrm{2}}\ldots \Varid{e}_{\Varid{n}}{}\<[E]%
\\
\>[6]{}\mid {}\<[6E]%
\>[9]{}\Conid{C}_{\Varid{k}}\;\Varid{e}_{\mathrm{1}}\;\Varid{e}_{\mathrm{2}}\ldots \Varid{e}_{\Varid{n}}{}\<[E]%
\\
\>[6]{}\mid {}\<[6E]%
\>[9]{}\Varid{e}_{\mathrm{1}}\mathbin{?}\Varid{e}_{\mathrm{2}}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\caption{Canonical FlatCurry.\\
         We split expressions into statement-like expressions \ensuremath{\Varid{s}}, and expressions \ensuremath{\Varid{e}}.
         Statement like expressions roughly correspond to control flow, and are translated
         to variable declaration and control flow statements in C.  }
\label{fig:flatCanonical}
\end{figure}

Let's start with an example:\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathrm{1}\mathbin{+}\mathbf{let}\;\Varid{x}\mathrel{=}\mathrm{3}\;\mathbf{in}\;\Varid{x}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
This is a perfectly fine Curry program, 
but C does not allow variable declarations in an expression,
so we need to rewrite this Curry expression to:\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;\Varid{x}\mathrel{=}\mathrm{3}\;\mathbf{in}\;\mathrm{1}\mathbin{+}\Varid{x}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
We don't reduce \ensuremath{\mathbf{let}\;\Varid{x}\mathrel{=}\mathrm{3}\;\mathbf{in}\;\Varid{x}} yet, because that would be an optimization.
However, this will be reduced later.
We can translate the new expression to C in a direct manner.
This is the purpose of the pre-process and post-process steps.
We rewrite a Curry expression that doesn't make sense in C to an equivalent Curry expression
that we can translate directly to C.
Most of the transformations consist of disallowing certain syntactic constructs.
Canonical FlatCurry is defined in figure \ref{fig:flatCanonical}.

Examples of the pre-processing transformations are presented in figures
\ref{fig:canonical} and \ref{fig:canonical2}.
We use the symbol \ensuremath{\Rrightarrow } for the optimization relation.
The implementation is presented in figure \ref{fig:code}.
We only show the initial implementation of an optimiation
that excludes the name and path, but it can be extended to the full optimization
in a straightforward manner.
The full implementation can be found in 
the \texttt{src/Optimize/Preprocess.curry} file at \cite{git}.

In practice several of these rules are generalized and optimized.
For example let-expressions may have many mutually recursive variables,
and when floating a let bound variable inward, we may want to recursively traverse
the expression to find the innermost declaration possible.
However, these extensions to the rules are also included in the repository \cite{git}.

\begin{figure}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{4}{@{}>{\hspre}l<{\hspost}@{}}%
\column{5}{@{}>{\hspre}l<{\hspost}@{}}%
\column{12}{@{}>{\hspre}l<{\hspost}@{}}%
\column{19}{@{}>{\hspre}l<{\hspost}@{}}%
\column{38}{@{}>{\hspre}l<{\hspost}@{}}%
\column{48}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{float}\;(\Conid{Let}\;(\Varid{as}\plus [\mskip1.5mu (\Varid{x},\Conid{Let}\;\Varid{vs}\;\Varid{e}_{\mathrm{1}})\mskip1.5mu]\plus \Varid{bs})\;\Varid{e}_{\mathrm{2}}){}\<[48]%
\>[48]{}\mathrel{=}\Conid{Let}\;((\Varid{x},\Varid{e}_{\mathrm{1}})\mathbin{:}\Varid{vs}\plus \Varid{as}\plus \Varid{bs})\;\Varid{e}_{\mathrm{2}}{}\<[E]%
\\
\>[3]{}\Varid{float}\;(\Conid{Let}\;(\Varid{as}\plus [\mskip1.5mu (\Varid{x},\Conid{Free}\;\Varid{vs}\;\Varid{e}_{\mathrm{1}})\mskip1.5mu]\plus \Varid{bs})\;\Varid{e}_{\mathrm{2}}){}\<[48]%
\>[48]{}\mathrel{=}\Conid{Free}\;\Varid{vs}\;(\Conid{Let}\;((\Varid{x},\Varid{e}_{\mathrm{1}})\mathbin{:}\Varid{as}\plus \Varid{bs})\;\Varid{e}_{\mathrm{2}}){}\<[E]%
\\
\>[3]{}\Varid{float}\;(\Conid{Or}\;(\Conid{Let}\;\Varid{vs}\;\Varid{e}_{\mathrm{1}})\;\Varid{e}_{\mathrm{2}}){}\<[48]%
\>[48]{}\mathrel{=}\Conid{Let}\;\Varid{vs}\;(\Conid{Or}\;\Varid{e}_{\mathrm{1}}\;\Varid{e}_{\mathrm{2}}){}\<[E]%
\\
\>[3]{}\Varid{float}\;(\Conid{Or}\;\Varid{e}_{\mathrm{1}}\;(\Conid{Let}\;\Varid{vs}\;\Varid{e}_{\mathrm{2}})){}\<[48]%
\>[48]{}\mathrel{=}\Conid{Let}\;\Varid{vs}\;(\Conid{Or}\;\Varid{e}_{\mathrm{1}}\;\Varid{e}_{\mathrm{2}}){}\<[E]%
\\
\>[3]{}\Varid{float}\;(\Conid{Or}\;(\Conid{Free}\;\Varid{vs}\;\Varid{e}_{\mathrm{1}})\;\Varid{e}_{\mathrm{2}}){}\<[48]%
\>[48]{}\mathrel{=}\Conid{Free}\;\Varid{vs}\;(\Conid{Or}\;\Varid{e}_{\mathrm{1}}\;\Varid{e}_{\mathrm{2}}){}\<[E]%
\\
\>[3]{}\Varid{float}\;(\Conid{Or}\;\Varid{e}_{\mathrm{1}}\;(\Conid{Free}\;\Varid{vs}\;\Varid{e}_{\mathrm{2}})){}\<[48]%
\>[48]{}\mathrel{=}\Conid{Free}\;\Varid{vs}\;(\Conid{Or}\;\Varid{e}_{\mathrm{1}}\;\Varid{e}_{\mathrm{2}}){}\<[E]%
\\
\>[3]{}\Varid{float}\;(\Conid{Comb}\;\Varid{ct}\;\Varid{n}\;(\Varid{as}\plus [\mskip1.5mu \Conid{Let}\;\Varid{vs}\;\Varid{e}\mskip1.5mu]\plus \Varid{bs})){}\<[48]%
\>[48]{}\mathrel{=}\Conid{Let}\;\Varid{vs}\;(\Conid{Comb}\;\Varid{ct}\;\Varid{n}\;(\Varid{as}\plus [\mskip1.5mu \Varid{e}\mskip1.5mu]\plus \Varid{bs})){}\<[E]%
\\
\>[3]{}\Varid{float}\;(\Conid{Comb}\;\Varid{ct}\;\Varid{n}\;(\Varid{as}\plus [\mskip1.5mu \Conid{Free}\;\Varid{vs}\;\Varid{e}\mskip1.5mu]\plus \Varid{bs})){}\<[48]%
\>[48]{}\mathrel{=}\Conid{Free}\;\Varid{vs}\;(\Conid{Comb}\;\Varid{ct}\;\Varid{n}\;(\Varid{as}\plus [\mskip1.5mu \Varid{e}\mskip1.5mu]\plus \Varid{bs})){}\<[E]%
\\
\>[3]{}\Varid{float}\;(\Conid{Case}\;(\Conid{Let}\;\Varid{vs}\;\Varid{e})\;\Varid{alts}){}\<[48]%
\>[48]{}\mathrel{=}\Conid{Let}\;\Varid{vs}\;(\Conid{Case}\;\Varid{e}\;\Varid{alts}){}\<[E]%
\\
\>[3]{}\Varid{float}\;(\Conid{Case}\;(\Conid{Free}\;\Varid{vs}\;\Varid{e})\;\Varid{alts}){}\<[48]%
\>[48]{}\mathrel{=}\Conid{Free}\;\Varid{vs}\;(\Conid{Case}\;\Varid{e}\;\Varid{alts}){}\<[E]%
\\
\>[3]{}\ {}\<[E]%
\\
\>[3]{}\Varid{flatten}\;(\Varid{apply}\;(\Varid{apply}\;\Varid{f}\;\Varid{as})\;\Varid{bs}){}\<[38]%
\>[38]{}\mathrel{=}\Varid{applyf}\;\Varid{f}\;(\Varid{as}\plus \Varid{bs}){}\<[E]%
\\
\>[3]{}\Varid{flatten}\;(\Varid{apply}\;(\Conid{Case}\;\Varid{e}\;\Varid{bs})\;\Varid{xs}){}\<[38]%
\>[38]{}\mathrel{=}\Conid{Case}\;\Varid{e}\;\Varid{bs'}{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mathbf{where}\;\Varid{bs'}\mathrel{=}[\mskip1.5mu \Conid{Branch}\;\Varid{p}\;(\Varid{applyf}\;\Varid{e'}\;\Varid{xs})\mid (\Conid{Branch}\;\Varid{p}\;\Varid{e'})\leftarrow \Varid{bs}\mskip1.5mu]{}\<[E]%
\\
\>[3]{}\Varid{flatten}\;(\Conid{Case}\;(\Conid{Case}\;\Varid{e}\;\Varid{alt2})\;\Varid{alt1}){}\<[38]%
\>[38]{}\mathrel{=}\Conid{Case}\;\Varid{e}\;\Varid{bs}\;(\Varid{map}\;\Varid{addCase}\;\Varid{alt2}){}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mathbf{where}\;\Varid{addCase}\;(\Conid{Branch}\;\Varid{p}\;\Varid{e'})\mathrel{=}\Conid{Branch}\;\Varid{p}\;(\Conid{Case}\;\Varid{e'}\;\Varid{b1}){}\<[E]%
\\
\>[3]{}\ {}\<[E]%
\\
\>[3]{}\Varid{blocks}\;\anonymous \;(\Conid{Let}\;\Varid{vs}\;\Varid{e})\mid \Varid{changed}\mathrel{=}\Varid{e'}{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mathbf{where}\;(\Varid{e'},\Varid{changed})\mathrel{=}\Varid{makeBlocks}\;\Varid{vs}\;\Varid{e}{}\<[E]%
\\
\>[3]{}\ {}\<[E]%
\\
\>[3]{}\Varid{alias}\;\anonymous \;(\Conid{Let}\;(\Varid{as}\plus [\mskip1.5mu (\Varid{v},\Conid{Var}\;\Varid{y})\mskip1.5mu]\plus \Varid{bs})\;\Varid{e}){}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mid \Varid{v}\Varid{==}\Varid{y}{}\<[19]%
\>[19]{}\mathrel{=}\Conid{Let}\;(\Varid{as}\plus [\mskip1.5mu (\Varid{v},\Varid{loop})\mskip1.5mu]\plus \Varid{bs})\;\Varid{e}{}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mid \Varid{otherwise}{}\<[19]%
\>[19]{}\mathrel{=}\Varid{suby}\;(\Conid{Let}\;(\Varid{as}\plus \Varid{bs})\;\Varid{e}){}\<[E]%
\\
\>[4]{}\hsindent{1}{}\<[5]%
\>[5]{}\mathbf{where}\;{}\<[12]%
\>[12]{}\Varid{loop}\mathrel{=}\Conid{Comb}\;\Conid{FuncCall}\;(\text{\ttfamily \char34 Prelude\char34},\text{\ttfamily \char34 loop\char34})\;[\mskip1.5mu \mskip1.5mu]{}\<[E]%
\\
\>[12]{}\Varid{suby}\mathrel{=}\Varid{sub}\;(\lambda \Varid{x}\to \Varid{x}\Varid{==}\Varid{v}\;\mathbf{then}\;\Conid{Var}\;\Varid{y}\;\mathbf{else}\;\Conid{Var}\;\Varid{x}){}\<[E]%
\\
\>[3]{}\ {}\<[E]%
\\
\>[3]{}\Varid{fillCases}\;\Varid{dt}\;\anonymous \;(\Conid{Case}\;\Varid{e}\;\Varid{bs}){}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mid \Varid{not}\;(\Varid{null}\;\Varid{exempts})\mathrel{=}\Conid{Case}\;\Varid{e}\;(\Varid{bs}\plus \Varid{exempts}){}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mathbf{where}\;\Varid{exempts}\mathrel{=}[\mskip1.5mu \Conid{Branch}\;(\Conid{Pattern}\;\Varid{b}\;[\mskip1.5mu \mskip1.5mu])\;\Varid{exempt}\mid \Varid{b}\leftarrow \Varid{missingBranches}\;\Varid{dt}\;\Varid{bs}\mskip1.5mu]{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\caption{The Curry implementation for the pre-processing transformations.\\
         In \ensuremath{\Varid{fillCases}}, \ensuremath{\Varid{dt}} is a \ensuremath{\Conid{DataTable}}, which holds information about data types.
         The \ensuremath{\Varid{missingBranches}} takes a list of branches and a \ensuremath{\Conid{DataTable}} and returns the names
         of the branches that aren't present.
         In \ensuremath{\Varid{alias}} the \ensuremath{\Varid{sub}} function applies a substitution to an expression.}
\label{fig:code}
\end{figure}

\begin{figure}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[B]{}\textbf{Let Floating}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{12}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;\Varid{x}\mathrel{=}{}\<[12]%
\>[12]{}\mathbf{let}\;\Varid{y}\mathrel{=}\Varid{e}_{\mathrm{1}}{}\<[E]%
\\
\>[12]{}\mathbf{in}\;\Varid{e}_{\mathrm{2}}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\Varid{e}_{\mathrm{3}}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage} \ensuremath{\Rrightarrow }
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{8}{@{}>{\hspre}l<{\hspost}@{}}%
\column{12}{@{}>{\hspre}l<{\hspost}@{}}%
\column{17}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;{}\<[8]%
\>[8]{}\Varid{y}\mathrel{=}\Varid{e}_{\mathrm{1}}{}\<[E]%
\\
\>[8]{}\mathbf{in}\;{}\<[12]%
\>[12]{}\mathbf{let}\;{}\<[17]%
\>[17]{}\Varid{x}\mathrel{=}\Varid{e}_{\mathrm{2}}{}\<[E]%
\\
\>[12]{}\mathbf{in}\;{}\<[17]%
\>[17]{}\Varid{e}_{\mathrm{3}}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}\\
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{12}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;\Varid{x}\mathrel{=}{}\<[12]%
\>[12]{}\mathbf{let}\;\Varid{y}\;\textbf{free} {}\<[E]%
\\
\>[12]{}\mathbf{in}\;\Varid{e}_{\mathrm{1}}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\Varid{e}_{\mathrm{2}}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage} \ensuremath{\Rrightarrow }
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{7}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;\Varid{y}\;\textbf{free} {}\<[E]%
\\
\>[3]{}\mathbf{in}\;{}\<[7]%
\>[7]{}\mathbf{let}\;\Varid{x}\mathrel{=}\Varid{e}_{\mathrm{2}}{}\<[E]%
\\
\>[7]{}\mathbf{in}\;\Varid{e}_{\mathrm{3}}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}\\
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}(\mathbf{let}\;\Varid{x}\mathrel{=}\Varid{e}_{\mathrm{1}}\;\mathbf{in}\;\Varid{e}_{\mathrm{2}})\mathbin{?}\Varid{e}_{\mathrm{3}}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage} \ensuremath{\Rrightarrow }
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;\Varid{x}\mathrel{=}\Varid{e}_{\mathrm{1}}\;\mathbf{in}\;(\Varid{e}_{\mathrm{2}}\mathbin{?}\Varid{e}_{\mathrm{3}}){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}\\
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}(\mathbf{let}\;\Varid{x}\;\textbf{free} \;\mathbf{in}\;\Varid{e}_{\mathrm{1}})\mathbin{?}\Varid{e}_{\mathrm{2}}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage} \ensuremath{\Rrightarrow }
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;\Varid{x}\;\textbf{free} \;\mathbf{in}\;(\Varid{e}_{\mathrm{1}}\mathbin{?}\Varid{e}_{\mathrm{2}}){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}\\
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{f}\;(\mathbf{let}\;\Varid{x}\mathrel{=}\Varid{e}_{\mathrm{1}}\;\mathbf{in}\;\Varid{e}_{\mathrm{2}}){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage} \ensuremath{\Rrightarrow }
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;\Varid{x}\mathrel{=}\Varid{e}_{\mathrm{1}}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\Varid{f}\;\Varid{e}_{\mathrm{2}}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}\\
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{f}\;(\mathbf{let}\;\Varid{x}\;\textbf{free} \;\mathbf{in}\;\Varid{e}){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage} \ensuremath{\Rrightarrow }
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;\Varid{x}\;\textbf{free} {}\<[E]%
\\
\>[3]{}\mathbf{in}\;\Varid{f}\;\Varid{e}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}\\
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{9}{@{}>{\hspre}l<{\hspost}@{}}%
\column{17}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{case}\;{}\<[9]%
\>[9]{}\mathbf{let}\;\Varid{x}\mathrel{=}\Varid{e}_{\mathrm{1}}{}\<[E]%
\\
\>[9]{}\mathbf{in}\;\Varid{e}_{\mathrm{2}}\;{}\<[17]%
\>[17]{}\mathbf{of}{}\<[E]%
\\
\>[9]{}\Varid{alts}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage} \ensuremath{\Rrightarrow }
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;\Varid{x}\mathrel{=}\Varid{e}_{\mathrm{1}}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\mathbf{case}\;\Varid{e}_{\mathrm{2}}\;\mathbf{of}\;\Varid{alts}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}\\
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{9}{@{}>{\hspre}l<{\hspost}@{}}%
\column{15}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{case}\;{}\<[9]%
\>[9]{}\mathbf{let}\;\Varid{x}\;\textbf{free} {}\<[E]%
\\
\>[9]{}\mathbf{in}\;\Varid{e}\;{}\<[15]%
\>[15]{}\mathbf{of}{}\<[E]%
\\
\>[9]{}\Varid{alts}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage} \ensuremath{\Rrightarrow }
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;\Varid{x}\;\textbf{free} {}\<[E]%
\\
\>[3]{}\mathbf{in}\;\mathbf{case}\;\Varid{e}\;\mathbf{of}\;\Varid{alts}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}
\caption{GAS rules for putting FlatCurry programs into canonical form}
\label{fig:canonical}
\end{figure}

\begin{figure}
\vspace{-4ex}
\textbf{Case in Case}\\
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{9}{@{}>{\hspre}l<{\hspost}@{}}%
\column{16}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{case}\;{}\<[9]%
\>[9]{}(\mathbf{case}\;{}\<[16]%
\>[16]{}\Varid{e}\;\mathbf{of}{}\<[E]%
\\
\>[16]{}\{\mskip1.5mu \Varid{b}_{\mathrm{2}}\to \Varid{e}_{\mathrm{2}}\mskip1.5mu\})\;\mathbf{of}{}\<[E]%
\\
\>[9]{}\{\mskip1.5mu \Varid{b}_{\mathrm{1}}\to \Varid{e}_{\mathrm{1}}\mskip1.5mu\}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage} \ensuremath{\Rrightarrow }
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{14}{@{}>{\hspre}c<{\hspost}@{}}%
\column{14E}{@{}l@{}}%
\column{17}{@{}>{\hspre}l<{\hspost}@{}}%
\column{23}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{case}\;\Varid{e}\;\mathbf{of}\;{}\<[14]%
\>[14]{}\{\mskip1.5mu {}\<[14E]%
\>[17]{}\Varid{b}_{\mathrm{2}}\to {}\<[E]%
\\
\>[17]{}\mathbf{case}\;{}\<[23]%
\>[23]{}\Varid{e}_{\mathrm{2}}\;\mathbf{of}{}\<[E]%
\\
\>[23]{}\{\mskip1.5mu \Varid{b}_{\mathrm{1}}\to \Varid{e}_{\mathrm{1}}\mskip1.5mu\}\mskip1.5mu\}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}\\
\textbf{Double Apply}\\
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{apply}\;(\Varid{apply}\;\Varid{f}\;[\mskip1.5mu \Varid{x}\mskip1.5mu])\;[\mskip1.5mu \Varid{y}\mskip1.5mu]{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage} \ensuremath{\Rrightarrow }
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{apply}\;\Varid{f}\;[\mskip1.5mu \Varid{x},\Varid{y}\mskip1.5mu]{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}\\
\textbf{Case Apply}\\
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{16}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{apply}\;(\mathbf{case}\;{}\<[16]%
\>[16]{}\Varid{e}\;\mathbf{of}{}\<[E]%
\\
\>[16]{}\{\mskip1.5mu \Varid{pat}\to \Varid{f}\mskip1.5mu\})\;\Varid{x}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage} \ensuremath{\Rrightarrow }
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{9}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{case}\;{}\<[9]%
\>[9]{}\Varid{e}\;\mathbf{of}{}\<[E]%
\\
\>[9]{}\{\mskip1.5mu \Varid{pat}\to \Varid{f}\;\Varid{x}\mskip1.5mu\}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}\\
\textbf{Blocks}\\
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{8}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;{}\<[8]%
\>[8]{}\Varid{a}\mathrel{=}\Varid{b}{}\<[E]%
\\
\>[8]{}\Varid{b}\mathrel{=}\Varid{c}{}\<[E]%
\\
\>[8]{}\Varid{c}\mathrel{=}\Varid{d}\mathbin{+}\Varid{e}{}\<[E]%
\\
\>[8]{}\Varid{d}\mathrel{=}\Varid{b}{}\<[E]%
\\
\>[8]{}\Varid{e}\mathrel{=}\mathrm{1}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;{}\<[8]%
\>[8]{}\Varid{a}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage} \ensuremath{\Rrightarrow }
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{8}{@{}>{\hspre}l<{\hspost}@{}}%
\column{13}{@{}>{\hspre}l<{\hspost}@{}}%
\column{18}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;{}\<[8]%
\>[8]{}\Varid{e}\mathrel{=}\mathrm{1}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;{}\<[8]%
\>[8]{}\mathbf{let}\;{}\<[13]%
\>[13]{}\Varid{b}\mathrel{=}\Varid{c}{}\<[E]%
\\
\>[13]{}\Varid{c}\mathrel{=}\Varid{d}\mathbin{+}\Varid{e}{}\<[E]%
\\
\>[13]{}\Varid{d}\mathrel{=}\Varid{b}{}\<[E]%
\\
\>[8]{}\mathbf{in}\;{}\<[13]%
\>[13]{}\mathbf{let}\;{}\<[18]%
\>[18]{}\Varid{a}\mathrel{=}\Varid{b}{}\<[E]%
\\
\>[13]{}\mathbf{in}\;{}\<[18]%
\>[18]{}\Varid{a}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}\\
\textbf{Alias}\\
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;\Varid{x}\mathrel{=}\Varid{y}\;\mathbf{in}\;\Varid{e}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage} \ensuremath{\Rrightarrow }
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{e}\;[\mskip1.5mu \Varid{x}\to\Varid{y}\mskip1.5mu]{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}\vspace{-4ex}\\
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;\Varid{x}\mathrel{=}\Varid{x}\;\mathbf{in}\;\Varid{e}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage} \ensuremath{\Rrightarrow }
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;\Varid{x}\mathrel{=}\Varid{loop}\;\mathbf{in}\;\Varid{e}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}\\
\textbf{Case Fill}\\
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{9}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{case}\;{}\<[9]%
\>[9]{}\Varid{e}\;\mathbf{of}{}\<[E]%
\\
\>[9]{}\Conid{True}\to \Varid{e}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage} \ensuremath{\Rrightarrow }
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{9}{@{}>{\hspre}l<{\hspost}@{}}%
\column{16}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{case}\;{}\<[9]%
\>[9]{}\Varid{e}\;\mathbf{of}{}\<[E]%
\\
\>[9]{}\Conid{True}{}\<[16]%
\>[16]{}\to \Varid{e}{}\<[E]%
\\
\>[9]{}\Conid{False}{}\<[16]%
\>[16]{}\to \bot {}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}\\

\caption{GAS rules for putting FlatCurry programs into canonical form (continued)}
\label{fig:canonical2}
\end{figure}

While most of these transformations are simple,
a few require some explanation.
The \textbf{blocks} transformation takes a let block with multiple variable definitions,
and rewrites it to a series of let blocks where all variables are split into
strongly connected components.
This isn't strictly necessary,
but it removes the need to check for mutual recursion during the optimization phase.
It will often transform a block of mutually defined variables into a cascading 
series of let expressions with a single variable,
which will allow more optimizations to run throughout the compiler.

The \textbf{alias} transformation will remove any aliased variables.
If one variables is aliased to another, then it will do the substitution,
but if a variable is aliased to itself, then it cannot be reduced to a normal form,
so we can replace it with an infinite loop.


Finally the \textbf{Fill cases} transformation completes the definitional tree.
If we have a case with branches for constructors \ensuremath{\Conid{C}_{\mathrm{1}},\Conid{C}_{\mathrm{2}}\ldots \Conid{C}_{\Varid{k}}},
then we look up the type \ensuremath{\Conid{T}} that all of these constructor belong to.
Next we get the list \ensuremath{\Conid{Ctrs}} of all constructors that belonging to \ensuremath{\Conid{T}}.
This list will contain \ensuremath{\Conid{C}_{\mathrm{1}},\Conid{C}_{\mathrm{2}},\ldots \Conid{C}_{\Varid{n}}}, but it may contain more.
For each constructor not represented in the case-expression,
we create a new branch \ensuremath{\Conid{C}_{\Varid{i}}\to \bot }.

After running all of these transformations, our program is in canonical form,
and we may choose to optimize it, or we may skip straight to the post-processing phase.
At this point we only need two transformations for post-processing
however, we will need to add more to support some of the optimizations.
If we ever have an expression of the form \ensuremath{\mathbf{let}\;\Varid{x}\mathrel{=}\mathbf{case}\ldots }, then we need to transform the
case-expression into a function call.
We don't do this transformation in pre-processing
because we don't want to split functions apart during optimizations.
The \textbf{Let-Case} transformation has a single rule given in figure \ref{fig:letcase}.

\begin{figure}
\textbf{Let Case}\\
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{6}{@{}>{\hspre}c<{\hspost}@{}}%
\column{6E}{@{}l@{}}%
\column{9}{@{}>{\hspre}l<{\hspost}@{}}%
\column{24}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{f}\;\overline{\Varid{v}} {}\<[E]%
\\
\>[3]{}\hsindent{3}{}\<[6]%
\>[6]{}\mathrel{=}{}\<[6E]%
\>[9]{}\mathbf{let}\;\Varid{x}\mathrel{=}\mathbf{case}\;{}\<[24]%
\>[24]{}\Varid{e}\;\mathbf{of}{}\<[E]%
\\
\>[24]{}\overline{\Varid{p}_{\Varid{i}}\to \Varid{e}_{\Varid{i}}} {}\<[E]%
\\
\>[9]{}\mathbf{in}\;\Varid{e'}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage} \ensuremath{\Rrightarrow }
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{18}{@{}>{\hspre}c<{\hspost}@{}}%
\column{18E}{@{}l@{}}%
\column{21}{@{}>{\hspre}l<{\hspost}@{}}%
\column{27}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{f}\;\overline{\Varid{v}} {}\<[18]%
\>[18]{}\mathrel{=}{}\<[18E]%
\>[21]{}\mathbf{let}\;\Varid{x}\mathrel{=}\Varid{f}_{\mathrm{1}}\;\overline{\Varid{x}} {}\<[E]%
\\
\>[21]{}\mathbf{in}\;\Varid{e'}{}\<[E]%
\\
\>[3]{}\Varid{f}_{\mathrm{1}}\;\overline{\Varid{x}} {}\<[18]%
\>[18]{}\mathrel{=}{}\<[18E]%
\>[21]{}\mathbf{case}\;{}\<[27]%
\>[27]{}\Varid{e}\;\mathbf{of}{}\<[E]%
\\
\>[27]{}\overline{\Varid{p}_{\Varid{i}}\to \Varid{e}_{\Varid{i}}} {}\<[E]%
\ColumnHook
\end{hscode}\resethooks
Where $\overline{x}$ are free variables of $e$ and $\overline{e_i}$.
% >  where vec x = freeVars e : vec e_i
\end{minipage}\\
\textbf{Var Case}\\
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{case}\;\Varid{e}\;\mathbf{of}\;\Varid{alts}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage} \ensuremath{\Rrightarrow }
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;\Varid{x}\mathrel{=}\Varid{e}\;\mathbf{in}\;\mathbf{case}\;\Varid{x}\;\mathbf{of}\;\Varid{alts}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}\\
\caption{Rule for moving a let bound case out of a function, 
         and eliminating compound expressions in case-expressions.}
\label{fig:letcase}
\end{figure}

Every let with a case-expression creates a new function \ensuremath{\Varid{f}\#\Varid{n}}
where \ensuremath{\Varid{n}} is incremented every time.

Finally, in our post-processing phase we simply factor out 
the scrutinee of a case-expression into a variable.
The transformation is straightforward.
An example of a pre-process derivation is given in \ref{fig:preprocess_example}.
At this point we are ready to transform the canonicalized FlatCurry into ICurry.

\begin{figure}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{30}{@{}>{\hspre}l<{\hspost}@{}}%
\column{37}{@{}>{\hspre}c<{\hspost}@{}}%
\column{37E}{@{}l@{}}%
\column{41}{@{}>{\hspre}l<{\hspost}@{}}%
\column{46}{@{}>{\hspre}l<{\hspost}@{}}%
\column{51}{@{}>{\hspre}l<{\hspost}@{}}%
\column{52}{@{}>{\hspre}l<{\hspost}@{}}%
\column{57}{@{}>{\hspre}l<{\hspost}@{}}%
\column{59}{@{}>{\hspre}l<{\hspost}@{}}%
\column{64}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{powaux}\;\Varid{v}_{\mathrm{1}}\;\Varid{v}_{\mathrm{2}}\;\Varid{v}_{\mathrm{3}}\mathrel{=}\mathbf{case}\;{}\<[30]%
\>[30]{}(\Varid{==})\;\Varid{v}_{\mathrm{3}}\;\mathrm{0}\;\mathbf{of}{}\<[E]%
\\
\>[30]{}\Conid{True}{}\<[37]%
\>[37]{}\to {}\<[37E]%
\>[41]{}\Varid{v}_{\mathrm{1}}{}\<[E]%
\\
\>[30]{}\Conid{False}{}\<[37]%
\>[37]{}\to {}\<[37E]%
\>[41]{}\mathbf{let}\;{}\<[46]%
\>[46]{}\Varid{v}_{\mathrm{4}}\mathrel{=}\Varid{square}\;\Varid{v}_{\mathrm{2}}{}\<[E]%
\\
\>[46]{}\Varid{v}_{\mathrm{5}}\mathrel{=}\Varid{halve}\;\Varid{v}_{\mathrm{3}}{}\<[E]%
\\
\>[41]{}\mathbf{in}\;{}\<[46]%
\>[46]{}\mathbf{case}\;{}\<[52]%
\>[52]{}(\Varid{==})\;\boxed{(\Varid{apply}\;(\Varid{apply}\;\Varid{mod}\;\Varid{v}_{\mathrm{3}})\;\mathrm{2})\;\mathrm{1}}\;\mathbf{of}{}\<[E]%
\\
\>[52]{}\Conid{True}{}\<[59]%
\>[59]{}\to \Varid{powaux}\;((\mathbin{*})\;\Varid{v}_{\mathrm{1}}\;\Varid{v}_{\mathrm{2}})\;\Varid{v4}\;\Varid{v5}{}\<[E]%
\\
\>[52]{}\Conid{False}{}\<[59]%
\>[59]{}\to \Varid{powaux}\;\Varid{v}_{\mathrm{1}}\;\Varid{v}_{\mathrm{4}}\;\Varid{v}_{\mathrm{5}}{}\<[E]%
\\
\>[3]{}\Rrightarrow \textbf{Double Apply}\;[\mskip1.5mu \mathrm{1},\mathbin{-}\mathrm{1},\mathbin{-}\mathrm{1},\mathrm{0}\mskip1.5mu]{}\<[E]%
\\
\>[3]{}\Varid{powaux}\;\Varid{v}_{\mathrm{1}}\;\Varid{v}_{\mathrm{2}}\;\Varid{v}_{\mathrm{3}}\mathrel{=}\mathbf{case}\;{}\<[30]%
\>[30]{}(\Varid{==})\;\Varid{v}_{\mathrm{3}}\;\mathrm{0}\;\mathbf{of}{}\<[E]%
\\
\>[30]{}\Conid{True}{}\<[37]%
\>[37]{}\to {}\<[37E]%
\>[41]{}\Varid{v}_{\mathrm{1}}{}\<[E]%
\\
\>[30]{}\Conid{False}{}\<[37]%
\>[37]{}\to {}\<[37E]%
\>[41]{}\mathbf{let}\;{}\<[46]%
\>[46]{}\Varid{v}_{\mathrm{4}}\mathrel{=}\boxed{\Varid{square}\;\Varid{v}_{\mathrm{2}}}{}\<[E]%
\\
\>[46]{}\Varid{v}_{\mathrm{5}}\mathrel{=}\boxed{\Varid{halve}\;\Varid{v}_{\mathrm{3}}}{}\<[E]%
\\
\>[41]{}\mathbf{in}\;{}\<[46]%
\>[46]{}\mathbf{case}\;{}\<[52]%
\>[52]{}(\Varid{==})\;(\Varid{apply}\;\Varid{mod}\;\Varid{v}_{\mathrm{3}}\;\mathrm{2})\;\mathrm{1}\;\mathbf{of}{}\<[E]%
\\
\>[52]{}\Conid{True}{}\<[59]%
\>[59]{}\to \Varid{powaux}\;((\mathbin{*})\;\Varid{v}_{\mathrm{1}}\;\Varid{v}_{\mathrm{2}})\;\Varid{v}_{\mathrm{4}}\;\Varid{v}_{\mathrm{5}}{}\<[E]%
\\
\>[52]{}\Conid{False}{}\<[59]%
\>[59]{}\to \Varid{powaux}\;\Varid{v}_{\mathrm{1}}\;\Varid{v}_{\mathrm{4}}\;\Varid{v}_{\mathrm{5}}{}\<[E]%
\\
\>[3]{}\Rrightarrow \textbf{Blocks}\;[\mskip1.5mu \mathrm{1}\mskip1.5mu]{}\<[E]%
\\
\>[3]{}\Varid{powaux}\;\Varid{v}_{\mathrm{1}}\;\Varid{v}_{\mathrm{2}}\;\Varid{v}_{\mathrm{3}}\mathrel{=}\mathbf{case}\;{}\<[30]%
\>[30]{}((\Varid{==})\;\Varid{v}_{\mathrm{3}}\;\mathrm{0})\;\mathbf{of}{}\<[E]%
\\
\>[30]{}\Conid{True}{}\<[37]%
\>[37]{}\to {}\<[37E]%
\>[41]{}\Varid{v}_{\mathrm{1}}{}\<[E]%
\\
\>[30]{}\Conid{False}{}\<[37]%
\>[37]{}\to {}\<[37E]%
\>[41]{}\mathbf{let}\;{}\<[46]%
\>[46]{}\Varid{v}_{\mathrm{4}}\mathrel{=}\Varid{square}\;\Varid{v}_{\mathrm{2}}{}\<[E]%
\\
\>[41]{}\mathbf{in}\;{}\<[46]%
\>[46]{}\mathbf{let}\;{}\<[51]%
\>[51]{}\Varid{v}_{\mathrm{5}}\mathrel{=}\Varid{halve}\;\Varid{v}_{\mathrm{3}}{}\<[E]%
\\
\>[46]{}\mathbf{in}\;{}\<[51]%
\>[51]{}\mathbf{case}\;{}\<[57]%
\>[57]{}(\Varid{==})\;(\Varid{apply}\;\Varid{mod}\;\Varid{v}_{\mathrm{3}}\;\mathrm{2})\;\mathrm{1}\;\mathbf{of}{}\<[E]%
\\
\>[57]{}\Conid{True}{}\<[64]%
\>[64]{}\to \Varid{powaux}\;((\mathbin{*})\;\Varid{v}_{\mathrm{1}}\;\Varid{v}_{\mathrm{2}})\;\Varid{v}_{\mathrm{4}}\;\Varid{v}_{\mathrm{5}}{}\<[E]%
\\
\>[57]{}\Conid{False}{}\<[64]%
\>[64]{}\to \Varid{powaux}\;\Varid{v}_{\mathrm{1}}\;\Varid{v}_{\mathrm{4}}\;\Varid{v}_{\mathrm{5}}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
    \caption{Reducing the \ensuremath{\Varid{powaux}} function defined in the standard Float library.
             The first reduction occurs in the \ensuremath{\Conid{False}} branch \ensuremath{[\mskip1.5mu \mathrm{1}\mskip1.5mu]} or the in expression [-1]
             in the scrutinee of the case [-1] in the first argument of the apply node [0],
             so it has a path of [1,-1,-1,0].}
    \label{fig:preprocess_example}
\end{figure}

\section{Compiling to ICurry}

ICurry is meant to be a bridge between Curry code and imperative languages like C, Python, and Assembly.
The let and case-expressions have been transformed into statements,
and variables have been explicitly declared.
All mutually recursive declarations are broken here into two steps:
Declare memory for each node, 
then fill in the pointers.
This allows us to create expression graphs with loops in them.
Each function is organized into a sequence of blocks,
and each block is broken up into declarations, assignments, and a single statement.
A statement can either fail, return a new expression graph, 
or inspect a single variable to choose a case.


\begin{figure}[t]\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{13}{@{}>{\hspre}c<{\hspost}@{}}%
\column{13E}{@{}l@{}}%
\column{17}{@{}>{\hspre}l<{\hspost}@{}}%
\column{22}{@{}>{\hspre}l<{\hspost}@{}}%
\column{47}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{p}{}\<[13]%
\>[13]{}\Rightarrow {}\<[13E]%
\>[17]{}\overline{\Varid{t}} \;\overline{\Varid{f}} \;{}\<[47]%
\>[47]{}\Varid{program}{}\<[E]%
\\
\>[3]{}\Varid{t}{}\<[13]%
\>[13]{}\Rightarrow {}\<[13E]%
\>[17]{}\overline{\Conid{C}} \;{}\<[47]%
\>[47]{}\Varid{datatype}{}\<[E]%
\\
\>[3]{}\Varid{f}{}\<[13]%
\>[13]{}\Rightarrow {}\<[13E]%
\>[17]{}\Varid{name}\mathrel{=}\Varid{b}\;{}\<[47]%
\>[47]{}\Varid{function}{}\<[E]%
\\
\>[3]{}\Varid{b}{}\<[13]%
\>[13]{}\Rightarrow {}\<[13E]%
\>[17]{}\overline{\Varid{d}} \;{}\<[47]%
\>[47]{}\Varid{block}{}\<[E]%
\\
\>[17]{}\overline{\Varid{a}} {}\<[E]%
\\
\>[17]{}\Varid{s}{}\<[E]%
\\
\>[3]{}\Varid{d}{}\<[13]%
\>[13]{}\Rightarrow {}\<[13E]%
\>[17]{}\text{declare} \;\Varid{x}\;{}\<[47]%
\>[47]{}\Varid{variable}\;\Varid{declaration}{}\<[E]%
\\
\>[13]{}\mid {}\<[13E]%
\>[17]{}\Varid{declfree}\;\Varid{x}\;{}\<[47]%
\>[47]{}\textbf{free} \;\Varid{variable}\;\Varid{declaration}{}\<[E]%
\\
\>[3]{}\Varid{a}{}\<[13]%
\>[13]{}\Rightarrow {}\<[13E]%
\>[17]{}\Varid{v}\mathrel{=}\Varid{e}{}\<[E]%
\\
\>[3]{}\Varid{s}{}\<[13]%
\>[13]{}\Rightarrow {}\<[13E]%
\>[17]{}\Varid{return}\;\Varid{e}\;{}\<[47]%
\>[47]{}\Varid{return}\;\Varid{statement}{}\<[E]%
\\
\>[13]{}\mid {}\<[13E]%
\>[17]{}\bot \;{}\<[47]%
\>[47]{}\Varid{failure}{}\<[E]%
\\
\>[13]{}\mid {}\<[13E]%
\>[17]{}\mathbf{case}\;\Varid{x}\;\mathbf{of}\;{}\<[47]%
\>[47]{}\mathbf{case}\;\Varid{statement}{}\<[E]%
\\
\>[17]{}\hsindent{5}{}\<[22]%
\>[22]{}\overline{\Conid{C}\to \Varid{b}} {}\<[E]%
\\
\>[3]{}\Varid{e}{}\<[13]%
\>[13]{}\Rightarrow {}\<[13E]%
\>[17]{}\Varid{v}\;{}\<[47]%
\>[47]{}\Varid{variable}\;\Varid{expression}{}\<[E]%
\\
\>[13]{}\mid {}\<[13E]%
\>[17]{}\Conid{NODE}\;(\Varid{l},\overline{\Varid{e}} )\;{}\<[47]%
\>[47]{}\Varid{node}\;\Varid{creation}{}\<[E]%
\\
\>[13]{}\mid {}\<[13E]%
\>[17]{}\Varid{e}_{\mathrm{1}}\mathbin{?}\Varid{e}_{\mathrm{2}}\;{}\<[47]%
\>[47]{}\Varid{choice}\;\Varid{expression}{}\<[E]%
\\
\>[3]{}\Varid{v}{}\<[13]%
\>[13]{}\Rightarrow {}\<[13E]%
\>[17]{}\Varid{x}\;{}\<[47]%
\>[47]{}\Varid{local}\;\Varid{variable}{}\<[E]%
\\
\>[13]{}\mid {}\<[13E]%
\>[17]{}\Varid{v}\;[\mskip1.5mu \Varid{i}\mskip1.5mu]\;{}\<[47]%
\>[47]{}\Varid{variable}\;\Varid{access}{}\<[E]%
\\
\>[13]{}\mid {}\<[13E]%
\>[17]{}\Conid{ROOT}\;{}\<[47]%
\>[47]{}\Varid{root}\;\Varid{variable}{}\<[E]%
\\
\>[3]{}\Varid{l}{}\<[13]%
\>[13]{}\Rightarrow {}\<[13E]%
\>[17]{}\Conid{C}_{\Varid{k}}\;{}\<[47]%
\>[47]{}\Varid{constructor}\;\Varid{label}{}\<[E]%
\\
\>[13]{}\mid {}\<[13E]%
\>[17]{}\Varid{f}_{\Varid{k}}\;{}\<[47]%
\>[47]{}\Varid{function}\;\Varid{label}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\caption{Abstract syntax of function definitions in ICurry}
\label{fig:iCurrySyntax}
\end{figure}

After we've finished transforming the FlatCurry,
the transformation to ICurry is much easier to implement.
The algorithm from \cite{icurry}, given in figure \ref{fig:flatCurryiCurry}, 
can be applied directly to the translated program.
We show an example of translating the function \ensuremath{\Varid{f}} from figure \ref{fig:stages}
into ICurry in figure \ref{fig:icurryStage}.

The algorithm itself is broken up into 6 pieces.
First \ensuremath{\mathcal{F} } Compiles a FlatCurry function into an ICurry function.
Then \ensuremath{\mathcal{B} } takes the function arguments, the expression, and the root,
and compiles it into a block.
We factor out \ensuremath{\mathcal{B} } instead of leaving it a part of \ensuremath{\mathcal{F} }
because we will be able to recursively call it to construct nested blocks.
This is also why we pass in a root parameter.
In subsequent calls, the scrutinee of a case expression.
While this isn't explicit in the algorithm here,
in our implementation, the root of any block under a case expression
is always \ensuremath{\Varid{v}_{\mathrm{1}}}.
This will become the variable \texttt{scrutenee} from the C code in chapter 3.
Next we declare variables with the \ensuremath{\mathcal{D} } function.
Each variables bound by a \ensuremath{\mathbf{let}} or \ensuremath{\textbf{free} } expression must be declared.
We also declare a variable for the scrutinee of the case statement, if this block has one.
Then, \ensuremath{\mathcal{R} } generates code for the return value.
If the expression is a case, 
then examine the case variable and generate code for the associated blocks,
otherwise we return the expression.
Finally \ensuremath{\mathcal{E} } generates code for constructing a piece of the expression graph.
If the expression contains choices, function calls, or constructor calls, then
the corresponding nodes are generated.
If the expression is a variable, then it is returned.
If the expression is a let or a free expression, then the principal expression is generated.



\begin{figure}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{44}{@{}>{\hspre}c<{\hspost}@{}}%
\column{44E}{@{}l@{}}%
\column{48}{@{}>{\hspre}l<{\hspost}@{}}%
\column{61}{@{}>{\hspre}l<{\hspost}@{}}%
\column{65}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[B]{}\mathcal{F} \;(\Varid{f}\;\overline{\Varid{x}} \mathrel{=}\Varid{e}){}\<[44]%
\>[44]{}\mathbin{:=}{}\<[44E]%
\>[48]{}\Varid{f}\mathrel{=}\mathcal{B} \;(\overline{\Varid{x}} ,\Varid{e},\Conid{ROOT}){}\<[E]%
\\[\blanklineskip]%
\>[B]{}\mathcal{B} \;(\overline{\Varid{x}} ,\bot ,\Varid{root}){}\<[44]%
\>[44]{}\mathbin{:=}{}\<[44E]%
\>[48]{}\bot {}\<[E]%
\\
\>[B]{}\mathcal{B} \;(\overline{\Varid{x}} ,\Varid{e},\Varid{root}){}\<[44]%
\>[44]{}\mathbin{:=}{}\<[44E]%
\>[48]{}\overline{\text{declare} \;\Varid{x}} {}\<[E]%
\\
\>[48]{}\mathcal{D} \;(\Varid{e}){}\<[E]%
\\
\>[48]{}\overline{\Varid{x}_{\Varid{i}}\mathrel{=}\Varid{root}\;[\mskip1.5mu \Varid{i}\mskip1.5mu]} {}\<[E]%
\\
\>[48]{}\mathcal{A} \;(\Varid{e}){}\<[E]%
\\
\>[48]{}\mathcal{R} \;(\Varid{e}){}\<[E]%
\\[\blanklineskip]%
\>[B]{}\mathcal{D} \;(\mathbf{let}\;\overline{\Varid{x}} \;\textbf{free} \;\mathbf{in}\;\Varid{e}){}\<[44]%
\>[44]{}\mathbin{:=}{}\<[44E]%
\>[48]{}\text{free} \;\overline{\Varid{x}} {}\<[E]%
\\
\>[B]{}\mathcal{D} \;(\mathbf{let}\;\overline{\Varid{x}\mathrel{=}\Varid{e}} \;\mathbf{in}\;\Varid{e'}){}\<[44]%
\>[44]{}\mathbin{:=}{}\<[44E]%
\>[48]{}\text{declare} \;\overline{\Varid{x}} {}\<[E]%
\\
\>[B]{}\mathcal{D} \;(\mathbf{case}\;\Varid{e}\;\mathbf{of}\;\overline{\Varid{p}\to \Varid{e'}} ){}\<[44]%
\>[44]{}\mathbin{:=}{}\<[44E]%
\>[48]{}\text{declare} \;\Varid{x}_{\Varid{e}}{}\<[E]%
\\[\blanklineskip]%
\>[B]{}\mathcal{A} \;(\mathbf{let}\;\overline{\Varid{x}\mathrel{=}\Varid{e}} \;\mathbf{in}\;\Varid{e'}){}\<[44]%
\>[44]{}\mathbin{:=}{}\<[44E]%
\>[48]{}\overline{\Varid{x}\mathrel{=}\mathcal{E} \;(\Varid{e})} {}\<[E]%
\\
\>[48]{}[\mskip1.5mu \Varid{x}_{\Varid{i}}\;[\mskip1.5mu \Varid{p}\mskip1.5mu]\mathrel{=}\Varid{x}_{\Varid{j}}\mid {}\<[65]%
\>[65]{}\Varid{x}_{\Varid{i}}\in \overline{\Varid{x}} ,{}\<[E]%
\\
\>[65]{}\Varid{x}_{\Varid{j}}\in \overline{\Varid{x}} ,{}\<[E]%
\\
\>[65]{}\Varid{e}_{\Varid{i}}|_{\Varid{p}}\mathrel{=}\Varid{x}_{\Varid{j}}\mskip1.5mu]{}\<[E]%
\\[\blanklineskip]%
\>[B]{}\mathcal{A} \;(\mathbf{case}\;\Varid{e}\;\mathbf{of}\;\anonymous ){}\<[44]%
\>[44]{}\mathbin{:=}{}\<[44E]%
\>[48]{}\Varid{x}_{\Varid{e}}\mathrel{=}\mathcal{E} \;(\Varid{e}){}\<[E]%
\\[\blanklineskip]%
\>[B]{}\mathcal{R} \;(\mathbf{case}\;\anonymous \;\mathbf{of}\;\overline{\Conid{C}\;(\overline{\Varid{x}} )\to \Varid{e}} ){}\<[44]%
\>[44]{}\mathbin{:=}{}\<[44E]%
\>[48]{}\mathbf{case}\;\Varid{x}_{\Varid{e}}\;\mathbf{of}\;{}\<[61]%
\>[61]{}\mathcal{B} \;(\overline{\Varid{x}} ,\Varid{e},\Varid{x}_{\Varid{e}}){}\<[E]%
\\
\>[B]{}\mathcal{R} \;(\Varid{e}){}\<[44]%
\>[44]{}\mathbin{:=}{}\<[44E]%
\>[48]{}\Varid{return}\;\Conid{E}\;(\Varid{e}){}\<[E]%
\\[\blanklineskip]%
\>[B]{}\mathcal{E} \;(\Varid{x}){}\<[44]%
\>[44]{}\mathbin{:=}{}\<[44E]%
\>[48]{}\Varid{x}{}\<[E]%
\\
\>[B]{}\mathcal{E} \;(\Conid{C}_{\Varid{k}}\;\overline{\Varid{e}} ){}\<[44]%
\>[44]{}\mathbin{:=}{}\<[44E]%
\>[48]{}\Conid{NODE}\;(\Conid{C}_{\Varid{k}},\overline{\mathcal{E} \;(\Varid{e})} ){}\<[E]%
\\
\>[B]{}\mathcal{E} \;(\Varid{f}_{\Varid{k}}\;\overline{\Varid{e}} ){}\<[44]%
\>[44]{}\mathbin{:=}{}\<[44E]%
\>[48]{}\Conid{NODE}\;(\Varid{f}_{\Varid{k}},\overline{\mathcal{E} \;(\Varid{e})} ){}\<[E]%
\\
\>[B]{}\mathcal{E} \;(\Varid{e}_{\mathrm{1}}\mathbin{?}\Varid{e}_{\mathrm{2}}){}\<[44]%
\>[44]{}\mathbin{:=}{}\<[44E]%
\>[48]{}\mathcal{E} \;(\Varid{e}_{\mathrm{1}})\mathbin{?}\mathcal{E} \;(\Varid{e}_{\mathrm{2}}){}\<[E]%
\\
\>[B]{}\mathcal{E} \;(\mathbf{let}\;\overline{\Varid{x}\mathrel{=}\Varid{e}} \;\mathbf{in}\;\Varid{e'}){}\<[44]%
\>[44]{}\mathbin{:=}{}\<[44E]%
\>[48]{}\mathcal{E} \;(\Varid{e}){}\<[E]%
\\
\>[B]{}\mathcal{E} \;(\mathbf{let}\;\overline{\Varid{x}} \;\textbf{free} \;\mathbf{in}\;\Varid{e}){}\<[44]%
\>[44]{}\mathbin{:=}{}\<[44E]%
\>[48]{}\mathcal{E} \;(\Varid{e}){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\caption{Algorithm for translating FlatCurry into ICurry}
\label{fig:flatCurryiCurry}
\end{figure}

\begin{figure}
After Post-processing\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{12}{@{}>{\hspre}l<{\hspost}@{}}%
\column{17}{@{}>{\hspre}l<{\hspost}@{}}%
\column{20}{@{}>{\hspre}l<{\hspost}@{}}%
\column{22}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{f}\;\Varid{v}_{\mathrm{2}}\mathrel{=}{}\<[12]%
\>[12]{}\mathbf{let}\;{}\<[17]%
\>[17]{}\Varid{v}_{\mathrm{3}}\mathrel{=}\Varid{f}_{\mathrm{0}}\;\Varid{v}_{\mathrm{2}}{}\<[E]%
\\
\>[12]{}\mathbf{in}\;{}\<[17]%
\>[17]{}\mathbf{let}\;{}\<[22]%
\>[22]{}\Varid{v}_{\mathrm{4}}\mathrel{=}\Varid{f}_{\mathrm{1}}\;\Varid{v}_{\mathrm{2}}{}\<[E]%
\\
\>[17]{}\mathbf{in}\;{}\<[22]%
\>[22]{}\Varid{v}_{\mathrm{3}}\mathbin{?}\Varid{v}_{\mathrm{4}}{}\<[E]%
\\
\>[3]{}\Varid{f}_{\mathrm{0}}\;\Varid{v}_{\mathrm{2}}\mathrel{=}\textbf{fcase} \;{}\<[20]%
\>[20]{}\Varid{v}_{\mathrm{2}}\;\mathbf{of}{}\<[E]%
\\
\>[20]{}\Conid{True}\to \Conid{False}{}\<[E]%
\\
\>[20]{}\Conid{False}\to \bot {}\<[E]%
\\
\>[3]{}\Varid{f}_{\mathrm{1}}\;\Varid{v}_{\mathrm{2}}\mathrel{=}\textbf{fcase} \;{}\<[20]%
\>[20]{}\Varid{v}_{\mathrm{2}}\;\mathbf{of}{}\<[E]%
\\
\>[20]{}\Conid{True}\to \Conid{False}{}\<[E]%
\\
\>[20]{}\Conid{False}\to \Conid{True}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
ICurry\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{5}{@{}>{\hspre}l<{\hspost}@{}}%
\column{7}{@{}>{\hspre}l<{\hspost}@{}}%
\column{9}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{f}\mathbin{/}\mathrm{1}\mathbin{:}\{\mskip1.5mu {}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\text{declare} \;\Varid{x}_{\mathrm{2}}{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\text{declare} \;\Varid{x}_{\mathrm{3}}{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\text{declare} \;\Varid{x}_{\mathrm{4}}{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\Varid{x}_{\mathrm{2}}\mathrel{=}\Conid{ROOT}\;[\mskip1.5mu \mathrm{0}\mskip1.5mu]{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\Varid{x}_{\mathrm{3}}\mathrel{=}\Varid{f}_{\mathrm{0}}\;(\Varid{x}_{\mathrm{2}}){}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\Varid{x}_{\mathrm{4}}\mathrel{=}\Varid{f}_{\mathrm{1}}\;(\Varid{x}_{\mathrm{2}}){}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\Varid{return}\;(\Varid{x}_{\mathrm{3}}\mathbin{?}\Varid{x}_{\mathrm{4}}){}\<[E]%
\\
\>[3]{}\mskip1.5mu\}{}\<[E]%
\\
\>[3]{}\Varid{f}_{\mathrm{0}}\mathbin{/}\mathrm{1}\mathbin{:}\{\mskip1.5mu {}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\text{declare} \;\Varid{x}_{\mathrm{2}}{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\Varid{x}_{\mathrm{2}}\mathrel{=}\Conid{ROOT}\;[\mskip1.5mu \mathrm{0}\mskip1.5mu]{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mathbf{case}\;\Varid{x}_{\mathrm{2}}\;\mathbf{of}{}\<[E]%
\\
\>[5]{}\hsindent{2}{}\<[7]%
\>[7]{}\Conid{True}\mathbin{/}\mathrm{0}\to \{\mskip1.5mu {}\<[E]%
\\
\>[7]{}\hsindent{2}{}\<[9]%
\>[9]{}\Varid{return}\;\Conid{False}\;(){}\<[E]%
\\
\>[5]{}\hsindent{2}{}\<[7]%
\>[7]{}\mskip1.5mu\}{}\<[E]%
\\
\>[5]{}\hsindent{2}{}\<[7]%
\>[7]{}\Conid{False}\mathbin{/}\mathrm{0}\to \{\mskip1.5mu {}\<[E]%
\\
\>[7]{}\hsindent{2}{}\<[9]%
\>[9]{}\Varid{exempt}{}\<[E]%
\\
\>[5]{}\hsindent{2}{}\<[7]%
\>[7]{}\mskip1.5mu\}{}\<[E]%
\\
\>[3]{}\mskip1.5mu\}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\caption{translating \ensuremath{\Varid{f}} and \ensuremath{\Varid{f}_{\mathrm{0}}} into icurry.\\
         We omit \ensuremath{\Varid{f}_{\mathrm{1}}} for space, and because it's largely the same as \ensuremath{\Varid{f}_{\mathrm{0}}}.}
\label{fig:icurryStage}
\end{figure}

\section{Generating C Code}

Now that we have a program in ICurry, we can translate this to C.
We already have a good idea of what the C code should look like,
and our ICurry structure fits closely with this.
The difference is that we need to be sure to declare and allocate memory for all variables,
which leads to a split in the structure of the generated code.
The code responsible for creating expression graphs and declaring memory will
go in the *.h file, and the code for executing the hnf function will go in the *.c file.
This is a common pattern for structuring C and C++ code,
so it's not surprising that we take the same approach.

For each Data type \ensuremath{\Conid{D}}, we generate both a \texttt{make\_D} function and a \texttt{set\_D}.
The difference is that \texttt{make\_D} will allocate memory for a new node, while \texttt{set\_D}
takes an existing node as a parameter, and transforms it to the given type of node.
We do the same thing for every ICurry function \ensuremath{\Varid{f}},
and produce a \texttt{make\_f} and \texttt{set\_f} function in C.
Each node contains a \texttt{symbol}, that denotes the type of node, and holds information
such as the name, arity, and hnf function of the node.
Along with setting the \texttt{symbol} from chapter \ref{ch:The Generated Code},
the make and set functions reset the nondet flag to \texttt{false},
and set any children that were passed into the node.


The code to generate the C source file is given in 
figures \ref{fig:cprog}, \ref{fig:cstmt}, and \ref{fig:cexpr}.
This is a standard syntax directed translation.
We hold of on showing the generated code for literal cases until Chapter \ref{ch:Memory Optimizations}
where we discuss our implementation of unboxing.
We also skip over the generation of the functions for case expressions discussed in section
\ref{Non-determinism}.
The code for this is largely the same.
We just begin generating code at each block inside the function, after the declarations and assignments.

The translation is similar to how we translated ICurry programs.
Figure \ref{fig:cprog} is the main entry point.
We translate the function, blocks, declarations, and assignments.
$\mathcal{F}$\index{$\mathcal{F}$} translates an  ICurry function to a C function.
$\mathcal{B}$\index{$\mathcal{B}$} translates an ICurry block.
Along with the block to translate, we also pass in the function name, and current path
to the block.
This allows us to generate unique names for each of the functions for case expressions.
We will use this information in the call to \texttt{save}, which pushes a rewrite onto
the backtracking stack.
The $\mathcal{D}$\index{$\mathcal{D}$} function translates a variable declaration,
and $\mathcal{A}$\index{$\mathcal{A}$} translates an assignment.

Figure \ref{fig:cstmt} generates code for translating statements.
The $\mathcal{S}$\index{$\mathcal{S}$} function translates an ICurry statement.
Both \ensuremath{\Varid{return}} and \ensuremath{\bot } just set the root of the expression to the appropriate value,
but case statements require us to generate the switch case loop from figure \ref{fig:notInit}.
Most of the loop is largely identical to the example,
but to simplify the code generation process, we introduce a function \texttt{save},
which takes the root node, and a copy of the current function at this particular case,
and pushes it on the backtracking stack.
The notation $f\vert_p$ is read as the function with symbol $f$ at the position $p$,
and is just a unique identifier for this particular case statement.
We also use a helper function $FV$ to find all of the free variables in the rest of the body,
since those will be needed to construct $f\vert_p$.

Finally figure \ref{fig:cexpr} translates free variables, case branches, and expressions to C.
The $\mathcal{V}$ \index{$\mathcal{V}$} function generates code to translate free variables.
The final free variable, and the constructors containing free variables 
are pushed on the stack in reverse order.
Then we set the root to be the first constructor.
The $\mathcal{C}$ \index{$\mathcal{C}$} function translates a case branch to a C case statement.
We insert the check and call to the \texttt{save} function, and generate code for the block.
We split the generation of expressions into two functions.
The $\mathcal{E_S}$ \index{$\mathcal{E_S}$} function sets the root to an expression.
The $\mathcal{E_M}$ \index{$\mathcal{E_M}$} function creates nodes for a new expression.


\begin{figure}
\begin{tabular}{lcl}
$\mathcal{F}(f (\overline{v}) = b)$ & $\coloneqq$
 & \texttt{void }$f\_$\texttt{hnf(field root)}\\
 & & \texttt{\{}\\
 & & $\ \ \ \ $ $\mathcal{B}(b, f, \epsilon)$\\
 & & \texttt{\}}\\
$\mathcal{B}(\{\overline{d}; \overline{a}; s\}, f, p)$ & $\coloneqq $
 & $\mathcal{D}(\overline{d})$ \\
 & & $\mathcal{A}(\overline{a})$ \\
 & & $\mathcal{S}(\overline{s}, f, p)$\\
$\mathcal{D}(\text{declare}\ x)$ & $\coloneqq$ & \texttt{field v\_}$x$\texttt{;}\\
$\mathcal{D}(\text{declfree}\ x)$ & $\coloneqq$ & \texttt{field v\_}$x$\texttt{ = free\_var();}\\
$\mathcal{A}(x = e)$ & $\coloneqq$ & \texttt{v\_}$x$\texttt{ =} $\mathcal{E}_M(e)$\texttt{;}\\
$\mathcal{A}(x[i] = e)$ & $\coloneqq$ & \texttt{child\_at(v\_}$x,i$\texttt{) =} $\mathcal{E}_M(e)$\texttt{;}\\
\end{tabular}
\caption{Code for generating Programs, declarations, and assignments.}
\label{fig:cprog}
\end{figure}

\begin{figure}
\begin{tabular}{lcl}
$\mathcal{S}(\texttt{return } e, f, p)$ & $\coloneqq$ & $\mathcal{E}_S($\texttt{root},$e)$\\
& & \texttt{return;}\\
$\mathcal{S}(\bot, f, p)$ & $\coloneqq$ & \texttt{fail(root);}\\
& & \texttt{return;}\\
\end{tabular} \\
$\ $\\
\begin{tabular}{l}
$\mathcal{S}($\ensuremath{\mathbf{case}\;\Varid{x}\;\mathbf{of}\;\overline{\Conid{C}\to \Varid{b}} }$, f, p)$ $\coloneqq$ \\
$\ \ $ \texttt{bool nondet = false;}\\
$\ \ $ \texttt{field scrutinee = } $x$ \texttt{;}\\
$\ \ $ \texttt{while(true)}\\
$\ \ $ \texttt{\{}\\
$\ \ \ \ $ \texttt{nondet |= scrutinee.n->nondet;}\\
$\ \ \ \ $ \texttt{switch(scrutinee.n->symbol->tag)}\\
$\ \ \ \ $ \texttt{\{}\\
$\ \ \ \ \ \ $ \texttt{case FAIL\_TAG:}\\
$\ \ \ \ \ \ \ \ $ \texttt{if(nondet)}\\
$\ \ \ \ \ \ \ \ $ $\ \ $ \texttt{save(root, make\_}$f\vert_p(FV(e))\texttt{}$\texttt{);}\\
$\ \ \ \ \ \ \ \ $ \texttt{fail(root);}\\
$\ \ \ \ \ \ \ \ $ \texttt{return;}\\
$\ \ \ \ \ \ $ \texttt{case FUNCTION\_TAG:}\\
$\ \ \ \ \ \ \ \ $ \texttt{HNF(scrutinee);}\\
$\ \ \ \ \ \ \ \ $ \texttt{break;}\\
$\ \ \ \ \ \ $ \texttt{case CHOICE\_TAG:}\\
$\ \ \ \ \ \ \ \ $ \texttt{choose(scrutinee);}\\
$\ \ \ \ \ \ \ \ $ \texttt{break;}\\
$\ \ \ \ \ \ $ \texttt{case FORWARD\_TAG:}\\
$\ \ \ \ \ \ \ \ $ \texttt{scrutinee = scrutinee.n->children[0];}\\
$\ \ \ \ \ \ \ \ $ \texttt{break;}\\
$\ \ \ \ \ \ $ \texttt{}$\mathcal{V}(\overline{C})$\\
$\ \ \ \ \ \ $ \texttt{}$\overline{\mathcal{C}(C_i \to b_i, f, i:p)}$\\
$\ \ \ \ $ \texttt{\}}\\
$\ \ $ \texttt{\}}\\
\end{tabular}{l}
\caption{code for generating statements.}
\label{fig:cstmt}
\end{figure}

\begin{figure}
\noindent
\begin{tabular}{l}
$\mathcal{C}(C \to b, f, p) \coloneqq$\\
$\ \ $ \texttt{case }$C$\texttt{:}\\
$\ \ \ \ $ \texttt{if(nondet)}\\
$\ \ \ \ $ $\ \ $ \texttt{save(root, make\_}$f_p(FV(e))\texttt{}$\texttt{);}\\
$\ \ \ \ $ $B(b, f, p)$\\
\end{tabular}\\
$\ $\\
\begin{tabular}{l}
$\mathcal{V}(C:\overline{CS}) \coloneqq$\\
$\ \ $ \texttt{case FREE\_TAG:}\\
$\ \ \ \ $ \texttt{push\_frame(scrutinee, free\_var());}\\
$\ \ \ \ $ \texttt{push\_choice(scrutinee, make\_}$\overline{CS}$\texttt{\_free();}\\
$\ \ \ \ $ \texttt{set\_}$C$\texttt{\_free(scrutinee);}\\
$\ \ \ \ $ \texttt{nondet = true;}\\
$\ \ \ \ $ \texttt{break;}\\
\end{tabular}\\
$\ $\\
\begin{tabular}{lcl}
$\mathcal{E_S}(v)$ & $\coloneqq$ & \texttt{set\_forward(root,v\_}$v$\texttt{)}\\
$\mathcal{E_S}(NODE(C_k,\overline e))$ & $\coloneqq$ & \texttt{set\_}$C$\texttt{(root,}$\overline{\mathcal{E}_M(e)}, k)$\texttt{;}\\
$\mathcal{E_S}(NODE(f_k,\overline e))$ & $\coloneqq$ & \texttt{set\_}$f$\texttt{(root,}$\overline{\mathcal{E}_M(e)}, k)$\texttt{;}\\
% & & $f$\texttt{\_hnf(root);}\\
$\mathcal{E_S}(e_1 ? e_2)$ & $\coloneqq$ & \texttt{set\_choice}$(\mathcal{E}_M(e_1), \mathcal{E}_M(e_2))$\texttt{;}\\
% & & \texttt{choose(root);}\\
\end{tabular}\\
$\ $\\
\begin{tabular}{lcl}
$\mathcal{E_M}(v)$ & $\coloneqq$ & \texttt{v\_}$v$\\
$\mathcal{E_M}(NODE(C_k,\overline e))$ & $\coloneqq$ & \texttt{make\_}$C$\texttt{(root,}$\overline{\mathcal{E}_M(e)}, k)$\texttt{;}\\
$\mathcal{E_M}(NODE(f_k,\overline e))$ & $\coloneqq$ & \texttt{make\_}$f$\texttt{(root,}$\overline{\mathcal{E}_M(e)}, k)$\texttt{;}\\
$\mathcal{E_M}(e_1 ? e_2)$ & $\coloneqq$ & \texttt{make\_choice}$(\mathcal{E}_M(e_1), \mathcal{E}_M(e_2))$\texttt{;}\\
\end{tabular}
\caption{Code for generating cases, free variables, and expressions.}
\label{fig:cexpr}
\end{figure}


In this chapter we used this library to transform FlatCurry programs into a canonical form that we could then
translate to ICurry.  We also showed how to translate ICurry program to C.
In short we wrote the back end of a compiler in a simple, clear, and short implementation.
This shows the power of the GAS system for applying simple transformations to Curry programs.
In the next chapter we'll see how we can use it to write an Optimizer.
Now we're cooking with GAS!

\chapter{Basic Optimizations} \label{ch:Basic Optimizations}


In the last chapter we saw how the GAS tool
let us write transformation rules as rewrite rules in Curry.
The power of this tool came from two aspects.
The first is that it's easy to write rules syntactically.
The second is that the rules are written in Curry,
so we are not limited by our rewriting system.
We'll put this second part to use in optimizating Curry expressions.

In this chapter we outline a number of optimizations that were necessary
to implement in order for unboxing, deforestation, and shortcutting to be effective.
We start by introducing a new restriction on FlatCurry expressions
called Administrative Normal Form, or A-Normal Form.
This is a common form for functional program optimizers to take,
and it provides several benefits to Curry too.
We describe the transformation, and why it's useful,
then we detail a few smaller optimizations that move let-expressions around.
The goal is to move the let-expression to a position just before the variable is used in the expression.
Finally we discuss four optimizations that will do most of the work in the compiler:
Case canceling, dead code elimination, inlining, and reduction.
These optimization are an important part of any optimizing compiler,
but they are often tricky to get right.
In fact, with the exception of dead code elimination, 
It's not clear at all that they are even valid for Curry.
We show an effective method to implement them
in a way that they remain valid for Curry expressions.

In this chapter we discuss one of the major hurderls to optimizing 
FlatCurry programs,
we then present a solution in A-Normal form,
We do on to develop some standard optimizations
for FlatCurry includeing dead code elimination, case cancelling, and inlinig.
Finally, we show these optimiztions at work optimizing the implementation
the implementation \ensuremath{\leq } for the \ensuremath{\Conid{Bool}} type.

\section{A-Normal Form}

Before we discuss any substantial optimizations, we need to deal with a significant
roadblock to optimizing Curry.
Equational reasoning,
in the sense of replacing expressions with their derived values,
is not valid when optimizing FlatCurry programs.
The reason is that expressions in FlatCurry aren't reverentially transparent \cite{whyFPmatters}.
The evaluation of Curry programs is graph rewriting,
which maintains referential transparency,
but since FlatCurry is composed of terms, and not graph,
we can't substitute expressions with their values.

While there have been graph intermediate representation proposed for
languages \cite{graph_ir, dactl} FlatCurry is not one of these.
We do think that incorporating the graph based IR
might improve the optimization process, and we believe
it is a promising area of future work.

To see an example of why this an issue, let's consider the following program.
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{13}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{double}\;\Varid{x}{}\<[13]%
\>[13]{}\mathrel{=}\Varid{x}\mathbin{+}\Varid{x}{}\<[E]%
\\
\>[3]{}\Varid{main}{}\<[13]%
\>[13]{}\mathrel{=}\Varid{double}\;(\mathrm{0}\mathbin{?}\mathrm{1}){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
In pure lazy functional languages, it is always safe to replace a function
with its definition.
So we should be able to rewrite \ensuremath{\Varid{main}} to \ensuremath{(\mathrm{0}\mathbin{?}\mathrm{1})\mathbin{+}(\mathrm{0}\mathbin{?}\mathrm{1})},
but this expression will produce a different set of answers.
This is the primary problem with optimizing functional logic languages,
but exactly why this happens is a bit tricky to pin down.
The non-determinism isn't the only problem, for example evaluating \ensuremath{\Varid{id}\;(\mathrm{0}\mathbin{?}\mathrm{1})} 
at compile time is fine.
We can even duplicate non-deterministic expressions with the following example.\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{13}{@{}>{\hspre}l<{\hspost}@{}}%
\column{16}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{double}\;\Varid{x}{}\<[13]%
\>[13]{}\mathrel{=}\Varid{x}\mathbin{+}\Varid{x}{}\<[E]%
\\
\>[3]{}\Varid{main}{}\<[13]%
\>[13]{}\mathrel{=}{}\<[16]%
\>[16]{}\mathbf{let}\;\Varid{y}\mathrel{=}(\mathrm{0}\mathbin{?}\mathrm{1}){}\<[E]%
\\
\>[16]{}\mathbf{in}\;\Varid{double}\;\Varid{y}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
Here \ensuremath{\Varid{y}} is a non-deterministic expression, because it produces two answers when evaluated,
but the expression \ensuremath{\mathbf{let}\;\Varid{y}\mathrel{=}(\mathrm{0}\mathbin{?}\mathrm{1})\;\mathbf{in}\;\Varid{y}\mathbin{+}\Varid{y}} is still equivalent to our example.
The real problem with our first example is a bit more subtle,
and we have to step back into the world of graph rewriting.
If we construct the graph for the first expression we see:

\begin{mdframed}
\centerline{
  \graphxy{
      & \xynode{$double$} \xyS{d} & \\
      & \xynode{$?$} \xyD{dl} \xyU{dr} & \\
      \xynode{$0$} & & \xynode{$1$} \\
  }
  \hspace*{2em}
  $\Rightarrow$
  \hspace*{2em}
  \graphxy{
      & \xynode{$+$} \xyD{dl} \xyU{dr} & \\
      \xynode{$?$} \xyD{d} \xyD{drr} & & \xynode{$?$} \xyU{dll} \xyU{d} \\
      \xynode{$0$} & & \xynode{$1$}
  }

}
\end{mdframed}

\begin{mdframed}
\centerline{
  \graphxy{
      & \xynode{$double$} \xyS{d} & \\
      & \xynode{$?_y$} \xyD{dl} \xyU{dr} & \\
      \xynode{$0$} & & \xynode{$1$} \\
  }
  \hspace*{2em}
  $\Rightarrow$
  \hspace*{2em}
  \graphxy{
      & \xynode{$+$} \xyD{d} \xyU{d} & \\
      & \xynode{$?_y$} \xyD{dl} \xyU{dr} & \\
      \xynode{$0$} & & \xynode{$1$}
  }

}
\end{mdframed}

Now the real issue comes to light.
In the second example, while we copied a non-deterministic expression in the code,
we didn't copy the non-deterministic expression in the graph.
This gives us a powerful tool when reasoning about Curry expressions.
Even if a variable is duplicated in the source code, it is not copied in the graph.
Since this duplication of non-deterministic expressions was the main concern for correctness,
the solution is pretty straightforward.
If we copy an expression in FlatCurry, then we should instead store that expression
in a variable and copy the variable.

We can enforce this restriction by disallowing any compound expressions.
Specifically, all function calls, constructor calls, choices, and case expression must either
be applied to literal values or variables.
Fortunately we are not the first to come up with this idea.
In fact this restricted form is used in many functional compilers,
and is known as Administrative Normal Form (ANF) \cite{ANormal}\index{Administrative Normal Form (ANF)}.
The idea originally was to take CPS, another well known intermediate representation
for functional languages, and remove common ``administrative redexes''.
After removing the administrative redexes, we can remove the continuations,
and rewrite the program using let-expressions.
Flanagan et al. showed that these transformations can be reduced into a single
A-Normal form transformation.
We give the definition of A-Normal Form for Curry programs in figure
\ref{fig:anormal}
and we implement the transformation using GAS in figure
\ref{fig:anormalTransform} with the Curry implementation in figure \ref{fig:anormalCurry}.

\begin{figure}
\textbf{ANF:}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{6}{@{}>{\hspre}c<{\hspost}@{}}%
\column{6E}{@{}l@{}}%
\column{10}{@{}>{\hspre}l<{\hspost}@{}}%
\column{34}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{a}{}\<[6]%
\>[6]{}\Rightarrow {}\<[6E]%
\>[10]{}\Varid{v}\;{}\<[34]%
\>[34]{}\Conid{Variable}{}\<[E]%
\\
\>[6]{}\mid {}\<[6E]%
\>[10]{}\Varid{l}\;{}\<[34]%
\>[34]{}\Conid{Literal}{}\<[E]%
\\
\>[6]{}\mid {}\<[6E]%
\>[10]{}\bot \;{}\<[34]%
\>[34]{}\Conid{Failed}{}\<[E]%
\\
\>[3]{}\Varid{e}{}\<[6]%
\>[6]{}\Rightarrow {}\<[6E]%
\>[10]{}\Varid{a}_{\mathrm{1}}\mathbin{?}\Varid{a}_{\mathrm{2}}\;{}\<[34]%
\>[34]{}\Conid{Choice}{}\<[E]%
\\
\>[6]{}\mid {}\<[6E]%
\>[10]{}\Varid{f}_{\Varid{k}}\;\overline{\Varid{a}} \;{}\<[34]%
\>[34]{}\Conid{Function}\;\Conid{Application}{}\<[E]%
\\
\>[6]{}\mid {}\<[6E]%
\>[10]{}\Conid{C}_{\Varid{k}}\;\overline{\Varid{a}} \;{}\<[34]%
\>[34]{}\Conid{Constructor}\;\Conid{Application}{}\<[E]%
\\
\>[6]{}\mid {}\<[6E]%
\>[10]{}\mathbf{let}\;(\overline{\Varid{v}} \mathrel{=}\Varid{e})\;\mathbf{in}\;\Varid{e}\;{}\<[34]%
\>[34]{}\Conid{Variable}\;\Conid{Declaration}{}\<[E]%
\\
\>[6]{}\mid {}\<[6E]%
\>[10]{}\mathbf{let}\;\overline{\Varid{v}} \;\textbf{free} \;\mathbf{in}\;\Varid{e}\;{}\<[34]%
\>[34]{}\Conid{Free}\;\Conid{Variable}\;\Conid{Declaration}{}\<[E]%
\\
\>[6]{}\mid {}\<[6E]%
\>[10]{}\mathbf{case}\;\Varid{a}\;\mathbf{of}\;\overline{\Varid{alt}} \;{}\<[34]%
\>[34]{}\Conid{Case}\;\Conid{Expression}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\caption{
Restricting Curry expressions to A-Normal Form.\\
An atom is either a variable, a literal, or a failure.
Compound expressions are only allowed to contain atoms.}
\label{fig:anormal}
\end{figure}

\begin{figure}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{31}{@{}>{\hspre}l<{\hspost}@{}}%
\column{48}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{case}\;\Varid{e}\;\mathbf{of}\;\Varid{alts}{}\<[31]%
\>[31]{}\Rrightarrow \mathbf{let}\;\Varid{x}\mathrel{=}\Varid{e}\;{}\<[48]%
\>[48]{}\mathbf{in}\;\mathbf{case}\;\Varid{x}\;\mathbf{of}\;\Varid{alts}{}\<[E]%
\\
\>[3]{}\Varid{f}\;\Varid{a}_{\mathrm{1}}\;\Varid{a}_{\mathrm{2}}\ldots \Varid{e}_{\Varid{k}}\ldots \Varid{e}_{\Varid{n}}{}\<[31]%
\>[31]{}\Rrightarrow \mathbf{let}\;\Varid{x}\mathrel{=}\Varid{e}_{\Varid{k}}\;{}\<[48]%
\>[48]{}\mathbf{in}\;\Varid{f}\;\Varid{a}_{\mathrm{1}}\;\Varid{a}_{\mathrm{2}}\ldots \Varid{x}\ldots \Varid{e}_{\Varid{n}}{}\<[E]%
\\
\>[3]{}\Conid{C}\;\Varid{a}_{\mathrm{1}}\;\Varid{a}_{\mathrm{2}}\ldots \Varid{e}_{\Varid{k}}\ldots \Varid{e}_{\Varid{n}}{}\<[31]%
\>[31]{}\Rrightarrow \mathbf{let}\;\Varid{x}\mathrel{=}\Varid{e}_{\Varid{k}}\;{}\<[48]%
\>[48]{}\mathbf{in}\;\Conid{C}\;\Varid{a}_{\mathrm{1}}\;\Varid{a}_{\mathrm{2}}\ldots \Varid{x}\ldots \Varid{e}_{\Varid{n}}{}\<[E]%
\\
\>[3]{}\Varid{e}_{\mathrm{1}}\mathbin{?}\Varid{e}_{\mathrm{2}}{}\<[31]%
\>[31]{}\Rrightarrow \mathbf{let}\;\Varid{x}\mathrel{=}\Varid{e}_{\mathrm{1}}\;{}\<[48]%
\>[48]{}\mathbf{in}\;\Varid{x}\mathbin{?}\Varid{e}_{\mathrm{2}}{}\<[E]%
\\
\>[3]{}\Varid{a}_{\mathrm{1}}\mathbin{?}\Varid{e}_{\mathrm{2}}{}\<[31]%
\>[31]{}\Rrightarrow \mathbf{let}\;\Varid{x}\mathrel{=}\Varid{e}_{\mathrm{2}}\;{}\<[48]%
\>[48]{}\mathbf{in}\;\Varid{a}_{\mathrm{1}}\mathbin{?}\Varid{x}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\caption{
    Rules for transforming Curry expression to A-Normal Form.\\
    \ensuremath{\Varid{a}} is used for atoms, \ensuremath{\Varid{e}} is used for arbitrary expressions,
    and \ensuremath{\Varid{x}} is a fresh variable name.  
    }
\label{fig:anormalTransform}
\end{figure}
\begin{figure}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{4}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{toANF}\mathbin{::}\Conid{Opt}{}\<[E]%
\\
\>[3]{}\Varid{toANF}\;(\Varid{n},\anonymous )\;(\Conid{Case}\;\Varid{ct}\;\Varid{e}\;\Varid{bs}){}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mid \Varid{not}\;(\Varid{trivial}\;\Varid{e})\mathrel{=}\Conid{Let}\;[\mskip1.5mu (\Varid{n},\Varid{e})\mskip1.5mu]\;(\Conid{Case}\;\Varid{ct}\;(\Conid{Var}\;\Varid{n})\;\Varid{bs}){}\<[E]%
\\[\blanklineskip]%
\>[3]{}\Varid{toANF}\;(\Varid{n},\anonymous )\;(\Conid{Comb}\;\Varid{ct}\;\Varid{f}\;(\Varid{as}\plus [\mskip1.5mu \Varid{e}\mskip1.5mu]\plus \Varid{bs})){}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mid \Varid{all}\;\Varid{trivial}\;\Varid{as}\mathrel{\wedge}\Varid{not}\;(\Varid{trivial}\;\Varid{e})\mathrel{=}\Conid{Let}\;[\mskip1.5mu (\Varid{n},\Varid{e})\mskip1.5mu]\;(\Conid{Comb}\;\Varid{ct}\;\Varid{f}\;(\Varid{as}\plus [\mskip1.5mu \Conid{Var}\;\Varid{n}\mskip1.5mu]\plus \Varid{bs})){}\<[E]%
\\[\blanklineskip]%
\>[3]{}\Varid{toANF}\;(\Varid{n},\anonymous )\;(\Conid{Or}\;\Varid{e}_{\mathrm{1}}\;\Varid{e}_{\mathrm{2}}){}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mid \Varid{not}\;(\Varid{trivial}\;\Varid{e}_{\mathrm{1}})\mathrel{=}\Conid{Let}\;[\mskip1.5mu (\Varid{n},\Varid{e}_{\mathrm{1}})\mskip1.5mu]\;(\Conid{Or}\;(\Conid{Var}\;\Varid{n})\;\Varid{e}_{\mathrm{2}}){}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mid \Varid{not}\;(\Varid{trivial}\;\Varid{e}_{\mathrm{2}})\mathrel{=}\Conid{Let}\;[\mskip1.5mu (\Varid{n},\Varid{e}_{\mathrm{2}})\mskip1.5mu]\;(\Conid{Or}\;\Varid{e}_{\mathrm{1}}\;(\Conid{Var}\;\Varid{n})){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\caption{
    Curry implementation of A-Normal Form transformation.
    }
\label{fig:anormalCurry}
\end{figure}

As long as we enforce this A-Normal Form structure,
we restore equational reasoning for Curry programs.
We don't even need to enforce A-Normal Form strictly here.
During optimization, it's often useful to be able to replace
variable bound to constructors and partial applications with their definitions.
Since these nodes have no rewrite rules that can apply at the root,
we can do this replacement without fear of problems with non-deterministic expressions.
This will be referred to as limited A-Normal Form.

In fact, this is exactly how the operational semantics were defined for FlatCurry.
In \cite{currySemantics} FlatCurry programs are translated into
a normalized form before evaluation begins.
We choose to flatten these expressions as well because
it produces more uniform programs,
and more optimizing transformations become valid.
Some examples of programs in ANF are given in figure \ref{fig:anormalExample}.

\begin{figure}
\fbox{
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{12}{@{}>{\hspre}l<{\hspost}@{}}%
\column{18}{@{}>{\hspre}l<{\hspost}@{}}%
\column{25}{@{}>{\hspre}c<{\hspost}@{}}%
\column{25E}{@{}l@{}}%
\column{29}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{fib}\;\Varid{n}\mathrel{=}{}\<[12]%
\>[12]{}\mathbf{case}\;\Varid{n}\mathbin{<}\mathrm{1}{}\<[E]%
\\
\>[12]{}\hsindent{6}{}\<[18]%
\>[18]{}\Conid{True}{}\<[25]%
\>[25]{}\to {}\<[25E]%
\>[29]{}\Varid{n}{}\<[E]%
\\
\>[12]{}\hsindent{6}{}\<[18]%
\>[18]{}\Conid{False}{}\<[25]%
\>[25]{}\to {}\<[25E]%
\>[29]{}\Varid{fib}\;(\Varid{n}\mathbin{-}\mathrm{1})\mathbin{+}{}\<[E]%
\\
\>[29]{}\Varid{fib}\;(\Varid{n}\mathbin{-}\mathrm{2}){}\<[E]%
\\[\blanklineskip]%
\>[3]{}\ {}\<[E]%
\\
\>[3]{}\ {}\<[E]%
\\
\>[3]{}\ {}\<[E]%
\\
\>[3]{}\ {}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage} \ensuremath{\Rrightarrow^* }
\begin{minipage}{.45\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{12}{@{}>{\hspre}l<{\hspost}@{}}%
\column{17}{@{}>{\hspre}l<{\hspost}@{}}%
\column{23}{@{}>{\hspre}l<{\hspost}@{}}%
\column{30}{@{}>{\hspre}c<{\hspost}@{}}%
\column{30E}{@{}l@{}}%
\column{34}{@{}>{\hspre}l<{\hspost}@{}}%
\column{39}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{fib}\;\Varid{n}\mathrel{=}{}\<[12]%
\>[12]{}\mathbf{let}\;{}\<[17]%
\>[17]{}\Varid{x}\mathrel{=}\Varid{n}\mathbin{<}\mathrm{1}{}\<[E]%
\\
\>[12]{}\mathbf{in}\;{}\<[17]%
\>[17]{}\mathbf{case}\;\Varid{x}\;\mathbf{of}{}\<[E]%
\\
\>[17]{}\hsindent{6}{}\<[23]%
\>[23]{}\Conid{True}{}\<[30]%
\>[30]{}\to {}\<[30E]%
\>[34]{}\Varid{n}{}\<[E]%
\\
\>[17]{}\hsindent{6}{}\<[23]%
\>[23]{}\Conid{False}{}\<[30]%
\>[30]{}\to {}\<[30E]%
\>[34]{}\mathbf{let}\;{}\<[39]%
\>[39]{}\Varid{n}_{\mathrm{1}}\mathrel{=}\Varid{n}\mathbin{-}\mathrm{1}{}\<[E]%
\\
\>[39]{}\Varid{n}_{\mathrm{2}}\mathrel{=}\Varid{n}\mathbin{-}\mathrm{2}{}\<[E]%
\\
\>[39]{}\Varid{f}_{\mathrm{1}}\mathrel{=}\Varid{fib}\;\Varid{n}_{\mathrm{1}}{}\<[E]%
\\
\>[39]{}\Varid{f}_{\mathrm{2}}\mathrel{=}\Varid{fib}\;\Varid{n}_{\mathrm{2}}{}\<[E]%
\\
\>[34]{}\mathbf{in}\;{}\<[39]%
\>[39]{}\Varid{f}_{\mathrm{1}}\mathbin{+}\Varid{f}_{\mathrm{2}}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}
}
\fbox{
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{14}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{sumPrimes}{}\<[14]%
\>[14]{}\mathrel{=}\Varid{foldr}\;(\mathbin{+})\;\mathrm{0}{}\<[E]%
\\
\>[14]{}\mathbin{\circ}\Varid{filter}\;\Varid{isPrime}{}\<[E]%
\\
\>[14]{}\mathbin{\circ}\Varid{enumFromTo}\;\mathrm{1}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage} \ensuremath{\Rrightarrow^* }
\begin{minipage}{.45\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{5}{@{}>{\hspre}l<{\hspost}@{}}%
\column{18}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[5]{}\Varid{sumPrimes}\mathrel{=}{}\<[18]%
\>[18]{}\mathbf{let}\;\Varid{v}_{\mathrm{1}}\mathrel{=}(\mathbin{+}){}\<[E]%
\\
\>[18]{}\mathbf{in}\;\mathbf{let}\;\Varid{v}_{\mathrm{2}}\mathrel{=}\Varid{foldr}\;\Varid{v}_{\mathrm{1}}\;\mathrm{0}{}\<[E]%
\\
\>[18]{}\mathbf{in}\;\mathbf{let}\;\Varid{v}_{\mathrm{3}}\mathrel{=}\Varid{isPrime}{}\<[E]%
\\
\>[18]{}\mathbf{in}\;\mathbf{let}\;\Varid{v}_{\mathrm{4}}\mathrel{=}\Varid{filter}\;\Varid{v}_{\mathrm{3}}{}\<[E]%
\\
\>[18]{}\mathbf{in}\;\mathbf{let}\;\Varid{v}_{\mathrm{5}}\mathrel{=}\Varid{enumFromTo}\;\mathrm{1}{}\<[E]%
\\
\>[18]{}\mathbf{in}\;\mathbf{let}\;\Varid{v}_{\mathrm{6}}\mathrel{=}\Varid{v}_{\mathrm{4}}\mathbin{\circ}\Varid{v}_{\mathrm{5}}{}\<[E]%
\\
\>[18]{}\mathbf{in}\;\Varid{v}_{\mathrm{2}}\mathbin{\circ}\Varid{v}_{\mathrm{6}}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}
}
\caption{Examples of Curry programs translated to A-Normal Form}
\label{fig:anormalExample}
\end{figure}

\section{Case Canceling}

Finally, we come to our first example of an optimization.
In fact, this is arguably our most important optimization.
It's a very simple optimization, but it proves to be very powerful.
Consider the following code:
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{19}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{notTrue}\mathrel{=}\mathbf{case}\;{}\<[19]%
\>[19]{}\Conid{True}\;\mathbf{of}{}\<[E]%
\\
\>[19]{}\Conid{True}\to \Conid{False}{}\<[E]%
\\
\>[19]{}\Conid{False}\to \Conid{True}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
Expressions like this come up frequently during optimization.
This is fantastic, because it's clear what we should do here.
We know that the \ensuremath{\Conid{True}} branch will be taken, 
so we might as well evaluate the case expression right now.
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{notTrue}\mathrel{=}\Conid{False}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
This transformation is called Case Canceling,
and it's the workhorse of all of our other optimizations.
The transformation is given and \ref{fig:caseCode} 
and examples of the transformation are given in \ref{fig:CaseCancel} .
If the scrutinee of a case is labeled by a constructor,
then we find the appropriate branch, and reduce to that branch.
The only real complication is that we need to keep the expression in
A-Normal form.
However, we can simply add let-expressions for every variable that the constructor binds.

We also include two other optimizations.
These optimizations are really about cleaning up after Case Canceling runs.
The first is Case Variable elimination.
Consider the expression from the optimization of \ensuremath{\Varid{compare}} for \ensuremath{\Conid{Bool}} in figure \ref{fig:caseBool}.
\begin{figure}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{7}{@{}>{\hspre}l<{\hspost}@{}}%
\column{16}{@{}>{\hspre}l<{\hspost}@{}}%
\column{23}{@{}>{\hspre}l<{\hspost}@{}}%
\column{32}{@{}>{\hspre}l<{\hspost}@{}}%
\column{39}{@{}>{\hspre}l<{\hspost}@{}}%
\column{48}{@{}>{\hspre}l<{\hspost}@{}}%
\column{55}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[7]{}\mathbf{in}\;\mathbf{case}\;{}\<[16]%
\>[16]{}\Varid{v}_{\mathrm{2}}\;\mathbf{of}{}\<[E]%
\\
\>[16]{}\Conid{True}{}\<[23]%
\>[23]{}\to \Conid{LT}{}\<[E]%
\\
\>[16]{}\Conid{False}{}\<[23]%
\>[23]{}\to \mathbf{case}\;{}\<[32]%
\>[32]{}\boxed{\Varid{v}_{\mathrm{2}}}\;\mathbf{of}{}\<[E]%
\\
\>[32]{}\Conid{True}{}\<[39]%
\>[39]{}\to \Conid{EQ}{}\<[E]%
\\
\>[32]{}\Conid{False}{}\<[39]%
\>[39]{}\to \mathbf{case}\;{}\<[48]%
\>[48]{}\Varid{v}_{\mathrm{1}}\;\mathbf{of}{}\<[E]%
\\
\>[48]{}\Conid{True}{}\<[55]%
\>[55]{}\to \Conid{GT}{}\<[E]%
\\
\>[48]{}\Conid{False}{}\<[55]%
\>[55]{}\to \Conid{EQ}{}\<[E]%
\\
\>[3]{}\Rrightarrow \textbf{Case Var}\;[\mskip1.5mu \mathbin{-}\mathrm{1},\mathrm{0},\mathbin{-}\mathrm{1}\mskip1.5mu]{}\<[E]%
\\
\>[3]{}\hsindent{4}{}\<[7]%
\>[7]{}\mathbf{in}\;\mathbf{case}\;{}\<[16]%
\>[16]{}\Varid{v}_{\mathrm{2}}\;\mathbf{of}{}\<[E]%
\\
\>[16]{}\Conid{True}{}\<[23]%
\>[23]{}\to \Conid{LT}{}\<[E]%
\\
\>[16]{}\Conid{False}{}\<[23]%
\>[23]{}\to \mathbf{case}\;{}\<[32]%
\>[32]{}\boxed{\Conid{False}}\;\mathbf{of}{}\<[E]%
\\
\>[32]{}\Conid{True}{}\<[39]%
\>[39]{}\to \Conid{EQ}{}\<[E]%
\\
\>[32]{}\Conid{False}{}\<[39]%
\>[39]{}\to \mathbf{case}\;{}\<[48]%
\>[48]{}\Varid{v}_{\mathrm{1}}\;\mathbf{of}{}\<[E]%
\\
\>[48]{}\Conid{True}{}\<[55]%
\>[55]{}\to \Conid{GT}{}\<[E]%
\\
\>[48]{}\Conid{False}{}\<[55]%
\>[55]{}\to \Conid{EQ}{}\<[E]%
\\
\>[3]{}\Rrightarrow \textbf{Case Cancel}\;[\mskip1.5mu \mathbin{-}\mathrm{1},\mathrm{0},\mathbin{-}\mathrm{1},\mathrm{1}\mskip1.5mu]{}\<[E]%
\\
\>[3]{}\hsindent{4}{}\<[7]%
\>[7]{}\mathbf{in}\;\mathbf{case}\;{}\<[16]%
\>[16]{}\Varid{v}_{\mathrm{2}}\;\mathbf{of}{}\<[E]%
\\
\>[16]{}\Conid{True}{}\<[23]%
\>[23]{}\to \Conid{LT}{}\<[E]%
\\
\>[16]{}\Conid{False}{}\<[23]%
\>[23]{}\to \mathbf{case}\;{}\<[32]%
\>[32]{}\Varid{v}_{\mathrm{1}}\;\mathbf{of}{}\<[E]%
\\
\>[32]{}\Conid{True}{}\<[39]%
\>[39]{}\to \Conid{GT}{}\<[E]%
\\
\>[32]{}\Conid{False}{}\<[39]%
\>[39]{}\to \Conid{EQ}{}\<[E]%
\\
\>[3]{}\ldots {}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\caption{a piece of the optimization derivation for the implementation of \ensuremath{\Varid{compare}}
for \ensuremath{\Conid{Bool}}.}
\label{fig:caseBool}
\end{figure}
The use of Case Variable elimination allows us to set up
a situation where a case can cancel later.
This occurs a lot in practice, but this optimization may raise red flags for some.
In general it's not valid to replace a variable with an expression in FlatCurry.
That variable could be shared, and it could represent a non-deterministic expression.
Fortunately, this is still viable in Curry.

We give a short sketch of the why Case Variable elimination is viable in Curry with the following
example.
Suppose I have the following FlatCurry definition for \ensuremath{\Varid{notHead}}.
This function will look at the first element of a list, and return \ensuremath{\Varid{not}\;\Conid{True}}
if the head of the list evaluates to True.\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{22}{@{}>{\hspre}l<{\hspost}@{}}%
\column{35}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{notHead}\;\Varid{xs}\mathrel{=}\mathbf{case}\;{}\<[22]%
\>[22]{}\Varid{xs}\;\mathbf{of}{}\<[E]%
\\
\>[22]{}\Varid{x}\mathbin{:\char95 }\to \mathbf{case}\;{}\<[35]%
\>[35]{}\Varid{x}\;\mathbf{of}{}\<[E]%
\\
\>[35]{}\Conid{True}\to \Varid{not}\;\Varid{x}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
We use a key fact from Brassels work \cite{Kics2Theory}[Lemma 4.1.10].
Lifting a case into it's own function Does not change the set of values
an expression evaluates to.
We can use this to lift the inner case into it's own function.\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{22}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{notHead}\;\Varid{xs}\mathrel{=}\mathbf{case}\;{}\<[22]%
\>[22]{}\Varid{xs}\;\mathbf{of}{}\<[E]%
\\
\>[22]{}\Varid{x}\mathbin{:\char95 }\to \Varid{notHead}_{\mathrm{1}}\;\Varid{x}{}\<[E]%
\\
\>[3]{}\Varid{notHead}_{\mathrm{1}}\;\Varid{x}\mathrel{=}\mathbf{case}\;\Varid{x}\;\mathbf{of}{}\<[E]%
\\
\>[3]{}\hsindent{19}{}\<[22]%
\>[22]{}\Conid{True}\to \Varid{not}\;\Varid{x}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
Since uniform programs can be viewed as inductively sequential rewrite systems.
The function \ensuremath{\Varid{notHead}_{\mathrm{1}}} should be equivalent to the following Curry program.\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{notHead}_{\mathrm{1}}\;\Conid{True}\mathrel{=}\Varid{not}\;\Conid{True}{}\<[E]%
\\
\>[3]{}\Varid{notHead}_{\mathrm{1}}\;\Conid{False}\mathrel{=}\bot {}\<[E]%
\ColumnHook
\end{hscode}\resethooks
Now this program could be compiled into the following semantically equivalent FlatCurry program.\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{23}{@{}>{\hspre}l<{\hspost}@{}}%
\column{30}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{notHead}_{\mathrm{1}}\;\Varid{x}\mathrel{=}\mathbf{case}\;{}\<[23]%
\>[23]{}\Varid{x}\;\mathbf{of}{}\<[E]%
\\
\>[23]{}\Conid{True}{}\<[30]%
\>[30]{}\to \Varid{not}\;\Conid{True}{}\<[E]%
\\
\>[23]{}\Conid{False}{}\<[30]%
\>[30]{}\to \bot {}\<[E]%
\ColumnHook
\end{hscode}\resethooks
Finally, by the path compression theorem we can reduce the call in \ensuremath{\Varid{notHead}} to get the following result.\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{22}{@{}>{\hspre}l<{\hspost}@{}}%
\column{35}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{notHead}\;\Varid{xs}\mathrel{=}\mathbf{case}\;{}\<[22]%
\>[22]{}\Varid{xs}\;\mathbf{of}{}\<[E]%
\\
\>[22]{}\Varid{x}\mathbin{:\char95 }\to \mathbf{case}\;{}\<[35]%
\>[35]{}\Varid{x}\;\mathbf{of}{}\<[E]%
\\
\>[35]{}\Conid{True}\to \Varid{not}\;\Conid{True}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
This gives us a general procedure for converting FlatCurry programs to the same program
after performing Case Variable elimination.
While we don't perform these steps in practice, each one has already been shown to be valid
on their own, so our transformation is also valid.

Finally we have Dead Code Elimination.
This is a standard optimization.
In short, if we have an empty \ensuremath{\mathbf{let}} or \ensuremath{\textbf{free} } expression,
then we can remove them.
This may happen due to the aliasing rule from last chapter.
Furthermore if a variable is never used, then it can also be removed.
Finally, if we have \ensuremath{\mathbf{let}\;\Varid{x}\mathrel{=}\Varid{e}\;\mathbf{in}\;\Varid{x}}, then we don't need to create the variable \ensuremath{\Varid{x}}.
These are correct
as long as we're careful to make sure that our variable definitions aren't recursive.

\begin{figure}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{4}{@{}>{\hspre}l<{\hspost}@{}}%
\column{5}{@{}>{\hspre}l<{\hspost}@{}}%
\column{25}{@{}>{\hspre}l<{\hspost}@{}}%
\column{43}{@{}>{\hspre}l<{\hspost}@{}}%
\column{68}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{caseCancel}\mathbin{::}\Conid{Opt}{}\<[E]%
\\
\>[3]{}\Varid{caseCancel}\;(\Conid{Case}\;(\Conid{Comb}\;\Conid{ConsCall}\;\Varid{n}\;\Varid{es})\;(\anonymous \plus [\mskip1.5mu \Conid{Branch}\;(\Conid{Pattern}\;\Varid{n}\;\Varid{vs})\;\Varid{e}\mskip1.5mu]\plus \anonymous )){}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mathrel{=}\Varid{foldr}\;\Conid{Let}\;\Varid{e}\;(\Varid{zip}\;\Varid{vs}\;\Varid{es}){}\<[E]%
\\
\>[3]{}\Varid{caseCancel}\;(\Conid{Case}\;(\Conid{Lit}\;\Varid{l})\;(\anonymous \plus [\mskip1.5mu \Conid{Branch}\;(\Conid{LPattern}\;\Varid{l})\;\Varid{e}\mskip1.5mu]\plus \anonymous ))\mathrel{=}\Varid{e}{}\<[E]%
\\
\>[3]{}\Varid{caseCancel}\;(\Conid{Case}\;\bot \;\mathbf{of}\;\anonymous )\mathrel{=}\bot {}\<[E]%
\\
\>[3]{}\ {}\<[E]%
\\
\>[3]{}\Varid{caseVar}\;(\Conid{Case}\;(\Conid{Var}\;\Varid{x})\;\Varid{bs}){}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mid \Varid{x}\in \Varid{vars}\;\Varid{bs}\mathrel{=}\Conid{Case}\;(\Conid{Var}\;\Varid{x})\;(\Varid{map}\;(\Varid{repCaseVar}\;\Varid{x})\;\Varid{bs}){}\<[E]%
\\
\>[3]{}\Varid{repCaseVar}\;\Varid{x}\;(\Conid{Branch}\;(\Conid{Pattern}\;\Varid{n}\;\Varid{vs})\;\Varid{e}){}\<[43]%
\>[43]{}\mathrel{=}\Conid{Branch}\;(\Conid{Pattern}\;\Varid{n}\;\Varid{vs})\;{}\<[68]%
\>[68]{}(\Varid{sub}\;\Varid{f}\;\Varid{e}){}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mathbf{where}\;\Varid{f}\;\Varid{v}\mathrel{=}\mathbf{if}\;\Varid{v}\Varid{==}\Varid{x}\;\mathbf{then}\;\Conid{Comb}\;\Conid{ConsCall}\;\Varid{n}\;(\Varid{map}\;\Conid{Var}\;\Varid{vs})\;\mathbf{else}\;\Conid{Var}\;\Varid{v}{}\<[E]%
\\
\>[3]{}\Varid{repCaseVar}\;\Varid{x}\;(\Conid{Branch}\;(\Conid{LPattern}\;\Varid{l})\;\Varid{e}){}\<[43]%
\>[43]{}\mathrel{=}\Conid{Branch}\;(\Conid{LPattern}\;\Varid{l})\;{}\<[68]%
\>[68]{}(\Varid{sub}\;\Varid{f}\;\Varid{e}){}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mathbf{where}\;\Varid{f}\;\Varid{v}\mathrel{=}\mathbf{if}\;\Varid{v}\Varid{==}\Varid{x}\;\mathbf{then}\;\Conid{Lit}\;\Varid{l}\;\mathbf{else}\;\Conid{Var}\;\Varid{v}{}\<[E]%
\\
\>[3]{}\ {}\<[E]%
\\
\>[3]{}\Varid{deadCode}\;(\Conid{Free}\;[\mskip1.5mu \mskip1.5mu]\;\Varid{e}){}\<[25]%
\>[25]{}\mathrel{=}\Varid{e}{}\<[E]%
\\
\>[3]{}\Varid{deadCode}\;(\Conid{Let}\;[\mskip1.5mu \mskip1.5mu]\;\Varid{e}){}\<[25]%
\>[25]{}\mathrel{=}\Varid{e}{}\<[E]%
\\
\>[3]{}\Varid{deadCode}\;(\Conid{Free}\;(\Varid{as}\plus [\mskip1.5mu \Varid{v}\mskip1.5mu]\plus \Varid{bs})\;\Varid{e}){}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mid \Varid{not}\;(\Varid{hasVar}\;\Varid{v}\;\Varid{e}){}\<[25]%
\>[25]{}\mathrel{=}\Conid{Free}\;(\Varid{as}\plus \Varid{bs})\;\Varid{e}{}\<[E]%
\\
\>[3]{}\Varid{deadCode}\;(\Conid{Let}\;[\mskip1.5mu (\Varid{v},\anonymous )\mskip1.5mu]\;\Varid{e}){}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mid \Varid{not}\;(\Varid{hasVar}\;\Varid{v}\;\Varid{e}){}\<[25]%
\>[25]{}\mathrel{=}\Varid{e}{}\<[E]%
\\
\>[3]{}\Varid{deadCode}\;(\Conid{Let}\;[\mskip1.5mu (\Varid{x},\Varid{e})\mskip1.5mu]\;(\Conid{Var}\;\Varid{x})){}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mid \Varid{not}\;(\Varid{hasVar}\;\Varid{x}\;\Varid{e}){}\<[25]%
\>[25]{}\mathrel{=}\Varid{e}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\caption{The code for Case Canceling, Case Variable Elimination, and Dead Code Elimination.}
\label{fig:caseCode}
\end{figure}

\begin{figure}
\textbf{Case Cancel}\\
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{7}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{case}\;\Conid{C}_{\Varid{i}}\;\overline{\Varid{e}} \;\mathbf{of}{}\<[E]%
\\
\>[3]{}\hsindent{4}{}\<[7]%
\>[7]{}\overline{\Conid{C}_{\Varid{i}}\;\overline{\Varid{x}} \to \Varid{e'}} {}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage} \ensuremath{\Rrightarrow }
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;\overline{\Varid{x}} \mathrel{=}\overline{\Varid{e}} {}\<[E]%
\\
\>[3]{}\mathbf{in}\;\Varid{e'}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}\\
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{7}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{case}\;l_i\;\mathbf{of}{}\<[E]%
\\
\>[3]{}\hsindent{4}{}\<[7]%
\>[7]{}\overline{l_i\to \Varid{e'}} {}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage} \ensuremath{\Rrightarrow }
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{e'}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}\\
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{case}\;\bot \;\mathbf{of}\;\Varid{alts}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage} \ensuremath{\Rrightarrow }
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\bot {}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}\\
\textbf{Case Var}\\
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{8}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{case}\;\Varid{v}\;\mathbf{of}{}\<[E]%
\\
\>[3]{}\hsindent{5}{}\<[8]%
\>[8]{}(\Conid{C}\;(\overline{\Varid{x}} \to \Varid{e'})){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage} \ensuremath{\Rrightarrow }
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{9}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{case}\;{}\<[9]%
\>[9]{}\Varid{v}\;\mathbf{of}{}\<[E]%
\\
\>[9]{}(\Conid{C}\;(\overline{\Varid{x}} \to \Varid{e'}[\Varid{v}\to\Conid{C}\;\overline{\Varid{x}} ])){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}\\
\textbf{Dead Code}\\
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;\textbf{free} \;\mathbf{in}\;\Varid{e}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage} \ensuremath{\Rrightarrow }
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{e}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}\\
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;\mathbf{in}\;\Varid{e}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage} \ensuremath{\Rrightarrow }
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{e}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}\\
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{16}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;\Varid{v}\;\textbf{free} \;{}\<[16]%
\>[16]{}\mathbf{in}\;\Varid{e}\mid \Varid{v}\not\in \Varid{e}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage} \ensuremath{\Rrightarrow }
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{e}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}\\
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{15}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;\Varid{v}\mathrel{=}\Varid{e'}\;{}\<[15]%
\>[15]{}\mathbf{in}\;\Varid{e}\mid \Varid{v}\not\in \Varid{e}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage} \ensuremath{\Rrightarrow }
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{e}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}\\
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;\Varid{v}\mathrel{=}\Varid{e}\;\mathbf{in}\;\Varid{v}\mid \Varid{v}\not\in \Varid{e}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage} \ensuremath{\Rrightarrow }
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{e}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}\\
    \caption{Case Canceling, Case Variable, and Dead Code Elimination optimizations.}
    \label{fig:CaseCancel}
\end{figure}

Now that we've finally created an optimization,
we can get back to moving code around in convoluted patterns.
In the next section we look at how we can inline functions.
Unlike Case Canceling, It's harder to determine the correctness of Inlining.
In fact, we have to do a lot of work to inline functions in Curry.

\section{Inlining}

As mentioned at the start of this chapter, inlining isn't generally valid in Curry.
So, we need to establish cases when inlining is valid,
determine when it's a good idea to inline,
and ensure that our inlining algorithm is correct.
This work is largely based on \cite{haskellInliner, CarruthInline}.

Similarly to \cite{haskellInliner}, we need to make a distinction between
inlining and reduction.
When we use the term \textit{inlining} we are referring to replacing a let bound variable with
it's definition.
For example \ensuremath{\mathbf{let}\;\Varid{x}\mathrel{=}\Conid{True}\;\mathbf{in}\;\Varid{not}\;\Varid{x}} could inline to \ensuremath{\Varid{not}\;\Conid{True}}.
When we use the term \textit{reduction}, we are referring to replacing a function call
with the body of the function where the parameters of the function are replaced
with the arguments of the call.
Again, as an example \ensuremath{\mathbf{let}\;\Varid{x}\mathrel{=}\Conid{True}\;\mathbf{in}\;\Varid{not}\;\Varid{x}} could reduce to:\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{8}{@{}>{\hspre}l<{\hspost}@{}}%
\column{14}{@{}>{\hspre}l<{\hspost}@{}}%
\column{21}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;{}\<[8]%
\>[8]{}\Varid{x}\mathrel{=}\Conid{True}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;{}\<[8]%
\>[8]{}\mathbf{case}\;{}\<[14]%
\>[14]{}\Varid{x}\;\mathbf{of}{}\<[E]%
\\
\>[14]{}\Conid{True}{}\<[21]%
\>[21]{}\to \Conid{False}{}\<[E]%
\\
\>[14]{}\Conid{False}{}\<[21]%
\>[21]{}\to \Conid{True}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
The first problem with inlining and reduction we encounter is recursion.
Consider the expression:\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;\Varid{loop}\mathrel{=}\Varid{loop}\;\mathbf{in}\ldots {}\<[E]%
\ColumnHook
\end{hscode}\resethooks
If we were to inline this variable, we could potentially send the optimizer into an infinite loop.
So, we need to somehow mark all recursive variables and functions.
The next problem follows immediately after that.
So far we've done transformations with local information,
but reduction is going to require global information.
In fact, for reduction to be effective, it will require information from different modules.
Consider the function:\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{sumPrimes}\mathrel{=}\Varid{foldr}\;(\mathbin{+})\;\mathrm{0}\mathbin{\circ}\Varid{filter}\;\Varid{isPrime}\mathbin{\circ}\Varid{enumFromTo}\;\mathrm{1}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
Aside from the fact that \ensuremath{\Varid{sumPrimes}} contains mostly recursive functions,
we wouldn't be able to optimize it anyway, because \ensuremath{\mathbin{\circ}} is defined in the standard Prelude.
If we can't reduce the definition of \ensuremath{\mathbin{\circ}}, then we're fighting a losing battle.

This brings us to our third problem with inlining.
The \ensuremath{\Varid{sumPrimes}} function is actually partially applied.
Its type should be \ensuremath{\Varid{sumPrimes}\mathbin{::}\Conid{Int}\to \Conid{Int}},
but \ensuremath{\Varid{sumPrimes}} is defined in a point-free style.
Point-free programming causes a lot of problems, specifically because
FlatCurry is a combinator language.
In IR's like Haskell's Core, we could solve this problem by inlining 
a lambda expression, but it's not clear at all that inlining a lambda
expression is valid in Curry.
Instead, to solve this problem, we convert functions to be fully applied.

In order to solve these problems, 
we keep a map from function names to several attributes about the function.
This includes: if the function is defined externally;
if the function is known to be deterministic;
if the function contains cases;
the parameters of the function; 
the current number of variables in a function;
the size of the function;
and the function definition.
This map is updated every time we optimize a new function,
so we can reduce all functions that we've already optimized.
We will use this map to determine when it is safe and effective to reduce a function.

\subsection{Partial Applications}

Dealing with partial applications is a bit more tricky.
In fact, we can't use the GAS system to solve this problem
because we may not know if a function is a partial application until we've optimized it.
Consider the \ensuremath{\Varid{sumPrimes}} function again.
It doesn't look like a partial application because the root function, \ensuremath{\mathbin{\circ}}, is fully applied.
Let's look at the definition for \ensuremath{\mathbin{\circ}}.
In Curry it's defined using a lambda expression.\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{f}\mathbin{\circ}\Varid{g}\mathrel{=}\lambda \Varid{x}\to \Varid{f}\;(\Varid{g}\;\Varid{x}){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
However, when translated to FlatCurry, this lambda expression is turned into a combinator.\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{f}\mathbin{\circ}\Varid{g}\mathrel{=}\Varid{compLambda}_{\mathrm{1}}\;\Varid{f}\;\Varid{g}{}\<[E]%
\\
\>[3]{}\Varid{compLambda}\;\Varid{f}\;\Varid{g}\;\Varid{x}\mathrel{=}\Varid{f}\;(\Varid{g}\;\Varid{x}){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
So, when we try to optimize \ensuremath{\Varid{sumPrimes}} we end up with the following derivation.\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;\Varid{v}_{\mathrm{1}}\mathrel{=}\Varid{p}_{\mathrm{2}}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\mathbf{let}\;\Varid{v}_{\mathrm{2}}\mathrel{=}foldr_1\;\Varid{v}_{\mathrm{1}}\;\mathrm{0}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\mathbf{let}\;\Varid{v}_{\mathrm{3}}\mathrel{=}\Varid{isPrime\char95 1}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\mathbf{let}\;\Varid{v}_{\mathrm{4}}\mathrel{=}\Varid{filter\char95 1}\;\Varid{v}_{\mathrm{3}}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\mathbf{let}\;\Varid{v}_{\mathrm{5}}\mathrel{=}\Varid{enumFromTo\char95 1}\;\mathrm{1}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\mathbf{let}\;\Varid{v}_{\mathrm{6}}\mathrel{=}\Varid{v}_{\mathrm{4}}\mathbin{\circ}\Varid{v}_{\mathrm{5}}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\boxed{\Varid{v}_{\mathrm{2}}\mathbin{\circ}\Varid{v}_{\mathrm{6}}}{}\<[E]%
\\
\>[3]{}\textbf{Reduce Base}\Rrightarrow [\mskip1.5mu \mathbin{-}\mathrm{1},\mathbin{-}\mathrm{1},\mathbin{-}\mathrm{1},\mathbin{-}\mathrm{1},\mathbin{-}\mathrm{1},\mathbin{-}\mathrm{1}\mskip1.5mu]{}\<[E]%
\\
\>[3]{}\mathbf{let}\;\Varid{v}_{\mathrm{1}}\mathrel{=}\Varid{p}_{\mathrm{2}}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\mathbf{let}\;\Varid{v}_{\mathrm{2}}\mathrel{=}foldr_1\;\Varid{v}_{\mathrm{1}}\;\mathrm{0}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\mathbf{let}\;\Varid{v}_{\mathrm{3}}\mathrel{=}\Varid{isPrime\char95 1}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\mathbf{let}\;\Varid{v}_{\mathrm{4}}\mathrel{=}\Varid{filter\char95 1}\;\Varid{v}_{\mathrm{3}}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\mathbf{let}\;\Varid{v}_{\mathrm{5}}\mathrel{=}\Varid{enumFromTo\char95 1}\;\mathrm{1}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\mathbf{let}\;\Varid{v}_{\mathrm{6}}\mathrel{=}\boxed{\Varid{v}_{\mathrm{4}}\mathbin{\circ}\Varid{v}_{\mathrm{5}}}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\Varid{compLambda}_{\mathrm{1}}\;\Varid{v}_{\mathrm{2}}\;\Varid{v}_{\mathrm{6}}{}\<[E]%
\\
\>[3]{}\textbf{Reduce Let}\Rrightarrow [\mskip1.5mu \mathbin{-}\mathrm{1},\mathbin{-}\mathrm{1},\mathbin{-}\mathrm{1},\mathbin{-}\mathrm{1},\mathbin{-}\mathrm{1}\mskip1.5mu]{}\<[E]%
\\
\>[3]{}\mathbf{let}\;\Varid{v}_{\mathrm{1}}\mathrel{=}\Varid{p}_{\mathrm{2}}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\mathbf{let}\;\Varid{v}_{\mathrm{2}}\mathrel{=}foldr_1\;\Varid{v}_{\mathrm{1}}\;\mathrm{0}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\mathbf{let}\;\Varid{v}_{\mathrm{3}}\mathrel{=}\Varid{isPrime\char95 1}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\mathbf{let}\;\Varid{v}_{\mathrm{4}}\mathrel{=}\Varid{filter\char95 1}\;\Varid{v}_{\mathrm{3}}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\mathbf{let}\;\Varid{v}_{\mathrm{5}}\mathrel{=}\Varid{enumFromTo\char95 1}\;\mathrm{1}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\mathbf{let}\;\Varid{v}_{\mathrm{6}}\mathrel{=}\Varid{compLambda}_{\mathrm{1}}\;\Varid{v}_{\mathrm{4}}\;\Varid{v}_{\mathrm{5}}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\Varid{compLambda}_{\mathrm{1}}\;\Varid{v}_{\mathrm{2}}\;\Varid{v}_{\mathrm{6}}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
The \ensuremath{\textbf{Reduce Base}} and \ensuremath{\textbf{Reduce Let}} transformations will be described later.
At this point there's no more optimization that can be done,
because everything is a partial function.
But this isn't a great result.
We've created a pipeline, and when we pass it a variable, then everything will be fully applied.
So, how do we solve the problem?

The key is to notice that if the root of the body of a function is a partial application,
then we can rewrite our definition.
We simply add enough variables to the function definition so the body of the function
is fully applied.
The transformation 

\noindent
\textbf{Add Missing Variables}\\
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{f}\;\overline{\Varid{v}} \mathrel{=}\Varid{g\char95 k}\;\overline{\Varid{e}} {}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage} \ensuremath{\Rrightarrow }
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{f}\;\overline{\Varid{v}} \;\overline{\Varid{x}} \mathrel{=}\Varid{apply}\;(\Varid{g\char95 k}\;\overline{\Varid{e}} )\;\overline{\Varid{x}} {}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}\\

The \ensuremath{\Varid{sumPrimes}} functions is transformed with the derivation in \ref{fig:addvarDeriv}
and we can continue to optimize the function.

\begin{figure}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{19}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;\Varid{v}_{\mathrm{1}}\mathrel{=}(\mathbin{+}){}\<[E]%
\\
\>[3]{}\mathbf{in}\;\mathbf{let}\;\Varid{v}_{\mathrm{2}}\mathrel{=}\Varid{foldr}\;\Varid{v}_{\mathrm{1}}\;\mathrm{0}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\mathbf{let}\;\Varid{v}_{\mathrm{3}}\mathrel{=}\Varid{isPrime}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\mathbf{let}\;\Varid{v}_{\mathrm{4}}\mathrel{=}\Varid{filter}\;\Varid{v}_{\mathrm{3}}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\mathbf{let}\;\Varid{v}_{\mathrm{5}}\mathrel{=}\Varid{enumFromTo}\;\mathrm{1}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\mathbf{let}\;\Varid{v}_{\mathrm{6}}\mathrel{=}\Varid{compLambda}_{\mathrm{1}}\;\Varid{v}_{\mathrm{4}}\;\Varid{v}_{\mathrm{5}}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\Varid{compLambda}_{\mathrm{1}}\;\Varid{v}_{\mathrm{2}}\;\Varid{v}_{\mathrm{6}}{}\<[E]%
\\
\>[3]{}\Rrightarrow \textbf{Add Missing Variables}{}\<[E]%
\\
\>[3]{}\boxed{\Varid{apply}}\;({}\<[19]%
\>[19]{}\mathbf{let}\;\Varid{v}_{\mathrm{1}}\mathrel{=}(\mathbin{+}){}\<[E]%
\\
\>[19]{}\mathbf{in}\;\mathbf{let}\;\Varid{v}_{\mathrm{2}}\mathrel{=}\Varid{foldr}\;\Varid{v}_{\mathrm{1}}\;\mathrm{0}{}\<[E]%
\\
\>[19]{}\mathbf{in}\;\mathbf{let}\;\Varid{v}_{\mathrm{3}}\mathrel{=}\Varid{isPrime}{}\<[E]%
\\
\>[19]{}\mathbf{in}\;\mathbf{let}\;\Varid{v}_{\mathrm{4}}\mathrel{=}\Varid{filter}\;\Varid{v}_{\mathrm{3}}{}\<[E]%
\\
\>[19]{}\mathbf{in}\;\mathbf{let}\;\Varid{v}_{\mathrm{5}}\mathrel{=}\Varid{enumFromTo}\;\mathrm{1}{}\<[E]%
\\
\>[19]{}\mathbf{in}\;\mathbf{let}\;\Varid{v}_{\mathrm{6}}\mathrel{=}\Varid{compLambda}_{\mathrm{1}}\;\Varid{v}_{\mathrm{4}}\;\Varid{v}_{\mathrm{5}}{}\<[E]%
\\
\>[19]{}\mathbf{in}\;\Varid{compLambda}_{\mathrm{1}}\;\Varid{v}_{\mathrm{2}}\;\Varid{v}_{\mathrm{6}})\;\Varid{x}_{\mathrm{1}}{}\<[E]%
\\
\>[3]{}\Rrightarrow \textbf{Let Floating}{}\<[E]%
\\
\>[3]{}\mathbf{let}\;\Varid{v}_{\mathrm{1}}\mathrel{=}(\mathbin{+}){}\<[E]%
\\
\>[3]{}\mathbf{in}\;\mathbf{let}\;\Varid{v}_{\mathrm{2}}\mathrel{=}\Varid{foldr}\;\Varid{v}_{\mathrm{1}}\;\mathrm{0}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\mathbf{let}\;\Varid{v}_{\mathrm{3}}\mathrel{=}\Varid{isPrime}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\mathbf{let}\;\Varid{v}_{\mathrm{4}}\mathrel{=}\Varid{filter}\;\Varid{v}_{\mathrm{3}}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\mathbf{let}\;\Varid{v}_{\mathrm{5}}\mathrel{=}\Varid{enumFromTo}\;\mathrm{1}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\mathbf{let}\;\Varid{v}_{\mathrm{6}}\mathrel{=}\Varid{compLambda}_{\mathrm{1}}\;\Varid{v}_{\mathrm{4}}\;\Varid{v}_{\mathrm{5}}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\boxed{\Varid{apply}\;(\Varid{compLambda}_{\mathrm{1}}\;\Varid{v}_{\mathrm{2}}\;\Varid{v}_{\mathrm{6}})\;\Varid{x}_{\mathrm{1}}}{}\<[E]%
\\
\>[3]{}\Rrightarrow \textbf{Unapply}{}\<[E]%
\\
\>[3]{}\mathbf{let}\;\Varid{v}_{\mathrm{1}}\mathrel{=}(\mathbin{+}){}\<[E]%
\\
\>[3]{}\mathbf{in}\;\mathbf{let}\;\Varid{v}_{\mathrm{2}}\mathrel{=}\Varid{foldr}\;\Varid{v}_{\mathrm{1}}\;\mathrm{0}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\mathbf{let}\;\Varid{v}_{\mathrm{3}}\mathrel{=}\Varid{isPrime}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\mathbf{let}\;\Varid{v}_{\mathrm{4}}\mathrel{=}\Varid{filter}\;\Varid{v}_{\mathrm{3}}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\mathbf{let}\;\Varid{v}_{\mathrm{5}}\mathrel{=}\Varid{enumFromTo}\;\mathrm{1}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\mathbf{let}\;\Varid{v}_{\mathrm{6}}\mathrel{=}\Varid{compLambda}_{\mathrm{1}}\;\Varid{v}_{\mathrm{4}}\;\Varid{v}_{\mathrm{5}}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\Varid{compLambda}\;\Varid{v}_{\mathrm{2}}\;\Varid{v}_{\mathrm{6}}\;\Varid{x}_{\mathrm{1}}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
    \caption{Adding a missing variable to \ensuremath{\Varid{sumPrimes}}}
    \label{fig:addvarDeriv}
\end{figure}

\subsection{The Function Table} \label{sec:funTab}
In order to keep track of all of the functions we've optimized we create a function lookup table
called \ensuremath{\textbf{F} _\mathcal{F} } \index{$F_{\mathcal{F}}$}.
The function table is just a map from function names to information about the function.
We use the following definitions for lookups into the function table.
\ensuremath{\Conid{I}_\mathcal{F} \;\Varid{f}} \index{$I_{\mathcal{F}}$} returns true if we believe that \ensuremath{\Varid{f}}
is a good candidate for reduction.
We have designed the compiler so that whatever heuristic we use to decide
if a function can be inlined, it is easy to tweak,
but at the very least \ensuremath{\Varid{f}} should not be external, nor too big, and inlining \ensuremath{\Varid{f}}
should not lead to an infinite derivation.
\ensuremath{\Conid{U}_\mathcal{F} \;\Varid{x}\;\Varid{f}\;\Varid{e}} \index{$U_{\mathcal{F}}$} attempts to determine if reducing the function \ensuremath{\Varid{f}} 
in the expression \ensuremath{\mathbf{let}\;\Varid{x}\mathrel{=}\Varid{f}\ldots \mathbf{in}\;\Varid{e}} would be useful.
Again this heuristic is easily tweakable, but currently,
a function is useful if \ensuremath{\Varid{x}} is returned from the function,
it's used as the scrutinee of a case expression,
or it's used in a function that's likely to be reduced.
\ensuremath{\Conid{S}_\mathcal{F} \;\Varid{f}} \index{$S_{\mathcal{F}}$} returns True if \ensuremath{\Varid{f}} is a simple reduction with no case expressions.
It's always useful to reduce these functions.
\ensuremath{\Conid{C}_\mathcal{F} \;\Varid{f}\;[\mskip1.5mu \Varid{e}_{\mathrm{1}},\ldots \Varid{e}_{\Varid{n}}\mskip1.5mu]} \index{$C_{\mathcal{F}}$} returns true if reducing \ensuremath{\Varid{f}} with \ensuremath{\Varid{e}_{\mathrm{1}}\ldots \Varid{e}_{\Varid{n}}}
will likely cause Case Canceling.


\subsection{Function Ordering}

The problem of function ordering seems like it should be pretty inconsequential,
but it turns out to be very important.
However, this problem has already been well studied \cite{CarruthInline, haskellInliner},
and the solutions for other languages apply equally well to Curry.

The problem seems very complicated at the start.
We want to know what is the best order to optimize functions.
Fortunately there's a very natural solution.
If possible we should optimize a function before we optimize any function that calls it.
This turns out to be an exercise in Graph Theory.

We define the Call Graph of a set of functions \ensuremath{\textbf{F} \mathrel{=}\{\mskip1.5mu \Varid{f}_{\mathrm{1}},\Varid{f}_{\mathrm{2}},\ldots \Varid{f}_{\Varid{n}}\mskip1.5mu\}}
to be the graph \ensuremath{\Conid{G}_{\textbf{F} }\mathrel{=}(\textbf{F} ,\{\mskip1.5mu \Varid{f}_{\Varid{i}}\to \Varid{f}_{\Varid{j}} \vert \Varid{f}_{\Varid{i}}\;\Varid{calls}\;\Varid{f}_{\Varid{j}}\mskip1.5mu\})}.
This problem reduces to finding the topological ordering of \ensuremath{\Conid{G}_{\textbf{F} }}.
Unfortunately, if \ensuremath{\textbf{F} } contains any recursion, then the topological ordering isn't defined.
So, instead, we split \ensuremath{\Conid{G}_{\textbf{F} }} into strongly connected components, and find the topological ordering
of those components.
Within each component, we pick an arbitrary function, called the \emph{loop breaker}\index{loop breaker},
which is removed from the graph.
We then attempt to find the topological order of each component again.
This process repeats until our graph is acyclic.

These loop breakers are marked in \ensuremath{\textbf{F} _\mathcal{F} }, and they are never allowed to be reduced.
Every other function can be reduced, because all functions that it calls,
except for possibly the loop breakers, have been optimized.

Consider the program:
\begin{mdframed}
\begin{minipage}{.4\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{14}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{f}\;\Varid{x}\mathrel{=}\Varid{g}\;\Varid{x}{}\<[E]%
\\
\>[3]{}\Varid{g}\;\Varid{x}\mathrel{=}\Varid{h}\;\Varid{x}{}\<[E]%
\\
\>[3]{}\Varid{h}\;\Varid{x}\mathrel{=}\mathbf{case}\;\Varid{x}\;\mathbf{of}{}\<[E]%
\\
\>[3]{}\hsindent{11}{}\<[14]%
\>[14]{}\mathrm{0}\to \mathrm{0}{}\<[E]%
\\
\>[3]{}\hsindent{11}{}\<[14]%
\>[14]{}\anonymous \to \mathrm{1}\mathbin{+}\Varid{f}\;\Varid{x}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}
\begin{minipage}{.6\textwidth}
\centerline{
  \graphxy{
      & \xynode{$f$} \xydS{dl} & \\ %\xydS{dr} & \\
      \xynode{$g$} \xydS{rr} & & \yxnode{$h$} \xydS{ul}\\
  }
  $\Rightarrow$
  \hspace*{2em}
  \graphxy{
      \xynode{$f$} \xydS{d} \\
      \xynode{$g$} \xydS{d} \\
      \xynode{$h$}\\
  }
}
\end{minipage}
\end{mdframed}

The graph for this function is a triangle, because \ensuremath{\Varid{f}} calls \ensuremath{\Varid{g}} which calls \ensuremath{\Varid{h}} which calls \ensuremath{\Varid{f}}.
However, if we mark \ensuremath{\Varid{h}} as a loop breaker, then suddenly this problem is easy.
When we optimize \ensuremath{\Varid{h}}, we are free to reduce \ensuremath{\Varid{f}} and \ensuremath{\Varid{g}}.
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{14}{@{}>{\hspre}l<{\hspost}@{}}%
\column{20}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{h}\;\Varid{x}\mathrel{=}\mathbf{case}\;\Varid{x}\;\mathbf{of}{}\<[E]%
\\
\>[3]{}\hsindent{11}{}\<[14]%
\>[14]{}\mathrm{0}\to {}\<[20]%
\>[20]{}\mathrm{0}{}\<[E]%
\\
\>[3]{}\hsindent{11}{}\<[14]%
\>[14]{}\anonymous \to {}\<[20]%
\>[20]{}\mathbf{let}\;\Varid{y}\mathrel{=}\boxed{\Varid{f}\;\Varid{x}}{}\<[E]%
\\
\>[20]{}\mathbf{in}\;\mathrm{1}\mathbin{+}\Varid{y}{}\<[E]%
\\
\>[3]{}\Rrightarrow \textbf{Reduce Let}{}\<[E]%
\\
\>[3]{}\Varid{h}\;\Varid{x}\mathrel{=}\mathbf{case}\;\Varid{x}\;\mathbf{of}{}\<[E]%
\\
\>[3]{}\hsindent{11}{}\<[14]%
\>[14]{}\mathrm{0}\to {}\<[20]%
\>[20]{}\mathrm{0}{}\<[E]%
\\
\>[3]{}\hsindent{11}{}\<[14]%
\>[14]{}\anonymous \to {}\<[20]%
\>[20]{}\mathbf{let}\;\Varid{y}\mathrel{=}\boxed{\Varid{g}\;\Varid{x}}{}\<[E]%
\\
\>[20]{}\mathbf{in}\;\mathrm{1}\mathbin{+}\Varid{y}{}\<[E]%
\\
\>[3]{}\Rrightarrow \textbf{Reduce Let}{}\<[E]%
\\
\>[3]{}\Varid{h}\;\Varid{x}\mathrel{=}\mathbf{case}\;\Varid{x}\;\mathbf{of}{}\<[E]%
\\
\>[3]{}\hsindent{11}{}\<[14]%
\>[14]{}\mathrm{0}\to {}\<[20]%
\>[20]{}\mathrm{0}{}\<[E]%
\\
\>[3]{}\hsindent{11}{}\<[14]%
\>[14]{}\anonymous \to {}\<[20]%
\>[20]{}\mathbf{let}\;\Varid{y}\mathrel{=}\boxed{\Varid{h}\;\Varid{x}}{}\<[E]%
\\
\>[20]{}\mathbf{in}\;\mathrm{1}\mathbin{+}\Varid{y}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks

\subsection{Inlining}

Now that we have everything in order, we can start developing the inlining transformation.
As mentioned before, we need to be careful with inlining.
In general, unrestricted inlining isn't valid in Curry.
This is a large change from lazy languages like Haskell, where it's valid,
but not always a good idea.
The other major distinction is that FlatCurry is a combinator language.
This means that we have no lambda expressions,
which limits what we can even do with inlining.

Fortunately for us, these problems actually end up canceling each other out.
In Peyton-Jones work \cite{haskellInliner} most of the focus was on inlining let bound variables,
because this is where duplication of computation could occur.
However, we have two things working for us.
The first is that we can't inline a lambda since they don't exist.
The second is that we've translated FlatCurry to A-Normal Form.
While Haskell programs are put into A-Normal Form when translating to STG code \cite{stg},
this is not the case for Core.
Certain constraints are enforced, such as the trivial constructor argument invariant,
but in general Core is less restricted.

Translating to A-Normal form gives us an important result.
If we inline a constructor then we don't affect the computed results.
This same result holds for literal values, but we will discuss how we handle literals
in Curry in the next chapter.

\begin{theorem}
If \ensuremath{\mathbf{let}\;\Varid{x}\mathrel{=}\Varid{e}_{\mathrm{1}}\;\mathbf{in}\;\Varid{e}} is a Curry expression in limited A-Normal Form, 
and \ensuremath{\Varid{e}_{\mathrm{1}}} is rooted by a constructor application, or partial application,
then $e[x \to e_1]$ computes the same results.
\end{theorem}

\begin{proof}
First note that given our semantics for partial application,
a partially applied function is a normal form.
There are no rules for evaluating a partial application,
only for examining one while evaluating an apply node.

If $e_1$ is a constructor, or partial application,
then it is a normal form.
Therefore it's a deterministic expression by definition \ref{def:deterministic}.
Since $e_1$ is deterministic by the path compression theorem,
$e$ evaluates to the same values as \ensuremath{\Varid{e}[\Varid{x}\to\Varid{e}_{\mathrm{1}}]}
\end{proof}

Now we have enough information to inline variables as long as we restrict inlining to
literals, constructors, variables, and partial applications,
although the case for variables is already subsumed by the \ensuremath{\textbf{Alias}} rule \ref{fig:canonical2}.
We add two new rules.  \ensuremath{\textbf{Let Folding}} allows us to move variable definitions
closer to where they're actually used,
and \ensuremath{\textbf{Unapply}} allows us to simplify expressions involving \ensuremath{\Varid{apply}}.
Both of these are useful for inlining and reduction.
The GAS rules are given in figure \ref{fig:inline}.
Note that the \ensuremath{\textbf{Unapply}} rule corresponds exactly to the evaluation step for application nodes
in our semantics.
The inlining rules correspond to the cases discussed above.
We add one more rule.  We inline a variable bound to a case expression,
if that expression occurs once in a needed position.
Since we can't determine if the variable occurs in a needed position at compile time,
we can use check if it occurs in a strict position \cite{strictAbstract}.
This is usually good enough.
The implementation of Inlining in the Gas system is given in figure \ref{fig:inlineCode}.
The combinator \ensuremath{(\Varid{x},\Varid{e})\hspace{2pt}\text{@}\hspace{-3pt}\mathbin{>}\sigma} is used to build up substitutions.
It means that we add we add $x \to e$ to the substitution \ensuremath{\sigma}.
The \ensuremath{\Varid{idSub}} substitution is just the identity.
In the \ensuremath{\Varid{letFold}} rule, \ensuremath{\Varid{hasVar}} checks is expression \ensuremath{\Varid{e}} contains variable \ensuremath{\Varid{v}}.
In the fist Inlining rule, the \ensuremath{\Varid{strict}} and \ensuremath{\Varid{uses}} functions are just to ensure that \ensuremath{\Varid{x}}
is a in a strict position, and that it's only at one position in \ensuremath{\Varid{e}}.
These aren't required for correctness,
we've found that this restrictions generate better code.

\begin{figure}
\textbf{Let Folding}\\
\begin{minipage}{.30\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{8}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;{}\<[8]%
\>[8]{}\Varid{v}\mathrel{=}\Varid{e}_{\Varid{v}}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;{}\<[8]%
\>[8]{}\mathbf{case}\;\Varid{e}\;\mathbf{of}\;\overline{\Conid{C}_{\Varid{i}}\;\overline{\Varid{x}} \to \Varid{e}_{\Varid{i}}} {}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage} \begin{minipage}{.1\textwidth}$\vert$ \ensuremath{\Varid{v}\not\in \Varid{e}}\end{minipage} \ensuremath{\Rrightarrow }
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{9}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{case}\;{}\<[9]%
\>[9]{}\Varid{e}\;\mathbf{of}{}\<[E]%
\\
\>[9]{}\overline{\Conid{C}_{\Varid{i}}\;\overline{\Varid{x}} \to \mathbf{let}\;\Varid{v}\mathrel{=}\Varid{e}_{\Varid{v}}\;\mathbf{in}\;\Varid{e}_{\Varid{i}}} {}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}\\
\textbf{Unapply}\\
\begin{minipage}{.30\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{apply}\;\Varid{f}_{\Varid{k}}\;(\Varid{a}_{\mathrm{1}}\ldots \Varid{a}_{\Varid{k}}\ldots \Varid{a}_{\Varid{n}}){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage} \begin{minipage}{.1\textwidth} $\ $ \end{minipage} \ensuremath{\Rrightarrow }
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{apply}\;(\Varid{apply}\;\Varid{f}\;(\Varid{a}_{\mathrm{1}}\ldots \Varid{a}_{\Varid{k}}))\;a_{k+1}\ldots \Varid{a}_{\Varid{n}}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}\\
\begin{minipage}{.30\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{apply}\;\Varid{f}_{\Varid{n}}\;(\Varid{a}_{\mathrm{1}}\ldots \Varid{a}_{\Varid{n}}){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage} \begin{minipage}{.1\textwidth} $\ $ \end{minipage} \ensuremath{\Rrightarrow }
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{f}\;(\Varid{a}_{\mathrm{1}}\ldots \Varid{a}_{\Varid{n}}){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}\\
\begin{minipage}{.30\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{35}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{apply}\;\Varid{f}_{\Varid{k}}\;(\Varid{a}_{\mathrm{1}}\ldots \Varid{a}_{\Varid{n}})\mid \Varid{k}\mathbin{>}{}\<[35]%
\>[35]{}\Varid{n}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage} \begin{minipage}{.1\textwidth} $\ $ \end{minipage} \ensuremath{\Rrightarrow }
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}f_{k-n}\;(\Varid{a}_{\mathrm{1}}\ldots \Varid{a}_{\Varid{n}}){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}\\
\textbf{Inlining}\\
\begin{minipage}{.30\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{8}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;{}\<[8]%
\>[8]{}\Varid{x}\mathrel{=}\mathbf{case}\;\Varid{e}\;\mathbf{of}\;\Varid{alts}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;{}\<[8]%
\>[8]{}\Varid{e'}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage} \begin{minipage}{.1\textwidth}$\vert$ \ensuremath{\Varid{x}\in_1\Varid{e'}}\\ $\vert$ \ensuremath{\Varid{strict}\;\Varid{x}}\end{minipage} \ensuremath{\Rrightarrow }
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{e'}[\Varid{x}\to\;\mathbf{case}\;\Varid{e}\;\mathbf{of}\;\Varid{alts}]{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}\\
\begin{minipage}{.30\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;\Varid{x}\mathrel{=}\Conid{C}\;\overline{\Varid{v}} \;\mathbf{in}\;\Varid{e}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage} \begin{minipage}{.1\textwidth}$\vert$ \ensuremath{\Varid{x}\not\in \Varid{e}}\end{minipage} \ensuremath{\Rrightarrow }
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{e}[\Varid{x}\to\Conid{C}\;\overline{\Varid{v}} ]{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}\\
\begin{minipage}{.30\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{24}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;\Varid{x}\mathrel{=}\Varid{f}_{\Varid{k}}\;\overline{\Varid{v}} \;{}\<[24]%
\>[24]{}\mathbf{in}\;\Varid{e}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage} \begin{minipage}{.1\textwidth}$\vert$ \ensuremath{\Varid{x}\not\in \Varid{e}}\end{minipage} \ensuremath{\Rrightarrow }
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{e}[\Varid{x}\to\Varid{f}_{\Varid{k}}\;\overline{\Varid{v}} ]{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}\\
\begin{minipage}{.30\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;\Varid{x}\mathrel{=}\Varid{l}\;\mathbf{in}\;\Varid{e}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage} \begin{minipage}{.1\textwidth} $\ $ \end{minipage} \ensuremath{\Rrightarrow }
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{4}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[4]{}\Varid{e}[\Varid{x}\to\Varid{l}]{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}\\
\caption{rules for variable inlining.\\
         We need to ensure that \ensuremath{\Varid{x}} isn't used recursively before we inline it.
         Guards indicate that the rule fire only if the guard is satisfied.
         The notation $\in_1$ indicates that the variable $x$ occurs exactly once in $e'$,
         and \ensuremath{\Varid{strict}\;\Varid{x}} indicates that $x$ is strict, so the case will be evaluated.}
\label{fig:inline}
\end{figure}

\begin{figure}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{4}{@{}>{\hspre}l<{\hspost}@{}}%
\column{5}{@{}>{\hspre}l<{\hspost}@{}}%
\column{11}{@{}>{\hspre}l<{\hspost}@{}}%
\column{12}{@{}>{\hspre}l<{\hspost}@{}}%
\column{25}{@{}>{\hspre}l<{\hspost}@{}}%
\column{35}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{unapply}\mathbin{::}\Conid{Opt}{}\<[E]%
\\
\>[3]{}\Varid{unapply}\;(\Varid{v},\anonymous )\;(\Varid{apply}\;(\Conid{Comb}\;(\Conid{FuncPartCall}\;\Varid{k})\;\Varid{f}\;\Varid{es})\;\Varid{as}){}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mathrel{=}\mathbf{case}\;{}\<[12]%
\>[12]{}\Varid{compare}\;\Varid{k}\;\Varid{n}\;\mathbf{of}{}\<[E]%
\\
\>[12]{}\Conid{LT}\to \Conid{Let}\;[\mskip1.5mu (\Varid{v},\Conid{Comb}\;\Conid{FuncCall}\;\Varid{f}\;(\Varid{es}\plus \Varid{as}_{\mathrm{1}}))\mskip1.5mu]\;(\Varid{apply}\;(\Conid{Var}\;\Varid{n})\;\Varid{as}_{\mathrm{2}}){}\<[E]%
\\
\>[12]{}\Conid{EQ}\to \Conid{Comb}\;\Conid{FuncCall}\;\Varid{f}\;(\Varid{es}\plus \Varid{as}){}\<[E]%
\\
\>[12]{}\Conid{GT}\to \Conid{Comb}\;(\Conid{FuncPartCall}\;(\Varid{k}\mathbin{-}\Varid{n}))\;\Varid{f}\;(\Varid{es}\plus \Varid{as}){}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mathbf{where}\;{}\<[11]%
\>[11]{}\Varid{n}{}\<[25]%
\>[25]{}\mathrel{=}\Varid{length}\;\Varid{as}{}\<[E]%
\\
\>[11]{}(\Varid{as}_{\mathrm{1}},\Varid{as}_{\mathrm{2}}){}\<[25]%
\>[25]{}\mathrel{=}\Varid{splitAt}\;(\Varid{n}\mathbin{-}\Varid{k}){}\<[E]%
\\[\blanklineskip]%
\>[3]{}\Varid{letFold}\mathbin{::}\Conid{Opt}{}\<[E]%
\\
\>[3]{}\Varid{letFold}\;(\Varid{n},\anonymous )\;(\Conid{Let}\;[\mskip1.5mu (\Varid{v},\Varid{e}_{\Varid{v}})\mskip1.5mu]\;\Varid{c}\mathord{@}(\Conid{Case}\;\Varid{e}\;\Varid{bs})){}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mid \Varid{not}\;(\Varid{hasVar}\;\Varid{e}\;\Varid{v}){}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mathrel{=}\Conid{Case}\;\Varid{e}\;(\Varid{zipWith}\;\Varid{addVar}\;[\mskip1.5mu \mathrm{1}\mathinner{\ldotp\ldotp}\mskip1.5mu]\;\Varid{bs}){}\<[E]%
\\
\>[4]{}\hsindent{1}{}\<[5]%
\>[5]{}\mathbf{where}\;{}\<[12]%
\>[12]{}\Varid{addVar}\;\Varid{k}\;(\Conid{Branch}\;\Varid{p}\;\Varid{e}){}\<[35]%
\>[35]{}\mathrel{=}\Conid{Branch}\;\Varid{p}\;(\Conid{Let}\;[\mskip1.5mu (\Varid{n}\mathbin{+}\Varid{k},\sigma\;\Varid{k}\;\Varid{e}_{\Varid{v}})\mskip1.5mu]\;(\sigma\;\Varid{k}\;\Varid{e})){}\<[E]%
\\
\>[12]{}\sigma\;\Varid{k}{}\<[35]%
\>[35]{}\mathrel{=}\Varid{sub}\;((\Varid{v},\Varid{n}\mathbin{+}\Varid{k})\hspace{2pt}\text{@}\hspace{-3pt}\mathbin{>}\Varid{idSub}){}\<[E]%
\\[\blanklineskip]%
\>[3]{}\Varid{inline}\mathbin{::}\Conid{Opt}{}\<[E]%
\\
\>[3]{}\Varid{inline}\;\anonymous \;(\Conid{Let}\;[\mskip1.5mu \Varid{v}\mathord{@}(\Varid{x},\Conid{Case}\;\anonymous \;\anonymous )\mskip1.5mu]\;\Varid{e}){}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mid \Varid{strict}\;\Varid{x}\;\Varid{e}\mathbin{\&}\Varid{uses}\;\Varid{x}\;\Varid{e}\Varid{==}\mathrm{1}\mathrel{=}\Varid{sub}\;(\Varid{v}\hspace{2pt}\text{@}\hspace{-3pt}\mathbin{>}\Varid{idSub})\;\Varid{e}{}\<[E]%
\\[\blanklineskip]%
\>[3]{}\Varid{inline}\;\anonymous \;(\Conid{Let}\;[\mskip1.5mu (\Varid{x},\Varid{f}\mathord{@}(\Conid{Comb}\;\Varid{ct}\;\anonymous \;\anonymous ))\mskip1.5mu]\;\Varid{e}){}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mid (\Varid{isCons}\;\Varid{ct}\mathrel{\vee}\Varid{isPart}\;\Varid{ct})\mathbin{\&}\Varid{nonRecursive}\;\Varid{x}\;\Varid{f}\mathrel{=}\Varid{sub}\;((\Varid{x},\Varid{f})\hspace{2pt}\text{@}\hspace{-3pt}\mathbin{>}\Varid{idSub})\;\Varid{e}{}\<[E]%
\\[\blanklineskip]%
\>[3]{}\Varid{inline}\;\anonymous \;(\Conid{Let}\;[\mskip1.5mu \Varid{v}\mathord{@}(\anonymous ,\Conid{Lit}\;\anonymous )\mskip1.5mu]\;\Varid{e})\mathrel{=}\Varid{sub}\;(\Varid{v}\hspace{2pt}\text{@}\hspace{-3pt}\mathbin{>}\Varid{idSub})\;\Varid{e}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\caption{Gas implementation of the inlining rules.}
\label{fig:inlineCode}
\end{figure}

\subsection{Reduce}

Finally we come to reduction.
While this was a simpler task than inlining in GHC,
it becomes a very tricky prospect in Curry.
Fortunately, we've already done the hard work.
At this point, in any given function definition,
the only place a function symbol is allowed to appear in our expressions is
as the root of the body,
as the root of a branch in a \ensuremath{\mathbf{case}} expression,
as the root the result of a \ensuremath{\mathbf{let}} expression,
or as a variable assignment in a let-expression.
Furthermore our functions only contain trivial arguments,
so it's now valid to reduce any function we come across.

\begin{theorem}[reduction]
Let \ensuremath{\Varid{e}} be an expression in limited A-Normal Form,
let \ensuremath{\Varid{e}|_{\Varid{p}}\mathrel{=}\Varid{f}\;\overline{\Varid{e}} },
where \ensuremath{\Varid{f}} is a function symbol with definition \ensuremath{\Varid{f}\;\overline{\Varid{v}} \mathrel{=}\Varid{b}},
and let $\sigma = \{\overline{ v } \mapsto \overline{e}\}$.
Then \ensuremath{\Varid{e}[\Varid{p}\to\sigma\;\Varid{b}]}
has the same values as \ensuremath{\Varid{e}}.
\end{theorem}

\begin{proof}
First not that There is only one way to replace an expression
where the root has symbol \ensuremath{\Varid{f}}, with the body of the definition for \ensuremath{\Varid{f}}.
Therefore This is a deterministic step, and by the path compression theorem
\ensuremath{\Varid{e}} and \ensuremath{\Varid{e}[\Varid{p}\to\sigma\;\Varid{b}]} have the same values.
\end{proof}

We give the GAS rules for reduction in figure \ref{fig:reduce}.
These rule make use of the function table
We make sure that \ensuremath{\Conid{B}_\mathcal{F} \;\Varid{f}} replaces the definition with fresh variables.
Therefore, we avoid any need to deal with shadowing and name capture.
This strategy was taken from \cite{haskellInliner} and it works very well.
Although, since FlatCurry uses numbers exclusively to represent variables,
we don't get the same readable code.

\begin{figure}
\textbf{Reduce Base:}\\
\begin{minipage}{.30\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{f}\;\overline{\Varid{e}} {}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage} \begin{minipage}{.14\textwidth} $\vert$ \ensuremath{\Varid{top}\mathrel{\wedge}\Conid{I}_\mathcal{F} \hspace{-2pt}(\Varid{f})} \end{minipage} \ensuremath{\Rrightarrow }
\begin{minipage}{.30\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Conid{B}_\mathcal{F} \hspace{-2pt}(\Varid{f})[\overline{\Varid{v}} \to\overline{\Varid{e}} ]{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}\\
\textbf{Reduce Branch:}\\
\begin{minipage}{.30\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{case}\;\Varid{e'}\;\mathbf{of}\;\overline{\Conid{Ctr}\to \Varid{f}\;\overline{\Varid{e}} } {}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage} \begin{minipage}{.14\textwidth} $\vert$ \ensuremath{\Conid{I}_\mathcal{F} \hspace{-2pt}(\Varid{f})} \end{minipage} \ensuremath{\Rrightarrow }
\begin{minipage}{.30\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{case}\;\Varid{e'}\;\mathbf{of}\;\overline{\Conid{B}_\mathcal{F} \;\Varid{f}[\overline{\Varid{v}} \to\overline{\Varid{e}} ]} {}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}\\
\textbf{Reduce Let:}\\
\begin{minipage}{.30\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;\overline{\Varid{v}_{\Varid{i}}\mathrel{=}\Varid{e}_{\Varid{i}}} \;\mathbf{in}\;\Varid{f}\;\overline{\Varid{e}} {}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage} \begin{minipage}{.14\textwidth} $\vert$ \ensuremath{\Conid{I}_\mathcal{F} \hspace{-2pt}(\Varid{f})} \end{minipage} \ensuremath{\Rrightarrow }
\begin{minipage}{.30\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;\overline{\Varid{v}_{\Varid{i}}\mathrel{=}\Varid{e}_{\Varid{i}}} \;\mathbf{in}\;\Conid{B}_\mathcal{F} \;\Varid{f}[\overline{\Varid{v}} \to\overline{\Varid{e}} ]{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}\\
\textbf{Reduce Useful:}\\
\begin{minipage}{.30\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;\Varid{x}\mathrel{=}\Varid{f}\;\overline{\Varid{e}} \;\mathbf{in}\;\Varid{e'}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage} \begin{minipage}{.14\textwidth} $\vert$ \ensuremath{\Conid{U}_\mathcal{F} \hspace{-2pt}(\Varid{f})} \end{minipage} \ensuremath{\Rrightarrow }
\begin{minipage}{.30\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;\Varid{x}\mathrel{=}\Conid{B}_\mathcal{F} \;\Varid{f}[\overline{\Varid{v}} \to\overline{\Varid{e}} ]\;\mathbf{in}\;\Varid{e'}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}\\
\textbf{Reduce Simple:}\\
\begin{minipage}{.30\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;\Varid{x}\mathrel{=}\Varid{f}\;\overline{\Varid{e}} \;\mathbf{in}\;\Varid{e'}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage} \begin{minipage}{.14\textwidth} $\vert$ \ensuremath{\Conid{S}_\mathcal{F} \hspace{-2pt}(\Varid{f})} \end{minipage} \ensuremath{\Rrightarrow }
\begin{minipage}{.30\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;\Varid{x}\mathrel{=}\Conid{B}_\mathcal{F} \;\Varid{f}[\overline{\Varid{v}} \to\overline{\Varid{e}} ]\;\mathbf{in}\;\Varid{e'}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}\\
\textbf{Reduce Cancels:}\\
\begin{minipage}{.30\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;\Varid{x}\mathrel{=}\Varid{f}\;\overline{\Varid{e}} \;\mathbf{in}\;\Varid{e'}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage} \begin{minipage}{.14\textwidth} $\vert$ \ensuremath{\Conid{C}_\mathcal{F} \hspace{-2pt}(\Varid{f})} \end{minipage} \ensuremath{\Rrightarrow }
\begin{minipage}{.30\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;\Varid{x}\mathrel{=}\Conid{B}_\mathcal{F} \;\Varid{f}[\overline{\Varid{v}} \to\overline{\Varid{e}} ]\;\mathbf{in}\;\Varid{e'}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}\\
\caption{Rules for reduction.\\
         All expressions are kept in A-Normal Form.
         \ensuremath{\textbf{Reduce Base}} is only run at the root of the body.
         While the last three rules are very similar,
         It's useful to keep them separated for debugging reduction derivations.}
\label{fig:reduce}
\end{figure}

\begin{figure}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{5}{@{}>{\hspre}l<{\hspost}@{}}%
\column{6}{@{}>{\hspre}l<{\hspost}@{}}%
\column{9}{@{}>{\hspre}l<{\hspost}@{}}%
\column{16}{@{}>{\hspre}l<{\hspost}@{}}%
\column{17}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{reduce}\mathbin{::}\Conid{FunTable}\to \Conid{Opt}{}\<[E]%
\\
\>[3]{}\Varid{reduce}\;\Varid{funs}{}\<[16]%
\>[16]{}\mathrel{=}\Varid{reduce\char95 base}\;\Varid{funs}{}\<[E]%
\\
\>[16]{}\mathbin{?}\Varid{reduce\char95 branch}\;\Varid{funs}{}\<[E]%
\\
\>[16]{}\mathbin{?}\Varid{reduce\char95 let}\;\Varid{funs}{}\<[E]%
\\
\>[16]{}\mathbin{?}\Varid{reduce\char95 useful}\;\Varid{funs}{}\<[E]%
\\
\>[16]{}\mathbin{?}\Varid{reduce\char95 simple}\;\Varid{funs}{}\<[E]%
\\
\>[16]{}\mathbin{?}\Varid{reduce\char95 cancels}\;\Varid{funs}{}\<[E]%
\\[\blanklineskip]%
\>[3]{}\Varid{reduce\char95 base}\;\Varid{funs}\;(\Varid{n},\Conid{True})\;\Varid{b}\mathord{@}(\Conid{Comb}\;\Conid{FuncCall}\;\Varid{f}\;\anonymous ){}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mid \Varid{inlinable}\;\Varid{funs}\;\Varid{f}\mathrel{=}\Varid{b'}{}\<[E]%
\\
\>[5]{}\hsindent{1}{}\<[6]%
\>[6]{}\mathbf{where}\;\Varid{b'}\mathrel{=}\Varid{makeReduce}\;\Varid{funs}\;\Varid{n}\;\Varid{b}{}\<[E]%
\\[\blanklineskip]%
\>[3]{}\Varid{reduce\char95 branch}\;\Varid{funs}\;(\Varid{n},\anonymous )\;(\Conid{Case}\;\Varid{ct}\;\Varid{e}\;(\Varid{as}\plus [\mskip1.5mu \Conid{Branch}\;\Varid{p}\;\Varid{b}\mathord{@}(\Conid{Comb}\;\Conid{FuncCall}\;\Varid{f}\;\anonymous )\mskip1.5mu]\plus \Varid{bs})){}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mid \Varid{inlinable}\;\Varid{funs}\;\Varid{f}\mathrel{=}\Conid{Case}\;\Varid{ct}\;\Varid{e}\;(\Varid{as}\plus [\mskip1.5mu \Conid{Branch}\;\Varid{p}\;\Varid{b'}\mskip1.5mu]\plus \Varid{bs}){}\<[E]%
\\
\>[5]{}\hsindent{1}{}\<[6]%
\>[6]{}\mathbf{where}\;\Varid{b'}\mathrel{=}\Varid{makeReduce}\;\Varid{funs}\;\Varid{n}\;\Varid{b}{}\<[E]%
\\[\blanklineskip]%
\>[3]{}\Varid{reduce\char95 let}\;\Varid{funs}\;(\Varid{n},\anonymous )\;(\Conid{Let}\;\Varid{vs}\;\Varid{b}\mathord{@}(\Conid{Comb}\;\Conid{FuncCall}\;\Varid{f}\;\anonymous )){}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mid \Varid{inlinable}\;\Varid{funs}\;\Varid{f}\mathrel{=}\Conid{Let}\;\Varid{vs}\;\Varid{b'}{}\<[E]%
\\
\>[5]{}\hsindent{1}{}\<[6]%
\>[6]{}\mathbf{where}\;\Varid{b'}\mathrel{=}\Varid{makeReduce}\;\Varid{funs}\;\Varid{n}\;\Varid{b}{}\<[E]%
\\[\blanklineskip]%
\>[3]{}\Varid{reduce\char95 useful}\;\Varid{funs}\;(\Varid{n},\anonymous )\;(\Conid{Let}\;[\mskip1.5mu (\Varid{x},\Varid{b}\mathord{@}(\Conid{Comb}\;\Conid{FuncCall}\;\Varid{f}\;\anonymous ))\mskip1.5mu]\;\Varid{e}){}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mid {}\<[9]%
\>[9]{}\Varid{inlinable}\;\Varid{funs}\;\Varid{f}{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mathrel{\wedge}{}\<[9]%
\>[9]{}\Varid{useful}\;\Varid{funs}\;\Conid{False}\;\Varid{x}\;\Varid{e}\mathrel{=}\Conid{Let}\;[\mskip1.5mu (\Varid{x},\Varid{b'})\mskip1.5mu]\;\Varid{e}{}\<[E]%
\\
\>[5]{}\hsindent{1}{}\<[6]%
\>[6]{}\mathbf{where}\;\Varid{b'}{}\<[17]%
\>[17]{}\mathrel{=}\Varid{makeReduce}\;\Varid{funs}\;\Varid{n}\;\Varid{b}{}\<[E]%
\\[\blanklineskip]%
\>[3]{}\Varid{reduce\char95 simple}\;\Varid{funs}\;(\Varid{n},\anonymous )\;(\Conid{Let}\;[\mskip1.5mu (\Varid{x},\Varid{b}\mathord{@}(\Conid{Comb}\;\Conid{FuncCall}\;\Varid{f}\;\anonymous ))\mskip1.5mu]\;\Varid{e}){}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mid \Varid{simple}\;\Varid{funs}\;\Varid{f}\mathrel{=}\Conid{Let}\;[\mskip1.5mu (\Varid{x},\Varid{b'})\mskip1.5mu]\;\Varid{e}{}\<[E]%
\\
\>[5]{}\hsindent{1}{}\<[6]%
\>[6]{}\mathbf{where}\;\Varid{b'}\mathrel{=}\Varid{makeReduce}\;\Varid{funs}\;\Varid{n}\;\Varid{b}{}\<[E]%
\\[\blanklineskip]%
\>[3]{}\Varid{reduce\char95 cancels}\;\Varid{funs}\;(\Varid{n},\anonymous )\;(\Conid{Let}\;[\mskip1.5mu (\Varid{x},\Varid{b}\mathord{@}(\Conid{Comb}\;\Conid{FuncCall}\;\Varid{f}\;\Varid{es}))\mskip1.5mu]\;\Varid{e}){}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mid {}\<[9]%
\>[9]{}\Varid{inlinable}\;\Varid{funs}\;\Varid{f}{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mathrel{\wedge}{}\<[9]%
\>[9]{}\Varid{cancels}\;\Varid{funs}\;\Varid{f}\;(\Varid{map}\;\Varid{isConsExpr}\;\Varid{es})\mathrel{=}\Conid{Let}\;[\mskip1.5mu (\Varid{x},\Varid{b'})\mskip1.5mu]\;\Varid{e}{}\<[E]%
\\
\>[5]{}\hsindent{1}{}\<[6]%
\>[6]{}\mathbf{where}\;\Varid{b'}\mathrel{=}\Varid{makeReduce}\;\Varid{funs}\;\Varid{n}\;\Varid{b}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\caption{Gas code for the Reduce optimizations.\\
         The \ensuremath{\Varid{makeReduce}} function corresponds to \ensuremath{\Conid{B}_\mathcal{F} },
         and it is a helper function that
         substitutes parameters of the function with expressions,
         and renames variables to ensure there are no name clashes.
         The function \ensuremath{\Varid{inlinable},\Varid{useful},\Varid{simple},} and \ensuremath{\Varid{cancels}}
         correspond to \ensuremath{\Conid{I}_\mathcal{F} ,\Conid{U}_\mathcal{F} ,\Conid{S}_\mathcal{F} } and \ensuremath{\Conid{C}_\mathcal{F} } respectively.}
\label{fig:reduce_code}

\end{figure}

We end by giving a couple of examples of reductions to see how they work in practice.
The first example returns from the start of this chapter.
We see that \ensuremath{\Varid{double}\;(\mathrm{0}\mathbin{?}\mathrm{1})} is reduced so we don't make a needless call to \ensuremath{\Varid{double}},
but we've avoided the problem of run time choice semantics.

Our next function comes from a possible implementation of \ensuremath{\leq } for Boolean values.
In fact, this is the implementation we chose for the instance of the \ensuremath{\Conid{Ord}} class for \ensuremath{\Conid{Bool}}.
The example is a bit long, but it shows how many of these optimizations work together
to produce efficient code.

In the next chapter we discuss three more optimizations, Unboxing, Shortcutting, and Deforestation.
While Unboxing and Deforestation are in common use in lazy function compilers,
they have not been used for functional-logic languages before.
Shortcutting is a new optimization to Curry.


\begin{figure}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{double}\;\Varid{x}\mathrel{=}\Varid{x}\mathbin{+}\Varid{x}{}\<[E]%
\\
\>[3]{}\Varid{main}\mathrel{=}\Varid{double}\;(\mathrm{0}\mathbin{?}\mathrm{1}){}\<[E]%
\\[\blanklineskip]%
\>[3]{}\Varid{double}\;\boxed{\mathrm{0}\mathbin{?}\mathrm{1}}{}\<[E]%
\\
\>[3]{}\Rrightarrow \textbf{ANF App}{}\<[E]%
\\
\>[3]{}\mathbf{let}\;\Varid{v}_{\mathrm{1}}\mathrel{=}\mathrm{0}\mathbin{?}\mathrm{1}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\boxed{\Varid{double}\;\Varid{v}_{\mathrm{1}}}{}\<[E]%
\\
\>[3]{}\Rrightarrow \textbf{Reduce Let}{}\<[E]%
\\
\>[3]{}\mathbf{let}\;\Varid{v}_{\mathrm{1}}\mathrel{=}\mathrm{0}\mathbin{?}\mathrm{1}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\Varid{v}_{\mathrm{1}}\mathbin{+}\Varid{v}_{\mathrm{1}}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\caption{Derivation of \ensuremath{\Varid{double}\;(\mathrm{0}\mathbin{?}\mathrm{1})} showing that we still arrive at an equivalent expression.}
\label{fig:doubleReduce}
\end{figure}

\begin{figure}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{19}{@{}>{\hspre}l<{\hspost}@{}}%
\column{22}{@{}>{\hspre}l<{\hspost}@{}}%
\column{26}{@{}>{\hspre}l<{\hspost}@{}}%
\column{29}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{not}\;\Varid{v}_{\mathrm{1}}\mathrel{=}\mathbf{case}\;{}\<[19]%
\>[19]{}\Varid{v}_{\mathrm{1}}\;\mathbf{of}{}\<[E]%
\\
\>[19]{}\Conid{True}{}\<[26]%
\>[26]{}\to \Conid{False}{}\<[E]%
\\
\>[19]{}\Conid{False}{}\<[26]%
\>[26]{}\to \Conid{True}{}\<[E]%
\\
\>[3]{}\Varid{v}_{\mathrm{1}}\mathrel{\wedge}\Varid{v}_{\mathrm{2}}\mathrel{=}\mathbf{case}\;{}\<[22]%
\>[22]{}\Varid{v}_{\mathrm{1}}\;\mathbf{of}{}\<[E]%
\\
\>[22]{}\Conid{True}{}\<[29]%
\>[29]{}\to \Varid{v}_{\mathrm{2}}{}\<[E]%
\\
\>[22]{}\Conid{False}{}\<[29]%
\>[29]{}\to \Conid{False}{}\<[E]%
\\
\>[3]{}\Varid{v}_{\mathrm{1}}\mathrel{\vee}\Varid{v}_{\mathrm{2}}\mathrel{=}\mathbf{case}\;{}\<[22]%
\>[22]{}\Varid{v}_{\mathrm{1}}\;\mathbf{of}{}\<[E]%
\\
\>[22]{}\Conid{True}{}\<[29]%
\>[29]{}\to \Conid{True}{}\<[E]%
\\
\>[22]{}\Conid{False}{}\<[29]%
\>[29]{}\to \Varid{v}_{\mathrm{2}}{}\<[E]%
\\
\>[3]{}\Varid{v}_{\mathrm{1}}\leq \Varid{v}_{\mathrm{2}}\mathrel{=}\Varid{not}\;\Varid{v}_{\mathrm{1}}\mathrel{\vee}\Varid{v}_{\mathrm{2}}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\caption{Definition of \ensuremath{\leq } for \ensuremath{\Conid{Bool}}.}
\label{fig:boolLeq}
\end{figure}

\begin{figure}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{8}{@{}>{\hspre}l<{\hspost}@{}}%
\column{9}{@{}>{\hspre}l<{\hspost}@{}}%
\column{14}{@{}>{\hspre}l<{\hspost}@{}}%
\column{16}{@{}>{\hspre}l<{\hspost}@{}}%
\column{19}{@{}>{\hspre}l<{\hspost}@{}}%
\column{20}{@{}>{\hspre}l<{\hspost}@{}}%
\column{21}{@{}>{\hspre}l<{\hspost}@{}}%
\column{23}{@{}>{\hspre}l<{\hspost}@{}}%
\column{26}{@{}>{\hspre}l<{\hspost}@{}}%
\column{27}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\boxed{(\Varid{not}\;\Varid{v}_{\mathrm{1}})\mathrel{\vee}\Varid{v}_{\mathrm{2}}}{}\<[E]%
\\
\>[3]{}\Rrightarrow \textbf{ANF App}\;[\mskip1.5mu \mskip1.5mu]{}\<[E]%
\\
\>[3]{}\mathbf{let}\;\Varid{v}_{\mathrm{3}}\mathrel{=}\boxed{\Varid{not}\;\Varid{v}_{\mathrm{1}}}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\Varid{v}_{\mathrm{3}}\mathrel{\vee}\Varid{v}_{\mathrm{2}}{}\<[E]%
\\
\>[3]{}\Rrightarrow \textbf{Reduce Useful}\;[\mskip1.5mu \mskip1.5mu]{}\<[E]%
\\
\>[3]{}\mathbf{let}\;\Varid{v}_{\mathrm{3}}\mathrel{=}\mathbf{case}\;{}\<[19]%
\>[19]{}\Varid{v}_{\mathrm{1}}\;\mathbf{of}{}\<[E]%
\\
\>[19]{}\Conid{True}{}\<[26]%
\>[26]{}\to \Conid{False}{}\<[E]%
\\
\>[19]{}\Conid{False}{}\<[26]%
\>[26]{}\to \Conid{True}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\boxed{\Varid{v}_{\mathrm{3}}\mathrel{\vee}\Varid{v}_{\mathrm{2}}}{}\<[E]%
\\
\>[3]{}\Rrightarrow \textbf{Reduce Let}\;[\mskip1.5mu \mskip1.5mu]{}\<[E]%
\\
\>[3]{}\mathbf{let}\;{}\<[8]%
\>[8]{}\Varid{v}_{\mathrm{3}}\mathrel{=}\mathbf{case}\;{}\<[20]%
\>[20]{}\Varid{v}_{\mathrm{1}}\;\mathbf{of}{}\<[E]%
\\
\>[20]{}\Conid{True}{}\<[27]%
\>[27]{}\to \Conid{False}{}\<[E]%
\\
\>[20]{}\Conid{False}{}\<[27]%
\>[27]{}\to \Conid{True}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;{}\<[8]%
\>[8]{}\mathbf{case}\;{}\<[14]%
\>[14]{}\Varid{v}_{\mathrm{3}}\;\mathbf{of}{}\<[E]%
\\
\>[14]{}\Conid{True}{}\<[21]%
\>[21]{}\to \boxed{\Varid{v}_{\mathrm{3}}}{}\<[E]%
\\
\>[14]{}\Conid{False}{}\<[21]%
\>[21]{}\to \Varid{v}_{\mathrm{2}}{}\<[E]%
\\
\>[3]{}\Rrightarrow \textbf{Case Var}\;[\mskip1.5mu \mathbin{-}\mathrm{1}\mskip1.5mu]{}\<[E]%
\\
\>[3]{}\mathbf{let}\;{}\<[8]%
\>[8]{}\Varid{v}_{\mathrm{3}}\mathrel{=}\mathbf{case}\;{}\<[20]%
\>[20]{}\Varid{v}_{\mathrm{1}}\;\mathbf{of}{}\<[E]%
\\
\>[20]{}\Conid{True}{}\<[27]%
\>[27]{}\to \Conid{False}{}\<[E]%
\\
\>[20]{}\Conid{False}{}\<[27]%
\>[27]{}\to \Conid{True}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;{}\<[8]%
\>[8]{}\mathbf{case}\;{}\<[14]%
\>[14]{}\Varid{v}_{\mathrm{3}}\;\mathbf{of}{}\<[E]%
\\
\>[14]{}\Conid{True}{}\<[21]%
\>[21]{}\to \Conid{True}{}\<[E]%
\\
\>[14]{}\Conid{False}{}\<[21]%
\>[21]{}\to \Varid{v}_{\mathrm{2}}{}\<[E]%
\\
\>[3]{}\Rrightarrow \textbf{Inline Case in Case}\;[\mskip1.5mu \mskip1.5mu]{}\<[E]%
\\
\>[3]{}\mathbf{case}\;{}\<[9]%
\>[9]{}(\mathbf{case}\;{}\<[16]%
\>[16]{}\Varid{v}_{\mathrm{1}}\;\mathbf{of}{}\<[E]%
\\
\>[16]{}\Conid{True}{}\<[23]%
\>[23]{}\to \Conid{False}{}\<[E]%
\\
\>[16]{}\Conid{False}{}\<[23]%
\>[23]{}\to \Conid{True})\;\mathbf{of}{}\<[E]%
\\
\>[9]{}\Conid{True}{}\<[16]%
\>[16]{}\to \Conid{True}{}\<[E]%
\\
\>[9]{}\Conid{False}{}\<[16]%
\>[16]{}\to \Varid{v}_{\mathrm{2}}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\caption{Derivation of \ensuremath{\leq } for \ensuremath{\Conid{Bool}} condinued}
\label{fig:LtEqReduce2}
\end{figure}

\begin{figure}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{9}{@{}>{\hspre}l<{\hspost}@{}}%
\column{16}{@{}>{\hspre}l<{\hspost}@{}}%
\column{20}{@{}>{\hspre}l<{\hspost}@{}}%
\column{23}{@{}>{\hspre}l<{\hspost}@{}}%
\column{25}{@{}>{\hspre}l<{\hspost}@{}}%
\column{30}{@{}>{\hspre}l<{\hspost}@{}}%
\column{32}{@{}>{\hspre}l<{\hspost}@{}}%
\column{35}{@{}>{\hspre}l<{\hspost}@{}}%
\column{44}{@{}>{\hspre}l<{\hspost}@{}}%
\column{45}{@{}>{\hspre}l<{\hspost}@{}}%
\column{51}{@{}>{\hspre}l<{\hspost}@{}}%
\column{54}{@{}>{\hspre}l<{\hspost}@{}}%
\column{58}{@{}>{\hspre}l<{\hspost}@{}}%
\column{61}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Rrightarrow \textbf{Case in Case}\;[\mskip1.5mu \mskip1.5mu]{}\<[E]%
\\
\>[3]{}\mathbf{case}\;{}\<[9]%
\>[9]{}\Varid{v}_{\mathrm{1}}\;\mathbf{of}{}\<[E]%
\\
\>[9]{}\Conid{True}{}\<[16]%
\>[16]{}\to {}\<[20]%
\>[20]{}\mathbf{let}\;\boxed{\Varid{v7}\mathrel{=}\Conid{False}}\;{}\<[45]%
\>[45]{}\mathbf{in}\;\mathbf{case}\;{}\<[54]%
\>[54]{}\Varid{v7}\;\mathbf{of}{}\<[E]%
\\
\>[54]{}\Conid{True}{}\<[61]%
\>[61]{}\to \Conid{True}{}\<[E]%
\\
\>[54]{}\Conid{False}{}\<[61]%
\>[61]{}\to \Varid{v}_{\mathrm{2}}{}\<[E]%
\\
\>[9]{}\Conid{False}{}\<[16]%
\>[16]{}\to {}\<[20]%
\>[20]{}\mathbf{let}\;\Varid{v8}\mathrel{=}\Conid{True}\;{}\<[45]%
\>[45]{}\mathbf{in}\;\mathbf{case}\;{}\<[54]%
\>[54]{}\Varid{v8}\;\mathbf{of}{}\<[E]%
\\
\>[54]{}\Conid{True}{}\<[61]%
\>[61]{}\to \Conid{True}{}\<[E]%
\\
\>[54]{}\Conid{False}{}\<[61]%
\>[61]{}\to \Varid{v}_{\mathrm{2}}{}\<[E]%
\\
\>[3]{}\Rrightarrow \textbf{Inline Constructor}\;[\mskip1.5mu \mathrm{0}\mskip1.5mu]{}\<[E]%
\\
\>[3]{}\mathbf{case}\;{}\<[9]%
\>[9]{}\Varid{v}_{\mathrm{1}}\;\mathbf{of}{}\<[E]%
\\
\>[9]{}\Conid{True}\to \mathbf{case}\;{}\<[23]%
\>[23]{}\boxed{\Conid{False}}\;\mathbf{of}{}\<[E]%
\\
\>[23]{}\Conid{True}{}\<[30]%
\>[30]{}\to \Conid{True}{}\<[E]%
\\
\>[23]{}\Conid{False}{}\<[30]%
\>[30]{}\to \Varid{v}_{\mathrm{2}}{}\<[E]%
\\
\>[9]{}\Conid{False}{}\<[16]%
\>[16]{}\to {}\<[20]%
\>[20]{}\mathbf{let}\;\Varid{v8}\mathrel{=}\Conid{True}\;{}\<[35]%
\>[35]{}\mathbf{in}\;\mathbf{case}\;{}\<[44]%
\>[44]{}\Varid{v8}\;\mathbf{of}{}\<[E]%
\\
\>[44]{}\Conid{True}{}\<[51]%
\>[51]{}\to \Conid{True}{}\<[E]%
\\
\>[44]{}\Conid{False}{}\<[51]%
\>[51]{}\to \Varid{v}_{\mathrm{2}}{}\<[E]%
\\
\>[3]{}\Rrightarrow \textbf{Case Cancel Constructor}\;[\mskip1.5mu \mathrm{0}\mskip1.5mu]{}\<[E]%
\\
\>[3]{}\mathbf{case}\;{}\<[9]%
\>[9]{}\Varid{v}_{\mathrm{1}}\;\mathbf{of}{}\<[E]%
\\
\>[9]{}\Conid{True}{}\<[16]%
\>[16]{}\to \Varid{v}_{\mathrm{2}}{}\<[E]%
\\
\>[9]{}\Conid{False}{}\<[16]%
\>[16]{}\to \mathbf{let}\;\boxed{\Varid{v8}\mathrel{=}\Conid{True}}\;\mathbf{in}\;\mathbf{case}\;{}\<[51]%
\>[51]{}\Varid{v8}\;\mathbf{of}{}\<[E]%
\\
\>[51]{}\Conid{True}{}\<[58]%
\>[58]{}\to \Conid{True}{}\<[E]%
\\
\>[51]{}\Conid{False}{}\<[58]%
\>[58]{}\to \Varid{v}_{\mathrm{2}}{}\<[E]%
\\
\>[3]{}\Rrightarrow \textbf{Inline Constructor}\;[\mskip1.5mu \mathrm{1}\mskip1.5mu]{}\<[E]%
\\
\>[3]{}\mathbf{case}\;{}\<[9]%
\>[9]{}\Varid{v}_{\mathrm{1}}\;\mathbf{of}{}\<[E]%
\\
\>[9]{}\Conid{True}{}\<[16]%
\>[16]{}\to \Varid{v}_{\mathrm{2}}{}\<[E]%
\\
\>[9]{}\Conid{False}{}\<[16]%
\>[16]{}\to \mathbf{case}\;{}\<[25]%
\>[25]{}\boxed{\Conid{True}}\;\mathbf{of}{}\<[E]%
\\
\>[25]{}\Conid{True}{}\<[32]%
\>[32]{}\to \Conid{True}{}\<[E]%
\\
\>[25]{}\Conid{False}{}\<[32]%
\>[32]{}\to \Varid{v}_{\mathrm{2}}{}\<[E]%
\\
\>[3]{}\Rrightarrow \textbf{Case Cancel Constructor}\;[\mskip1.5mu \mathrm{1}\mskip1.5mu]{}\<[E]%
\\
\>[3]{}\mathbf{case}\;{}\<[9]%
\>[9]{}\Varid{v}_{\mathrm{1}}\;\mathbf{of}{}\<[E]%
\\
\>[9]{}\Conid{True}{}\<[16]%
\>[16]{}\to \Varid{v}_{\mathrm{2}}{}\<[E]%
\\
\>[9]{}\Conid{False}{}\<[16]%
\>[16]{}\to \Conid{True}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{figure}


\chapter{Memory Optimizations} \label{ch:Memory Optimizations}


In this chapter we develop three new optimizations for Curry.
First, Unboxing is an attempt to remove boxed values from our language.
We discuss our implementation of primitive values and operations,
and how explicitly representing the boxes around these values leads to optimizations.
Second, we adapt the shortcutting optimization,
which was designed for rewrite systems,
to work in our compilation scheme for Curry.
The techniques used in shortcutting allow us to
skip the construction of the scrutenee of a case expression.
Finally, Shortcut Deforestation is a optimization for removing intermediate lists.
This has been studied extensively in functional languages,
but it has not been shown to be valid in the presence of non-determinism.
We prove its validity in Curry,
and give a formulation that can apply to combinator languages.

\section{Unboxing}

So far we've avoided talking about operations in Curry for 
primitive data types \ensuremath{\Conid{Int}}, \ensuremath{\Conid{Char}}, and \ensuremath{\Conid{Float}}.
This is primarily because in all current implementations of Curry,
primitive values are boxed.
A \emph{box}\index{boxed} for a primitive value is a node in the expression graph
that holds the primitive value.
This is done primarily to give a uniform representation of nodes in our expression graph.
There are many reasons why we would want to box primitive values.
It makes the implementations of run-time systems, garbage collectors, and debugging software much easier.
The choice of how we represent boxes has a pervasive effect on the compiler.
Since we knew how we intended to implement Unboxing, 
we decided to use our representation from the beginning.

We chose to follow the style of Unboxing from Launchbury et al. \cite{unboxing}
and represent all boxes explicitly in FlatCurry,
as opposed to other system which may represent the boxes at run-time,
but don't mention the boxes at compile time.
This has several advantages, but one of the most important
is that we can apply optimizations to the boxes themselves.

\subsection{Boxed Values}

Before we get into the process of unboxing values,
we need to look at how we represent boxed values.
The idea of boxing primitive values is common in higher level languages,
since it allows us to simplify the run-time system.
This is especially true in lazy languages where 
expressions such as \ensuremath{\mathrm{3}\mathbin{+}\mathrm{5}} are represented by an expression
graph that will eventually hold the value \ensuremath{\mathrm{8}} after it is evaluated.
It is important that every node that points to the expression graph of \ensuremath{\mathrm{3}\mathbin{+}\mathrm{5}}
at run-time will then point to the expression graph of \ensuremath{\mathrm{8}} after it is evaluated.
This update is difficult if \ensuremath{\mathrm{8}} is the literal C integer \texttt 8.
However, if \ensuremath{\mathrm{8}} is instead a constructor node containing the value 8, then this is fine.
We just replace the contents of the node labeled by \ensuremath{\mathbin{+}} by a node labeled by \ensuremath{\Conid{Int}} with one child,
which is the C integer 8.

The purpose of unboxing is not to remove boxes entirely.
Instead we try to find cases where we replace the creation of new nodes in the expression graph
with primitive arithmetic operations.
The idea from Launchbury \cite{unboxing}
is that we can find these cases where we can remove boxes more easily if the boxes
are explicitly represented in the intermediate representation.
In order to represent boxes we need to make three changes to our FlatCurry programs.

The first is that every primitive value, a literal value of type \ensuremath{\Conid{Int}}, \ensuremath{\Conid{Float}}, or \ensuremath{\Conid{Char}}
is replaces with a constructor of the appropriate type.
For example \ensuremath{\mathrm{5}\mathbin{+}\mathrm{6}} is transformed into the expression \ensuremath{(\Conid{Int}\;\mathrm{5})\mathbin{+}(\Conid{Int}\;\mathrm{6})}.

Second, we need to wrap cases of literal values with cases that remove the box.
This can best be demonstrated with the example in figure \ref{fig:caseWrap}.
The value \ensuremath{\Varid{x}} is evaluated down to an \ensuremath{\Conid{Int}} node, then we extract
the unboxed integer \ensuremath{\Varid{x}_{\text{prim}}} and proceed with the primitive case statement.
We also add one dummy branch to the unboxing case for each branch in the primitive case.
These branches are there to instruct the code generator on what values a free variable could
take on.

\begin{figure}
\begin{minipage}{.4\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{9}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{case}\;{}\<[9]%
\>[9]{}\Varid{x}\;\mathbf{of}{}\<[E]%
\\
\>[9]{}\mathrm{0}\to \Conid{False}{}\<[E]%
\\
\>[9]{}\mathrm{1}\to \Conid{True}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage} \ensuremath{\Rrightarrow }
\begin{minipage}{.4\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{9}{@{}>{\hspre}l<{\hspost}@{}}%
\column{26}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{case}\;{}\<[9]%
\>[9]{}\Varid{x}\;\mathbf{of}{}\<[E]%
\\
\>[9]{}\Conid{Int}\;\Varid{x}_{\text{prim}}\to \mathbf{case}\;{}\<[26]%
\>[26]{}\Varid{x}_{\text{prim}}\;\mathbf{of}{}\<[E]%
\\
\>[26]{}\mathrm{0}\to \Conid{False}{}\<[E]%
\\
\>[26]{}\mathrm{1}\to \Conid{True}{}\<[E]%
\\
\>[9]{}\mathrm{0}\to \textbf{free} \;\mathbf{case}{}\<[E]%
\\
\>[9]{}\mathrm{1}\to \textbf{free} \;\mathbf{case}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}
\caption{Wrapping a primitive case with a case to remove the box.}
\label{fig:caseWrap}
\end{figure}

Finally we need to give new definitions for primitive operations such as \ensuremath{\mathbin{+}} and \ensuremath{\leq }.
All of the operators fit the same pattern, so we only give the definitions for \ensuremath{\mathbin{+}} and \ensuremath{\leq } for integers
in figure \ref{fig:primOp}.
In order to evaluate a \ensuremath{\mathbin{+}} node, we evaluate the first argument to its box,
then we unbox it with the case statement.
We do not have any dummy branches for free variables.
This represents the fact that \ensuremath{\mathbin{+}} is a rigid operation.
We proceed to evaluate and unbox the second argument.
Finally, we return the result inside of a new box.
The \ensuremath{\mathbin{+}_{\text{prim}}} operation performs the addition, and is translated to an add expression in C.
The \ensuremath{\leq _{\text{prim}}} operation performs a comparison between two integers, and returns either
\ensuremath{\Conid{True}} or \ensuremath{\Conid{False}} based on the result.

\begin{figure}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{17}{@{}>{\hspre}l<{\hspost}@{}}%
\column{18}{@{}>{\hspre}l<{\hspost}@{}}%
\column{34}{@{}>{\hspre}l<{\hspost}@{}}%
\column{35}{@{}>{\hspre}l<{\hspost}@{}}%
\column{46}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}(\mathbin{+})\mathbin{::}\Conid{Int}\to \Conid{Int}\to \Conid{Int}{}\<[E]%
\\
\>[3]{}\Varid{x}\mathbin{+}\Varid{y}\mathrel{=}\mathbf{case}\;{}\<[17]%
\>[17]{}\Varid{x}\;\mathbf{of}{}\<[E]%
\\
\>[17]{}\Conid{Int}\;\Varid{x}_{\text{prim}}\to \mathbf{case}\;{}\<[34]%
\>[34]{}\Varid{y}\;\mathbf{of}{}\<[E]%
\\
\>[34]{}\Conid{Int}\;\Varid{y}_{\text{prim}}\to {}\<[46]%
\>[46]{}\mathbf{let}\;\Varid{v}\mathrel{=}\Varid{x}_{\text{prim}}\;\mathbin{+}_{\text{prim}}\;\Varid{y}_{\text{prim}}{}\<[E]%
\\
\>[46]{}\mathbf{in}\;\Conid{Int}\;\Varid{v}{}\<[E]%
\\[\blanklineskip]%
\>[3]{}(\leq )\mathbin{::}\Conid{Int}\to \Conid{Int}\to \Conid{Bool}{}\<[E]%
\\
\>[3]{}\Varid{x}\leq \Varid{y}\mathrel{=}\mathbf{case}\;{}\<[18]%
\>[18]{}\Varid{x}\;\mathbf{of}{}\<[E]%
\\
\>[18]{}\Conid{Int}\;\Varid{x}_{\text{prim}}\to \mathbf{case}\;{}\<[35]%
\>[35]{}\Varid{y}\;\mathbf{of}{}\<[E]%
\\
\>[35]{}\Conid{Int}\;\Varid{y}_{\text{prim}}\to \Varid{x}_{\text{prim}}\;\leq _{\text{prim}}\;\Varid{y}_{\text{prim}}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\caption{Definitions for \ensuremath{\mathbin{+}} and \ensuremath{\leq } taking boxed integers.}
\label{fig:primOp}
\end{figure}

Before we even look at trying to remove these boxes,
it's worth taking a second to see if we can optimize literal values.
There are actually a couple of significant improvements we can make
that apply more broadly.

The first is that for any constructor with no arguments, such as \ensuremath{\Conid{True}} or \ensuremath{\Conid{Nothing}},
we can create a single static node to represent that constructor.
This eliminates the need to allocate memory for each instance of \ensuremath{\Conid{True}}.
While this is great, we might expect to go further.
For example, if we could turn case statements of Boolean expressions into
simple if statements in C.
We could compare the scrutinee to \ensuremath{\Conid{True}}, and if it is, then we evaluate the true branch,
otherwise we evaluate the false branch.
Unfortunately, this doesn't work for two reasons.
First, not all instances of \ensuremath{\Conid{True}} can be the static \ensuremath{\Conid{True}} nodes.
As an example, at run-time \ensuremath{\Varid{not}\;\Conid{False}} will evaluate to \ensuremath{\Conid{True}},
but the node is going to be in the same location as the original \ensuremath{\Varid{not}} node.
Second, even if we have a Boolean expression that has been evaluated to a value,
it could still be a \texttt{FAIL} or \texttt{FREE} node.

The next optimization we can make is for the primitive types \ensuremath{\Conid{Int}}, \ensuremath{\Conid{Char}}, and \ensuremath{\Conid{Float}}.
Since these constructors have an argument, namely the primitive value,
we cannot make a single static node for them.
We might try to create a single static node for every literal value used in the program.
Unfortunately this doesn't tend to help us that much.
Consider the standard factorial program:
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{fac}\;\mathrm{0}\mathrel{=}\mathrm{1}{}\<[E]%
\\
\>[3]{}\Varid{fac}\;\Varid{n}\mathrel{=}\Varid{n}\mathbin{*}\Varid{fac}\;(\Varid{n}\mathbin{-}\mathrm{1}){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
Now if we evaluate \ensuremath{\Varid{fac}\;\mathrm{42}}, we'll allocate memory up front for \ensuremath{\mathrm{0}}, \ensuremath{\mathrm{1}}, and \ensuremath{\mathrm{42}}.
This will certainly save some memory, but not as much as we would hope.
We'll still construct every number between \ensuremath{\mathrm{2}} and \ensuremath{\mathrm{41}}.

A better solution is to employ the flyweight pattern similar to the JVM.
The idea is that small integers are likely to come up often.
So, we statically allocate all of the integers between \ensuremath{\mathbin{-}\mathrm{128}} and \ensuremath{\mathrm{128}}.
We do a similar allocation for characters.
Unfortunately, this patterns didn't show improved performance for floating point numbers.

Now that we've seen how to represent boxes,
we can work on removing them, and see what we actually gain from it.

\subsection{Unboxed Values}


In order to get an idea of the effectiveness of unboxing, let's look at an example.
Consider the function to compute Fibonacci numbers if figure \ref{fig:fib}.
We will work with this example extensively in the next couple of optimizations,
in an attempt to see how much we can optimize it.

\begin{figure}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{17}{@{}>{\hspre}l<{\hspost}@{}}%
\column{24}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{fib}\mathbin{::}\Conid{Int}\to \Conid{Int}{}\<[E]%
\\
\>[3]{}\Varid{fib}\;\Varid{n}\mathrel{=}\mathbf{case}\;{}\<[17]%
\>[17]{}\Varid{n}\leq \mathrm{1}\;\mathbf{of}{}\<[E]%
\\
\>[17]{}\Conid{True}{}\<[24]%
\>[24]{}\to \Varid{n}{}\<[E]%
\\
\>[17]{}\Conid{False}{}\<[24]%
\>[24]{}\to \Varid{fib}\;(\Varid{n}\mathbin{-}\mathrm{1})\mathbin{+}\Varid{fib}\;(\Varid{n}\mathbin{-}\mathrm{2}){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
After translating to A-Normal Form:
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{12}{@{}>{\hspre}l<{\hspost}@{}}%
\column{21}{@{}>{\hspre}l<{\hspost}@{}}%
\column{28}{@{}>{\hspre}c<{\hspost}@{}}%
\column{28E}{@{}l@{}}%
\column{32}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{fib}\mathbin{::}\Conid{Int}\to \Conid{Int}{}\<[E]%
\\
\>[3]{}\Varid{fib}\;\Varid{n}\mathrel{=}{}\<[12]%
\>[12]{}\mathbf{let}\;\Varid{cond}\mathrel{=}\Varid{n}\leq \mathrm{1}{}\<[E]%
\\
\>[12]{}\mathbf{in}\;\mathbf{case}\;{}\<[21]%
\>[21]{}\Varid{cond}\;\mathbf{of}{}\<[E]%
\\
\>[21]{}\Conid{True}{}\<[28]%
\>[28]{}\to {}\<[28E]%
\>[32]{}\Varid{n}{}\<[E]%
\\
\>[21]{}\Conid{False}{}\<[28]%
\>[28]{}\to {}\<[28E]%
\>[32]{}\mathbf{let}\;\Varid{n}_{\mathrm{1}}\mathrel{=}\Varid{n}\mathbin{-}\mathrm{1}{}\<[E]%
\\
\>[32]{}\mathbf{in}\;\mathbf{let}\;\Varid{f}_{\mathrm{1}}\mathrel{=}\Varid{fib}\;\Varid{n}_{\mathrm{1}}{}\<[E]%
\\
\>[32]{}\mathbf{in}\;\mathbf{let}\;\Varid{n}_{\mathrm{2}}\mathrel{=}\Varid{n}\mathbin{-}\mathrm{2}{}\<[E]%
\\
\>[32]{}\mathbf{in}\;\mathbf{let}\;\Varid{f}_{\mathrm{2}}\mathrel{=}\Varid{fib}\;\Varid{n}_{\mathrm{2}}{}\<[E]%
\\
\>[32]{}\mathbf{in}\;\Varid{f}_{\mathrm{1}}\mathbin{+}\Varid{f}_{\mathrm{2}}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
After adding boxes:
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{12}{@{}>{\hspre}l<{\hspost}@{}}%
\column{21}{@{}>{\hspre}l<{\hspost}@{}}%
\column{28}{@{}>{\hspre}c<{\hspost}@{}}%
\column{28E}{@{}l@{}}%
\column{32}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{fib}\mathbin{::}\Conid{Int}\to \Conid{Int}{}\<[E]%
\\
\>[3]{}\Varid{fib}\;\Varid{n}\mathrel{=}{}\<[12]%
\>[12]{}\mathbf{let}\;\Varid{cond}\mathrel{=}\Varid{n}\leq \Conid{Int}\;\mathrm{1}{}\<[E]%
\\
\>[12]{}\mathbf{in}\;\mathbf{case}\;{}\<[21]%
\>[21]{}\Varid{cond}\;\mathbf{of}{}\<[E]%
\\
\>[21]{}\Conid{True}{}\<[28]%
\>[28]{}\to {}\<[28E]%
\>[32]{}\Varid{n}{}\<[E]%
\\
\>[21]{}\Conid{False}{}\<[28]%
\>[28]{}\to {}\<[28E]%
\>[32]{}\mathbf{let}\;\Varid{n}_{\mathrm{1}}\mathrel{=}\Varid{n}\mathbin{-}\Conid{Int}\;\mathrm{1}{}\<[E]%
\\
\>[32]{}\mathbf{in}\;\mathbf{let}\;\Varid{f}_{\mathrm{1}}\mathrel{=}\Varid{fib}\;\Varid{n}_{\mathrm{1}}{}\<[E]%
\\
\>[32]{}\mathbf{in}\;\mathbf{let}\;\Varid{n}_{\mathrm{2}}\mathrel{=}\Varid{n}\mathbin{-}\Conid{Int}\;\mathrm{2}{}\<[E]%
\\
\>[32]{}\mathbf{in}\;\mathbf{let}\;\Varid{f}_{\mathrm{2}}\mathrel{=}\Varid{fib}\;\Varid{n}_{\mathrm{2}}{}\<[E]%
\\
\>[32]{}\mathbf{in}\;\Varid{f}_{\mathrm{1}}\mathbin{+}\Varid{f}_{\mathrm{2}}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\caption{A program for generating Fibonacci numbers translated to ANF, and adding boxes.}
\label{fig:fib}
\end{figure}

Unfortunately, using the optimizations we've already discussed,
this function can't be optimized any further.
The \ensuremath{\Varid{fib}} function is recursive, so we can't reduce it,
and \ensuremath{\Varid{n}\mathbin{-}\mathrm{1}} contains a primitive operation.
However, we allocate a lot of memory while evaluating this function.
We create 5 nodes for each recursive call, \ensuremath{\Varid{cont},\Varid{n}_{\mathrm{1}},\Varid{f}_{\mathrm{1}},\Varid{n}_{\mathrm{2}},\Varid{f}_{\mathrm{2}}}.
We don't create a node for \ensuremath{\Varid{f}_{\mathrm{1}}\mathbin{+}\Varid{f}_{\mathrm{2}}} since that will replace the root node
during evaluation.
We can statically allocate a node for each integer, because the integers are constant.
However, there's still no need for this much allocation.
The problem is that each of our primitive operations and recursive calls 
must be represented as a node to fit in with our definition of an expression graph.

However, after explicitly representing the boxes, and using our
new definitions for \ensuremath{\mathbin{+}} and \ensuremath{\leq },
we can optimize \ensuremath{\Varid{fib}} to the program given in figure \ref{fig:fibOpt1}.

\begin{figure}[t]\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{17}{@{}>{\hspre}l<{\hspost}@{}}%
\column{22}{@{}>{\hspre}l<{\hspost}@{}}%
\column{30}{@{}>{\hspre}l<{\hspost}@{}}%
\column{34}{@{}>{\hspre}l<{\hspost}@{}}%
\column{35}{@{}>{\hspre}l<{\hspost}@{}}%
\column{40}{@{}>{\hspre}l<{\hspost}@{}}%
\column{47}{@{}>{\hspre}c<{\hspost}@{}}%
\column{47E}{@{}l@{}}%
\column{51}{@{}>{\hspre}l<{\hspost}@{}}%
\column{60}{@{}>{\hspre}l<{\hspost}@{}}%
\column{63}{@{}>{\hspre}l<{\hspost}@{}}%
\column{72}{@{}>{\hspre}l<{\hspost}@{}}%
\column{81}{@{}>{\hspre}l<{\hspost}@{}}%
\column{84}{@{}>{\hspre}l<{\hspost}@{}}%
\column{93}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{fib}\;\Varid{n}\mathrel{=}\mathbf{case}\;{}\<[17]%
\>[17]{}\Varid{n}\;\mathbf{of}{}\<[E]%
\\
\>[17]{}\Conid{Int}\;{}\<[22]%
\>[22]{}\Varid{v}_{\mathrm{2}}\to {}\<[30]%
\>[30]{}\mathbf{let}\;{}\<[35]%
\>[35]{}\Varid{cond}\mathrel{=}\Varid{v}_{\mathrm{2}}\;\leq _{\text{prim}}\;\mathrm{1}{}\<[E]%
\\
\>[30]{}\mathbf{in}\;{}\<[34]%
\>[34]{}\mathbf{case}\;{}\<[40]%
\>[40]{}\Varid{cond}{}\<[E]%
\\
\>[40]{}\Conid{True}{}\<[47]%
\>[47]{}\to {}\<[47E]%
\>[51]{}\Varid{n}{}\<[E]%
\\
\>[40]{}\Conid{False}{}\<[47]%
\>[47]{}\to {}\<[47E]%
\>[51]{}\mathbf{let}\;\Varid{n}_{\mathrm{1}}{}\<[63]%
\>[63]{}\mathrel{=}\Varid{v}_{\mathrm{2}}\;\mathbin{-}_{\text{prim}}\;\mathrm{1}{}\<[E]%
\\
\>[51]{}\mathbf{in}\;\mathbf{let}\;\Varid{f}_{\mathrm{1}}{}\<[63]%
\>[63]{}\mathrel{=}\Varid{fib}\;(\Conid{Int}\;\Varid{n}_{\mathrm{1}}){}\<[E]%
\\
\>[51]{}\mathbf{in}\;\mathbf{case}\;{}\<[60]%
\>[60]{}\Varid{f}_{\mathrm{1}}\;\mathbf{of}{}\<[E]%
\\
\>[60]{}\Conid{Int}\;\Varid{p}_{\mathrm{1}}\to {}\<[72]%
\>[72]{}\mathbf{let}\;\Varid{n}_{\mathrm{2}}{}\<[84]%
\>[84]{}\mathrel{=}\Varid{v}_{\mathrm{2}}\;\mathbin{-}_{\text{prim}}\;\mathrm{2}{}\<[E]%
\\
\>[72]{}\mathbf{in}\;\mathbf{let}\;\Varid{f}_{\mathrm{2}}{}\<[84]%
\>[84]{}\mathrel{=}\Varid{fib}\;(\Conid{Int}\;\Varid{n}_{\mathrm{2}}){}\<[E]%
\\
\>[72]{}\mathbf{in}\;\mathbf{case}\;{}\<[81]%
\>[81]{}\Varid{f}_{\mathrm{2}}\;\mathbf{of}{}\<[E]%
\\
\>[81]{}\Conid{Int}\;\Varid{p}_{\mathrm{2}}\to {}\<[93]%
\>[93]{}\mathbf{let}\;\Varid{r}\mathrel{=}\Varid{p}_{\mathrm{1}}\;\mathbin{+}_{\text{prim}}\;\Varid{p}_{\mathrm{2}}{}\<[E]%
\\
\>[93]{}\mathbf{in}\;\Conid{Int}\;\Varid{r}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\caption{Optimized \ensuremath{\Varid{fib}} after Unboxing}
\label{fig:fibOpt1}
\end{figure}

As we can see, the code is significantly longer,
but now we've included the primitive operations in our code.
The variables \ensuremath{\Varid{v}_{\mathrm{2}},\Varid{n}_{\mathrm{1}},\Varid{n}_{\mathrm{2}},\Varid{p}_{\mathrm{1}},\Varid{p}_{\mathrm{2}}} are all primitive values, so we don't need to allocate
any memory for them, so they won't be represented as nodes in our expression graph.
This seems like a big win, but it's a little deceptive.
We're still allocating 1 node for \ensuremath{\Varid{cond},\Varid{f}_{\mathrm{1}},\Varid{f}_{\mathrm{2}}} and 2 nodes for the \ensuremath{\Conid{Int}} constructors.
So, we're still allocating 5 nodes, which is just as much memory as before.
This is an improvement in efficiency, but we can certainly do better.

\subsection{Primitive Conditions}

The first optimization is that we really don't need to allocate memory for \ensuremath{\Varid{cond}}.
\ensuremath{\Varid{x}\;\leq _{\text{prim}}\;\Varid{y}} should compile down to an expression involving the primitive \texttt{<=} operation in C,
and return a Boolean value.
However, right now there's no way to signal that to the code generator,
so we introduce the \ensuremath{\textbf{pcase}} construct.

The \ensuremath{\Varid{primCond}} must be a primitive condition expression, which is either \ensuremath{\Varid{==}_{\text{prim}}} or \ensuremath{\leq _{\text{prim}}},
and the arguments must be primitive values.
The semantics of \ensuremath{\textbf{pcase}} are exactly what be expected,
but now we can translate it into a simple \texttt{if} 
statement in C, as shown in figure \ref{fig:primcond}.

\begin{figure}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{10}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\textbf{pcase}\;{}\<[10]%
\>[10]{}\Varid{primCond}\;\mathbf{of}{}\<[E]%
\\
\>[10]{}\Conid{True}\to \Varid{e}_{\Varid{t}}{}\<[E]%
\\
\>[10]{}\Conid{False}\to \Varid{e}_{\Varid{f}}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
$\ $\\
\begin{tabular}{l}
$\mathcal{B}($\ensuremath{\textbf{pcase}\;\Varid{primCond}\;\mathbf{of}\;\{\mskip1.5mu \Conid{True}\to \Varid{e}_{\Varid{t}};\Conid{False}\to \Varid{e}_{\Varid{f}}\mskip1.5mu\}}$) \coloneqq $\\
$\ \ $ \tif{$\mathcal{E}_M(primCond)$}\\
$\ \ $ \texttt{\{}\\
$\ \ \ \ \ \ $ $\mathcal{B}(e_t)$\\
$\ \ $ \texttt{\}}\\
$\ \ $ \texttt{else}\\
$\ \ $ \texttt{\{}\\
$\ \ \ \ \ \ $ $\mathcal{B}(e_f)$\\
$\ \ $ \texttt{\}}\\
\end{tabular}
\caption{The syntax and translation for \ensuremath{\Varid{primcond}}}
\label{fig:primcond}
\end{figure}

This has several advantages.
First we don't construct a node for the boolean value.
Even if we are statically allocating a single node value for \ensuremath{\Conid{True}}
and \ensuremath{\Conid{False}}, we avoid the cost of switch case loop,
and the cost of checking if \ensuremath{\Varid{primcond}} is non-deterministic.
It must be deterministic, because both of its operands are primitive values.
After implementing this construct, the new version is in figure \ref{fig:fibOpt2}.
Now we're down to 4 nodes, but we can still do better.
The next challenge is unboxing the arguments in the call to \ensuremath{\Varid{fib}}.

\begin{figure}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{17}{@{}>{\hspre}l<{\hspost}@{}}%
\column{35}{@{}>{\hspre}l<{\hspost}@{}}%
\column{42}{@{}>{\hspre}c<{\hspost}@{}}%
\column{42E}{@{}l@{}}%
\column{46}{@{}>{\hspre}l<{\hspost}@{}}%
\column{54}{@{}>{\hspre}l<{\hspost}@{}}%
\column{55}{@{}>{\hspre}l<{\hspost}@{}}%
\column{67}{@{}>{\hspre}l<{\hspost}@{}}%
\column{75}{@{}>{\hspre}l<{\hspost}@{}}%
\column{76}{@{}>{\hspre}l<{\hspost}@{}}%
\column{88}{@{}>{\hspre}l<{\hspost}@{}}%
\column{93}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{fib}\;\Varid{n}\mathrel{=}\mathbf{case}\;{}\<[17]%
\>[17]{}\Varid{n}\;\mathbf{of}{}\<[E]%
\\
\>[17]{}\Conid{Int}\;\Varid{v}_{\mathrm{2}}\to \textbf{pcase}\;{}\<[35]%
\>[35]{}\Varid{v}_{\mathrm{2}}\;\leq _{\text{prim}}\;\mathrm{1}\;{}\<[E]%
\\
\>[35]{}\Conid{True}{}\<[42]%
\>[42]{}\to {}\<[42E]%
\>[46]{}\Varid{n}{}\<[E]%
\\
\>[35]{}\Conid{False}{}\<[42]%
\>[42]{}\to {}\<[42E]%
\>[46]{}\mathbf{let}\;{}\<[54]%
\>[54]{}\Varid{n}_{\mathrm{1}}\mathrel{=}\Varid{v}_{\mathrm{2}}\;\mathbin{-}_{\text{prim}}\;\mathrm{1}{}\<[E]%
\\
\>[46]{}\mathbf{in}\;\mathbf{let}\;{}\<[54]%
\>[54]{}\Varid{f}_{\mathrm{1}}\mathrel{=}\Varid{fib}\;(\Conid{Int}\;\Varid{n}_{\mathrm{1}}){}\<[E]%
\\
\>[46]{}\mathbf{in}\;\mathbf{case}\;{}\<[55]%
\>[55]{}\Varid{f}_{\mathrm{1}}\;\mathbf{of}{}\<[E]%
\\
\>[55]{}\Conid{Int}\;\Varid{p}_{\mathrm{1}}\to {}\<[67]%
\>[67]{}\mathbf{let}\;{}\<[75]%
\>[75]{}\Varid{n}_{\mathrm{2}}\mathrel{=}\Varid{v}_{\mathrm{2}}\;\mathbin{-}_{\text{prim}}\;\mathrm{2}{}\<[E]%
\\
\>[67]{}\mathbf{in}\;\mathbf{let}\;{}\<[75]%
\>[75]{}\Varid{f}_{\mathrm{2}}\mathrel{=}\Varid{fib}\;(\Conid{Int}\;\Varid{n}_{\mathrm{2}}){}\<[E]%
\\
\>[67]{}\mathbf{in}\;\mathbf{case}\;{}\<[76]%
\>[76]{}\Varid{f}_{\mathrm{2}}\;\mathbf{of}{}\<[E]%
\\
\>[76]{}\Conid{Int}\;\Varid{p}_{\mathrm{2}}\to {}\<[88]%
\>[88]{}\mathbf{let}\;{}\<[93]%
\>[93]{}\Varid{r}\mathrel{=}\Varid{p}_{\mathrm{1}}\;\mathbin{+}_{\text{prim}}\;\Varid{p}_{\mathrm{2}}{}\<[E]%
\\
\>[88]{}\mathbf{in}\;{}\<[93]%
\>[93]{}\Conid{Int}\;\Varid{r}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\caption{The \ensuremath{\Varid{fib}} function with primitive cases}
\label{fig:fibOpt2}
\end{figure}

\subsection{Strictness Analysis}

The problems with eliminating boxes from arguments of function calls
is strongly related to the run-time system and how we represent nodes
in our expression graph.
Recall that our expression graph is made up of node structs
that point to other node structs.
If we have a \ensuremath{\Varid{fib}} node, then the argument to this node
is expected to be another node.
In C we can get around this by using a union.
We created a union \texttt{field}, defined in figure \ref{fig:field}
that can either represent an \ensuremath{\Conid{Int}}, \ensuremath{\Conid{Char}}, \ensuremath{\Conid{Float}}, \texttt{Node}, or an array of \texttt{Node*}
in case a node has more than 3 children.

\begin{figure}

\begin{tabbing}\ttfamily
~typedef~union~field\\
\ttfamily ~\char123{}\\
\ttfamily ~~~~~struct~Node\char42{}~~n\char59{}~\char47{}\char47{}normal~node~child\\
\ttfamily ~~~~~union~field\char42{}~~a\char59{}~\char47{}\char47{}array~child\\
\ttfamily ~~~~~unsigned~long~c\char59{}~\char47{}\char47{}primitive~character\\
\ttfamily ~~~~~long~~~~~~~~~~i\char59{}~\char47{}\char47{}primitive~int\\
\ttfamily ~~~~~double~~~~~~~~f\char59{}~\char47{}\char47{}primitive~float\\
\ttfamily ~\char125{}~field\char59{}
\end{tabbing}
\caption{Definition of \texttt{field} type.}
\label{fig:field}
\end{figure}

The problem with storing a primitive value in a node,
instead moves to identifying when a value is primitive.
There is no way to distinguish between 
\texttt{Node*} and \texttt{unsigned long}.
Instead of trying to figure out when a child of a node is supposed 
to represent a primitive value at run-time.  
We need to keep track of this information at compile time.
Fortunately, this is a well studied problem 
\cite{strictProj, strictAbstract, strictBack}.

Lazy functional languages often try to remove laziness for efficiency reasons.
We don't want to create an expression for a primitive value 
if we're only going to deconstruct it,
so it becomes useful to know what parameters in a function must be evaluated,
A parameter that must be evaluated by a function is called \emph{strict}\index{strict}.
Formally, a function \ensuremath{\Varid{f}} is strict in its parameter if 
\ensuremath{\Varid{f}\;\bot \mathrel{=}\bot }.

We use \ensuremath{\bot } here to mean that the value of it's parameter does not evaluate to a value,
this can come from a call to the \ensuremath{\Varid{error}} function, or
an infinite computation.
It does not mean that \ensuremath{\Varid{f}} failed to return a value.
We explicitly exclude that case, because that can change the results of some Curry programs.
For example consider the function:
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{f}\;\Varid{x}\mathrel{=}\Varid{head}\;[\mskip1.5mu \mskip1.5mu]{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
If we were to mark \ensuremath{\Varid{x}} as strict, then we may try to evaluate \ensuremath{\Varid{x}} before computing \ensuremath{\Varid{f}}.
This could cause an infinite loop in the following program:
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{loop}\mathrel{=}\Varid{loop}{}\<[E]%
\\
\>[3]{}\Varid{main}\mathrel{=}(\Varid{f}\;\Varid{loop})\mathbin{?}\mathrm{1}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
This should return a single result, and never try to evaluate \ensuremath{\Varid{loop}}.
For this reason we consider failing computations to be 
similar to expressions rooted by constructors for the purposes of strictness analysis.

We implemented an earlier form of strictness analysis described by Peyton Jones et al. \cite{haskellOpt}.
The idea is that we start by assuming every function is strict in all its parameters.
Then as we analyze a function we determine which parameters can be relaxed.
For example consider the following function:
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{19}{@{}>{\hspre}l<{\hspost}@{}}%
\column{26}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{f}\;\Varid{x}\;\Varid{y}\;\Varid{z}\mathrel{=}\mathbf{case}\;{}\<[19]%
\>[19]{}\Varid{x}\;\mathbf{of}{}\<[E]%
\\
\>[19]{}\Conid{True}{}\<[26]%
\>[26]{}\to \Varid{y}{}\<[E]%
\\
\>[19]{}\Conid{False}{}\<[26]%
\>[26]{}\to \Varid{y}\mathbin{+}\Varid{z}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
It's clear that \ensuremath{\Varid{x}} must be strict, but we don't know about \ensuremath{\Varid{y}} or \ensuremath{\Varid{z}}.
After analyzing the case branches, we see that since \ensuremath{\Varid{y}} appears in both branches,
and \ensuremath{\mathbin{+}} is strict in both of it's arguments, \ensuremath{\Varid{y}} must be strict as well.
Finally, since there's a branch that \ensuremath{\Varid{z}} doesn't appear in, \ensuremath{\Varid{z}} may not be evaluated,
so it's not strict.

This syntactic traversal of an expression is useful,
but it fails when working with a recursively defined function.
Consider the factorial function with an accumulator:
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{22}{@{}>{\hspre}l<{\hspost}@{}}%
\column{29}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{faca}\;\Varid{n}\;\Varid{acc}\mathrel{=}\mathbf{case}\;{}\<[22]%
\>[22]{}\Varid{n}\Varid{==}\mathrm{0}\;\mathbf{of}{}\<[E]%
\\
\>[22]{}\Conid{True}{}\<[29]%
\>[29]{}\to \Varid{acc}{}\<[E]%
\\
\>[22]{}\Conid{False}{}\<[29]%
\>[29]{}\to \Varid{n}\mathbin{*}\Varid{faca}\;(\Varid{n}\mathbin{-}\mathrm{1})\;(\Varid{n}\mathbin{*}\Varid{acc}){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
We can see with a syntactic check that \ensuremath{\Varid{n}} is strict, but what about \ensuremath{\Varid{acc}}.
\ensuremath{\Varid{acc}} does appear in both branches, but it's the argument to the recursive call of \ensuremath{\Varid{faca}}.
Therefore we have \ensuremath{\Varid{acc}}, the second parameter of \ensuremath{\Varid{faca}}, is strict if, and only if, the second
parameter of \ensuremath{\Varid{faca}} is strict.
We can solve this problem by iteratively running the strictness analyzer on \ensuremath{\Varid{faca}} until
it converges to a single set of strict parameters.
Formally, since a variable can be either strict or not strict,
we can represent it with a 2 element set $\{0,1\}$, and our strictness analyzer is a monotonic function, 
so we are computing a least fixed point in the strictness analyzer over the set $2^n$
where $n$ is the arity of the function.

There are much more sophisticated implementations of strictness analysis.
We do not analyze deeper than a single pattern, and we are very conservative
in regard to recursive functions.
Mycroft's original work was to interpret functions as Boolean formulas \cite{strictAbstract}.
This can find several cases of strict parameters that our implementation does not.
There has also been a lot of work on projection based strictness analysis \cite{strictProj}.
The current state of the art for Haskell is backwards projection analysis \cite{strictBack}.
Studying the validity and implementation of these strictness analyzers in regard to Curry
would all be great candidates for future work.

Once we know which arguments are strict we can split the function into a wrapper function
and a worker function \cite{strictBack}.
We can see this with \ensuremath{\Varid{fib}}.
We take the current optimized version in figure \ref{fig:fibOpt2},
and apply the worker/wrapper split in figure \ref{fig:fibOpt3}.
This creates two functions, \ensuremath{\Varid{fib}}, which simply evaluates and unboxes the parameter,
,and \ensuremath{\Varid{fib}\#\Varid{worker}}, which does the rest of the computation.
Then we optimize the function again resulting in figure \ref{fig:fibOpt4}.
Notice that since \ensuremath{\Varid{fib}} is no longer recursive we can inline it.
So we can inline the call to \ensuremath{\Varid{fib}} in the following code:
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{8}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;{}\<[8]%
\>[8]{}\Varid{f}_{\mathrm{1}}\mathrel{=}\Varid{fib}\;(\Conid{Int}\;\Varid{n}_{\mathrm{1}}){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
This results in:
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{8}{@{}>{\hspre}l<{\hspost}@{}}%
\column{17}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;{}\<[8]%
\>[8]{}\Varid{f}_{\mathrm{1}}\mathrel{=}\mathbf{case}\;(\Conid{Int}\;\Varid{n}_{\mathrm{1}})\;\mathbf{of}{}\<[E]%
\\
\>[8]{}\hsindent{9}{}\<[17]%
\>[17]{}\Conid{Int}\;\Varid{v}_{\mathrm{2}}\to \Varid{fib}\#\Varid{worker}\;\Varid{v}_{\mathrm{2}}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
Which can be optimized to:
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{8}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;{}\<[8]%
\>[8]{}\Varid{f}_{\mathrm{1}}\mathrel{=}\Varid{fib}\#\Varid{worker}\;\Varid{n}_{\mathrm{1}}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\begin{figure}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{6}{@{}>{\hspre}l<{\hspost}@{}}%
\column{13}{@{}>{\hspre}l<{\hspost}@{}}%
\column{17}{@{}>{\hspre}l<{\hspost}@{}}%
\column{31}{@{}>{\hspre}l<{\hspost}@{}}%
\column{38}{@{}>{\hspre}c<{\hspost}@{}}%
\column{38E}{@{}l@{}}%
\column{42}{@{}>{\hspre}l<{\hspost}@{}}%
\column{49}{@{}>{\hspre}l<{\hspost}@{}}%
\column{50}{@{}>{\hspre}l<{\hspost}@{}}%
\column{51}{@{}>{\hspre}l<{\hspost}@{}}%
\column{61}{@{}>{\hspre}l<{\hspost}@{}}%
\column{68}{@{}>{\hspre}l<{\hspost}@{}}%
\column{69}{@{}>{\hspre}l<{\hspost}@{}}%
\column{70}{@{}>{\hspre}l<{\hspost}@{}}%
\column{80}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{fib}\;\Varid{n}\mathrel{=}\mathbf{case}\;{}\<[17]%
\>[17]{}\Varid{n}\;\mathbf{of}{}\<[E]%
\\
\>[17]{}\Conid{Int}\;\Varid{v}_{\mathrm{2}}\to \Varid{fib}\#\Varid{worker}\;\Varid{v}_{\mathrm{2}}{}\<[E]%
\\[\blanklineskip]%
\>[3]{}\Varid{fib}\#\Varid{worker}\;\Varid{v}_{\mathrm{1}}\mathrel{=}{}\<[E]%
\\
\>[3]{}\hsindent{3}{}\<[6]%
\>[6]{}\mathbf{let}\;\Varid{n}\mathrel{=}\Conid{Int}\;\Varid{v}_{\mathrm{1}}{}\<[E]%
\\
\>[3]{}\hsindent{3}{}\<[6]%
\>[6]{}\mathbf{in}\;\mathbf{case}\;\Varid{n}\;\mathbf{of}{}\<[E]%
\\
\>[6]{}\hsindent{7}{}\<[13]%
\>[13]{}\Conid{Int}\;\Varid{v}_{\mathrm{2}}\to \textbf{pcase}\;{}\<[31]%
\>[31]{}\Varid{v}_{\mathrm{2}}\;\leq _{\text{prim}}\;\mathrm{1}\;\mathbf{of}{}\<[E]%
\\
\>[31]{}\Conid{True}{}\<[38]%
\>[38]{}\to {}\<[38E]%
\>[42]{}\Varid{n}{}\<[E]%
\\
\>[31]{}\Conid{False}{}\<[38]%
\>[38]{}\to {}\<[38E]%
\>[42]{}\mathbf{let}\;{}\<[50]%
\>[50]{}\Varid{n}_{\mathrm{1}}\mathrel{=}\Varid{v}_{\mathrm{2}}\;\mathbin{-}_{\text{prim}}\;\mathrm{1}{}\<[E]%
\\
\>[42]{}\mathbf{in}\;\mathbf{let}\;{}\<[50]%
\>[50]{}\Varid{f}_{\mathrm{1}}\mathrel{=}\Varid{fib}\;(\Conid{Int}\;\Varid{n}_{\mathrm{1}}){}\<[E]%
\\
\>[42]{}\mathbf{in}\;\mathbf{case}\;{}\<[51]%
\>[51]{}\Varid{f}_{\mathrm{1}}\;\mathbf{of}{}\<[E]%
\\
\>[42]{}\hsindent{7}{}\<[49]%
\>[49]{}\Conid{Int}\;\Varid{p}_{\mathrm{1}}\to {}\<[61]%
\>[61]{}\mathbf{let}\;{}\<[69]%
\>[69]{}\Varid{n}_{\mathrm{2}}\mathrel{=}\Varid{v}_{\mathrm{2}}\;\mathbin{-}_{\text{prim}}\;\mathrm{2}{}\<[E]%
\\
\>[61]{}\mathbf{in}\;\mathbf{let}\;{}\<[69]%
\>[69]{}\Varid{f}_{\mathrm{2}}\mathrel{=}\Varid{fib}\;(\Conid{Int}\;\Varid{n}_{\mathrm{2}}){}\<[E]%
\\
\>[61]{}\mathbf{in}\;\mathbf{case}\;{}\<[70]%
\>[70]{}\Varid{f}_{\mathrm{2}}\;\mathbf{of}{}\<[E]%
\\
\>[61]{}\hsindent{7}{}\<[68]%
\>[68]{}\Conid{Int}\;\Varid{p}_{\mathrm{2}}\to {}\<[80]%
\>[80]{}\mathbf{let}\;\Varid{r}\mathrel{=}\Varid{p}_{\mathrm{1}}\;\mathbin{+}_{\text{prim}}\;\Varid{p}_{\mathrm{2}}{}\<[E]%
\\
\>[80]{}\mathbf{in}\;\Conid{Int}\;\Varid{r}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\caption{The \ensuremath{\Varid{fib}} function after strictness analysis.}
\label{fig:fibOpt3}
\end{figure}

\begin{figure}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{5}{@{}>{\hspre}l<{\hspost}@{}}%
\column{12}{@{}>{\hspre}l<{\hspost}@{}}%
\column{18}{@{}>{\hspre}c<{\hspost}@{}}%
\column{18E}{@{}l@{}}%
\column{22}{@{}>{\hspre}l<{\hspost}@{}}%
\column{31}{@{}>{\hspre}l<{\hspost}@{}}%
\column{43}{@{}>{\hspre}l<{\hspost}@{}}%
\column{52}{@{}>{\hspre}l<{\hspost}@{}}%
\column{64}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{fib}\#\Varid{worker}\;\Varid{v}_{\mathrm{2}}\mathrel{=}{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\textbf{pcase}\;{}\<[12]%
\>[12]{}\Varid{v}_{\mathrm{2}}\;\leq _{\text{prim}}\;\mathrm{1}\;\mathbf{of}{}\<[E]%
\\
\>[12]{}\Conid{True}{}\<[18]%
\>[18]{}\to {}\<[18E]%
\>[22]{}\Conid{Int}\;\Varid{v}_{\mathrm{2}}{}\<[E]%
\\
\>[12]{}\Conid{False}\to {}\<[22]%
\>[22]{}\mathbf{let}\;\Varid{n}_{\mathrm{1}}\mathrel{=}\Varid{v}_{\mathrm{2}}\;\mathbin{-}_{\text{prim}}\;\mathrm{1}{}\<[E]%
\\
\>[22]{}\mathbf{in}\;\mathbf{let}\;\Varid{f}_{\mathrm{1}}\mathrel{=}\Varid{fib}\#\Varid{worker}\;\Varid{n}_{\mathrm{1}}{}\<[E]%
\\
\>[22]{}\mathbf{in}\;\mathbf{case}\;{}\<[31]%
\>[31]{}\Varid{f}_{\mathrm{1}}\;\mathbf{of}{}\<[E]%
\\
\>[31]{}\Conid{Int}\;\Varid{p}_{\mathrm{1}}\to {}\<[43]%
\>[43]{}\mathbf{let}\;\Varid{n}_{\mathrm{2}}\mathrel{=}\Varid{v}_{\mathrm{2}}\;\mathbin{-}_{\text{prim}}\;\mathrm{2}{}\<[E]%
\\
\>[43]{}\mathbf{in}\;\mathbf{let}\;\Varid{f}_{\mathrm{2}}\mathrel{=}\Varid{fib}\#\Varid{worker}\;\Varid{n}_{\mathrm{2}}{}\<[E]%
\\
\>[43]{}\mathbf{in}\;\mathbf{case}\;{}\<[52]%
\>[52]{}\Varid{f}_{\mathrm{2}}\;\mathbf{of}{}\<[E]%
\\
\>[52]{}\Conid{Int}\;\Varid{p}_{\mathrm{2}}\to {}\<[64]%
\>[64]{}\mathbf{let}\;\Varid{r}\mathrel{=}\Varid{p}_{\mathrm{1}}\;\mathbin{+}_{\text{prim}}\;\Varid{p}_{\mathrm{2}}{}\<[E]%
\\
\>[64]{}\mathbf{in}\;\Conid{Int}\;\Varid{r}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\caption{The \ensuremath{\Varid{fib}} function after strictness analysis and optimization.}
\label{fig:fibOpt4}
\end{figure}

We're down to allocating 2 nodes.
We only need to allocate nodes for the calls to \ensuremath{\Varid{fib}\#\Varid{worker}}.
This means that we've reduced our memory consumption by 60\%.
That's a huge improvement, but we can still do better.
With the next optimization we look at how to remove the remaining allocations.

\section{Shortcutting}

In the last section were able to optimize the \ensuremath{\Varid{fib}} function from allocating 
5 nodes per recursive call to only allocating 2 nodes per recursive call.
However, we were left with a problem that we can't solve by a code transformation.
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{12}{@{}>{\hspre}l<{\hspost}@{}}%
\column{24}{@{}>{\hspre}c<{\hspost}@{}}%
\column{24E}{@{}l@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;\Varid{f}_{\mathrm{1}}\mathrel{=}\Varid{fib}\#\Varid{worker}\;\Varid{n}_{\mathrm{1}}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\mathbf{case}\;{}\<[12]%
\>[12]{}\Varid{f}_{\mathrm{1}}\;\mathbf{of}{}\<[E]%
\\
\>[12]{}\Conid{Int}\;\Varid{p}_{\mathrm{1}}\to {}\<[24]%
\>[24]{}\ldots {}\<[24E]%
\ColumnHook
\end{hscode}\resethooks
In this section we aim to eliminate these final two nodes.
However, in order to do this, we'll have to step outside of compile-time optimizations,
and look into previous work on run-time optimizations for Curry.
Specifically we are going to use an idea inspired by the shortcutting optimizations \cite{shortcutting}.
We first look into the shortcutting optimization itself,
then we show how a couple of ideas from it can be applied to our compiler.
However, the analogy will be a bit imprecise, 
since shortcutting was developed for Graph Rewrite Systems.

\subsection{The Original Shortcutting Optimizations}

Initially shortcutting was developed for Inductively Sequential Graph Rewrite Systems \cite{shortcutting}.
However, the application to functional logic languages was clearly in mind,
and the ideas were even implemented, and shown to be effective in the Packs compiler.

We begin with a set of rewrite rules $R$, for an Inductively Sequential system,
and define a \texttt{compile} function to translate the rules into
a rewrite system that simulates
an innermost rewriting system by adding two new rules \textbf{H} and \textbf{N}.
These rules are roughly analogous to our \texttt{hnf} and \texttt{nf} functions
from chapter \ref{ch:The Generated Code}.
The \textbf{H} function computes an expression to head constructor form,
and the \textbf{N} function computes an expression to constructor normal form
by repeatedly calling the \textbf{H} function.
We will focus on the \textbf{H} function itself, since that is where the optimization occurs.

To translate $R$ to a new rewritings system that simulates
an innermost strategy, we traverse the definitional tree in post-order,
and emit rules as we reach the leaves of the tree.
We gloss over the details here, but an example of the \textbf{H} function for the curry function \ensuremath{\plus } and \ensuremath{\Varid{length}}
are shown in figure \ref{fig:H}.
Our transformed code is actually very similar to what the compiler already does.
We generate a new \textbf{H} function for every function symbol.
For example, $\textbf{H}_{length}$ computes the length of a list to head constructor form.
This corresponds to the $O_R$ code described in the original paper.
When looking at the $\textbf{H}_{length}$ function, we notice something interesting.
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\textbf{H}_{length}(\Varid{x}\mathbin{:}\Varid{xs}) \mathrel{=}\textbf{H}_{+}(\mathrm{1},\textbf{H}_{length}(\Varid{xs}) ) {}\<[E]%
\ColumnHook
\end{hscode}\resethooks
We don't actually construct a node for $+$ or \ensuremath{\Varid{length}\;\Varid{xs}}.
Even with our current implementation, and unboxing strategy, we'd still have to construct
a node for \ensuremath{\Varid{length}\;\Varid{xs}} in order to evaluate it.
It's recursive, so we couldn't inline the call to length, and it's possible that
it could be non-deterministic.
The shortcutting compiler has managed to avoid constructing a node that our compiler has to construct.
This is worth looking into.


\begin{figure}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{18}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}[\mskip1.5mu \mskip1.5mu]\plus \Varid{ys}{}\<[18]%
\>[18]{}\mathrel{=}\Varid{ys}{}\<[E]%
\\
\>[3]{}(\Varid{x}\mathbin{:}\Varid{xs})\plus \Varid{ys}{}\<[18]%
\>[18]{}\mathrel{=}\Varid{x}\mathbin{:}(\Varid{xs}\plus \Varid{ys}){}\<[E]%
\\
\>[3]{}\Varid{length}\;[\mskip1.5mu \mskip1.5mu]{}\<[18]%
\>[18]{}\mathrel{=}\mathrm{0}{}\<[E]%
\\
\>[3]{}\Varid{length}\;(\Varid{x}\mathbin{:}\Varid{xs}){}\<[18]%
\>[18]{}\mathrel{=}\mathrm{1}\mathbin{+}\Varid{length}\;\Varid{xs}{}\<[E]%
\\
\>[3]{}\ {}\<[E]%
\\
\>[3]{}\textbf{H}([\mskip1.5mu \mskip1.5mu]\plus [\mskip1.5mu \mskip1.5mu]) \mathrel{=}[\mskip1.5mu \mskip1.5mu]{}\<[E]%
\\
\>[3]{}\textbf{H}([\mskip1.5mu \mskip1.5mu]\plus (\Varid{y}\mathbin{:}\Varid{ys})) \mathrel{=}\Varid{y}\mathbin{:}\Varid{ys}{}\<[E]%
\\
\>[3]{}\textbf{H}([\mskip1.5mu \mskip1.5mu]\plus \Varid{y}) \mathrel{=}\textbf{H}(\Varid{y}) {}\<[E]%
\\
\>[3]{}\textbf{H}((\Varid{x}\mathbin{:}\Varid{xs})\plus \Varid{ys}) \mathrel{=}\Varid{x}\mathbin{:}\textbf{H}(\Varid{xs}\plus \Varid{ys}) {}\<[E]%
\\
\>[3]{}\textbf{H}(\Varid{xs}\plus \Varid{ys}) \mathrel{=}\textbf{H}(\textbf{H}(\Varid{xs}) \plus \Varid{ys}) {}\<[E]%
\\
\>[3]{}\textbf{H}(\Varid{length}\;[\mskip1.5mu \mskip1.5mu]) \mathrel{=}\mathrm{0}{}\<[E]%
\\
\>[3]{}\textbf{H}(\Varid{length}\;(\Varid{x}\mathbin{:}\Varid{xs})) \mathrel{=}\textbf{H}(\mathrm{1}\mathbin{+}\Varid{length}\;\Varid{xs}) {}\<[E]%
\\
\>[3]{}\textbf{H}(\Varid{length}\;\Varid{xs}) \mathrel{=}\textbf{H}(\Varid{length}\;\textbf{H}(\Varid{xs}) ) {}\<[E]%
\\
\>[3]{}\ {}\<[E]%
\\
\>[3]{}\textbf{H}_{\plus }([\mskip1.5mu \mskip1.5mu],[\mskip1.5mu \mskip1.5mu]) \mathrel{=}[\mskip1.5mu \mskip1.5mu]{}\<[E]%
\\
\>[3]{}\textbf{H}_{\plus }([\mskip1.5mu \mskip1.5mu],(\Varid{y}\mathbin{:}\Varid{ys})) \mathrel{=}\Varid{y}\mathbin{:}\Varid{ys}{}\<[E]%
\\
\>[3]{}\textbf{H}_{\plus }([\mskip1.5mu \mskip1.5mu],(\Varid{us}\plus \Varid{vs})) \mathrel{=}\textbf{H}_{\plus }(\Varid{us},\Varid{vs}) {}\<[E]%
\\
\>[3]{}\textbf{H}_{\plus }((\Varid{x}\mathbin{:}\Varid{xs}),\Varid{ys}) \mathrel{=}\Varid{x}\mathbin{:}\textbf{H}_{\plus }(\Varid{xs},\Varid{ys}) {}\<[E]%
\\
\>[3]{}\textbf{H}_{length}([\mskip1.5mu \mskip1.5mu]) \mathrel{=}\mathrm{0}{}\<[E]%
\\
\>[3]{}\textbf{H}_{length}(\Varid{x}\mathbin{:}\Varid{xs}) \mathrel{=}\textbf{H}_{+}(\mathrm{1},\textbf{H}_{length}(\Varid{xs}) ) {}\<[E]%
\\
\>[3]{}\textbf{H}_{length}(\Varid{xs}\plus \Varid{ys}) \mathrel{=}\textbf{H}_{length}(\textbf{H}_{\plus }(\Varid{xs},\Varid{ys}) ) {}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\caption{The \textbf{H} function, and associated transformed functions for \ensuremath{\plus } and \ensuremath{\Varid{length}}.}
\label{fig:H}
\end{figure}

In keeping with our example,
let's see what the shortcutting compiler produces with our \ensuremath{\Varid{fib}} example.
We have restructured the example as rewrite rules, but it's still performing the same computation.
The results are shown in figure \ref{fig:Hfib}.
As we can see, we can avoid constructing nodes for \ensuremath{\leq }, \ensuremath{\mathbin{+}} and \ensuremath{\mathbin{-}},
but we already managed to avoid these node constructions with unboxing and inlining.
The more interesting point here is that we can avoid the construction of the recursive call to \ensuremath{\Varid{fib}}.
So, how do we avoid constructing these nodes?
There are two key pieces of information that will help us here.
First, the node labeled by \ensuremath{\Varid{fib}} is not the root of the right hand side.
Second, the node is needed in that expression.
If both of these conditions are met, then we do not need to construct the node.
We can \emph{shortcut} the construction, and just compute the value.

\begin{figure}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{18}{@{}>{\hspre}l<{\hspost}@{}}%
\column{21}{@{}>{\hspre}l<{\hspost}@{}}%
\column{30}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{fib}\;\Varid{n}{}\<[21]%
\>[21]{}\mathrel{=}\Varid{fibComp}\;(\Varid{n}\mathbin{<}\mathrm{2})\;\Varid{n}{}\<[E]%
\\[\blanklineskip]%
\>[3]{}\Varid{fibComp}\;\Conid{True}\;{}\<[18]%
\>[18]{}\Varid{n}{}\<[21]%
\>[21]{}\mathrel{=}\Varid{n}{}\<[E]%
\\
\>[3]{}\Varid{fibComp}\;\Conid{False}\;{}\<[18]%
\>[18]{}\Varid{n}{}\<[21]%
\>[21]{}\mathrel{=}\Varid{fib}\;(\Varid{n}\mathbin{-}\mathrm{1})\mathbin{+}\Varid{fib}\;(\Varid{n}\mathbin{-}\mathrm{2}){}\<[E]%
\\[\blanklineskip]%
\>[3]{}\ {}\<[E]%
\\
\>[3]{}\textbf{H}(\Varid{fib}\;\Varid{n}) {}\<[30]%
\>[30]{}\mathrel{=}\textbf{H}(\Varid{fibComp}\;(\Varid{n}\leq \mathrm{2})\;\Varid{n}) {}\<[E]%
\\
\>[3]{}\textbf{H}(\Varid{fibComp}\;\Conid{True}\;(\Conid{Int}\;\Varid{n}_{\text{prim}})) {}\<[30]%
\>[30]{}\mathrel{=}\Conid{Int}\;\Varid{n}_{\text{prim}}{}\<[E]%
\\
\>[3]{}\textbf{H}(\Varid{fibComp}\;\Conid{True}\;\Varid{n}) {}\<[30]%
\>[30]{}\mathrel{=}\textbf{H}(\Varid{n}) {}\<[E]%
\\
\>[3]{}\textbf{H}(\Varid{fibComp}\;\Conid{False}\;\Varid{n}) {}\<[30]%
\>[30]{}\mathrel{=}\textbf{H}(\Varid{fib}\;(\Varid{n}\mathbin{-}\mathrm{1})\mathbin{+}\Varid{fib}\;(\Varid{n}\mathbin{-}\mathrm{2})) {}\<[E]%
\\[\blanklineskip]%
\>[3]{}\ {}\<[E]%
\\
\>[3]{}\textbf{H}_{fib}(\Varid{n}) {}\<[30]%
\>[30]{}\mathrel{=}\textbf{H}_{fibComp}(\textbf{H}_{\leq }(\Varid{n},\mathrm{2}) ,\Varid{n}) {}\<[E]%
\\
\>[3]{}\textbf{H}_{fibComp}(\Conid{True},(\Conid{Int}\;\Varid{n}_{\text{prim}})) {}\<[30]%
\>[30]{}\mathrel{=}\Conid{Int}\;\Varid{n}_{\text{prim}}{}\<[E]%
\\
\>[3]{}\textbf{H}_{fibComp}(\Conid{True},(\Varid{x}\mathbin{+}\Varid{y})) {}\<[30]%
\>[30]{}\mathrel{=}\textbf{H}_{+}(\Varid{x},\Varid{y}) {}\<[E]%
\\
\>[3]{}\textbf{H}_{fibComp}(\Conid{True},(\Varid{x}\mathbin{-}\Varid{y})) {}\<[30]%
\>[30]{}\mathrel{=}\textbf{H}_{-}(\Varid{x},\Varid{y}) {}\<[E]%
\\
\>[3]{}\textbf{H}_{fibComp}(\Conid{True},(\Varid{fib}\;\Varid{n})) {}\<[30]%
\>[30]{}\mathrel{=}\textbf{H}_{fib}(\Varid{n}) {}\<[E]%
\\
\>[3]{}\textbf{H}_{fibComp}(\Conid{False},\Varid{n}) {}\<[30]%
\>[30]{}\mathrel{=}\textbf{H}_{+}(\textbf{H}_{fib}(\textbf{H}_{-}(\Varid{n},\mathrm{1}) ) ,\textbf{H}_{fib}(\textbf{H}_{-}(\Varid{n},\mathrm{2}) ) ) {}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\caption{The \textbf{H} function, and associated transformed functions for \ensuremath{\Varid{fib}}.}
\label{fig:Hfib}
\end{figure}

Now that we have a theoretical idea of how to eliminate nodes with shortcutting,
we need to apply it to our actual generated code.
By our two conditions, we're looking for a node that's generated by the right hand side of a rewrite rule,
and we're looking for a node that's needed in that expression.
The equivalent in our compiled code is when a let bound variable is rooted by a function,
and is used exactly once as the scrutinee of a case expression.
In the Fibonacci example in figure \ref{fig:fibOpt4}
both $f_1$ and $f_2$ meet these conditions.
Typically a compiler for a lazy language would recognize this situation,
and instead of generating a node only to evaluate it, the compiler would produce a function call
that would return the value of that node.

It is worth looking at an attempt to try to replace the node with a function call.
One possibility would be to try to statically analyze a function \ensuremath{\Varid{f}} and determine if it's deterministic.
This is a reasonable idea, but it has two major drawbacks.
First, determining if a function is non-deterministic is undecidable,
so the best we could do is an approximation.
Second, even if \ensuremath{\Varid{f}} is deterministic, the expression \ensuremath{\Varid{f}\;\Varid{x}}
could still be non-deterministic if \ensuremath{\Varid{x}} is.
This is going to be very restrictive for any possible optimization.

In the example in figure \ref{fig:fibOpt4} we need a node to hold the value for \ensuremath{\Varid{fib}\#\Varid{worker}\;\Varid{n}_{\mathrm{1}}},
but this value will only be used in the case expression.
In fact, it's not possible for this node to be shared with any part of the expression graph.
If this expression is only ever scrutinized by the case expression,
then we only need to keep the value around temporarily.
The idea here is simple, but the implementation becomes tricky.
We want to use a single, statically allocated, node for every variable
that's only used as the scrutinee of a case.

There are two steps to the optimization.
The first step is marking every node that's only used as the scrutinee.
The second step happens during code generation.
Instead of dynamically allocating memory for a marked node,
we store all of the information in a single, statically allocated, node.
We call this node \texttt{RET} for return.

This effectively removes the rest of the dynamically allocated nodes from our \ensuremath{\Varid{fib}}
function, but before we celebrate, we need to make sure that 
code generated using this transformation actually produces the same results.
There are a few things the can potentially go wrong.

First, let's look at the case where the scrutinee is deterministic.
In that case, there is only one thing that could go wrong.
It's possible that in order to reduce the scrutinee 
we need to reduce another expression that could be stored in \texttt{RET}.
For example, consider the following program:
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{15}{@{}>{\hspre}l<{\hspost}@{}}%
\column{16}{@{}>{\hspre}l<{\hspost}@{}}%
\column{22}{@{}>{\hspre}l<{\hspost}@{}}%
\column{23}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{f}\;\Varid{x}\mathrel{=}\mathbf{case}\;{}\<[15]%
\>[15]{}\Varid{g}\;\Varid{x}\;\mathbf{of}{}\<[E]%
\\
\>[15]{}\Conid{True}{}\<[22]%
\>[22]{}\to \Conid{False}{}\<[E]%
\\
\>[15]{}\Conid{False}{}\<[22]%
\>[22]{}\to \Conid{True}{}\<[E]%
\\[\blanklineskip]%
\>[3]{}\Varid{main}\mathrel{=}\mathbf{case}\;{}\<[16]%
\>[16]{}\Varid{f}\;\mathrm{3}\;\mathbf{of}{}\<[E]%
\\
\>[16]{}\Conid{True}{}\<[23]%
\>[23]{}\to \mathrm{0}{}\<[E]%
\\
\>[16]{}\Conid{False}{}\<[23]%
\>[23]{}\to \mathrm{1}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
In the evaluation of \ensuremath{\Varid{main}}, \ensuremath{\Varid{f}\;\mathrm{3}} can be stored in the \texttt{RET} node,
then we can evaluate \ensuremath{\Varid{f}\;\mathrm{3}} to head constructor form,
but while we are evaluating \ensuremath{\Varid{f}\;\mathrm{3}}, we store \ensuremath{\Varid{g}\;\mathrm{3}} in the same \texttt{RET} node.
While this is concerning, it's not actually a problem.
As shown in chapter \ref{ch:The Generated Code}, 
at the beginning of \texttt{f\_hnf}, 
we store all of the children of \texttt{root} as local variables, 
and then when we've computed the value, we overwrite the \texttt{root} node.
In our case the \texttt{root} node in our function is \texttt{RET}.
However, aside from the very start and end of the function, 
we never interact with the \texttt{root} node,
so even if we reuse \texttt{RET} in the middle of evaluating \ensuremath{\Varid{f}}, it doesn't actually
affect the results.

A portion of the generated code for \ensuremath{\Varid{f}} can be seen in figure \ref{fig:gen_f}.
As we can see, the only time that we use the \texttt{root} node 
is at the very start of the function to store the variables,
and right before we return.
Even if \texttt{root} happens to be \texttt{RET},
this doesn't actually affect the evaluation.
The \texttt{RET} node is overwritten with the contents of \ensuremath{\Varid{g}\;\Varid{x}},
then it's evaluated, and finally it's overwritten with the result of \ensuremath{\Varid{f}} right before returning.

\begin{figure}
\begin{tabbing}\ttfamily
~void~f\char95{}hnf\char40{}Node\char42{}~root\char41{}\\
\ttfamily ~\char123{}\\
\ttfamily ~~~field~x~\char61{}~root\char45{}\char62{}children\char91{}0\char93{}\char59{}\\
\ttfamily ~~~set\char95{}g\char40{}RET\char44{}~make\char95{}int\char40{}3\char41{}\char41{}\char59{}\\
\ttfamily ~~~field~scrutenee~\char61{}~RET\char59{}\\
\ttfamily ~~~bool~nondet~\char61{}~false\char59{}\\
\ttfamily ~~~while\char40{}true\char41{}\\
\ttfamily ~~~\char123{}\\
\ttfamily ~~~~~nondet~\char124{}\char61{}~scrutenee\char46{}n\char45{}\char62{}nondet\char59{}\\
\ttfamily ~~~~~switch\char40{}TAG\char40{}scrutenee\char41{}\char41{}\\
\ttfamily ~~~~~\char123{}\\
\ttfamily ~~~~~~~\char46{}\char46{}\char46{}\\
\ttfamily ~~~~~~~case~True\char58{}\\
\ttfamily ~~~~~~~~~if\char40{}nondet\char41{}~push\char95{}frame\char40{}root\char44{}~make\char95{}Prelude\char95{}f\char95{}1\char40{}x\char41{}\char41{}\char59{}\\
\ttfamily ~~~~~~~~~set\char95{}Prelude\char95{}False\char40{}root\char44{}~0\char41{}\char59{}\\
\ttfamily ~~~~~~~~~return\char59{}\\
\ttfamily ~~~~~\char125{}\\
\ttfamily ~~~\char125{}\\
\ttfamily ~\char125{}
\end{tabbing}
\caption{Part of the generated code for \ensuremath{\Varid{f}}.}
\label{fig:gen_f}
\end{figure}

It seems like we should be able to 
store these marked variables in the \texttt{RET} node, and then 
just call the appropriate \texttt{\_hnf} function.
In fact this was the first idea we tried.
The generated code for main is given in figure \ref{fig:RET1}.

\begin{figure}
\begin{tabbing}\ttfamily
~void~main\char95{}hnf\char40{}Node\char42{}~root\char41{}\\
\ttfamily ~\char123{}\\
\ttfamily ~~~~~set\char95{}f\char40{}RET\char44{}~make\char95{}int\char40{}3\char41{}\char41{}\char59{}\\
\ttfamily ~~~~~field~scrutenee~\char61{}~RET\char59{}\\
\ttfamily ~~~~~bool~nondet~\char61{}~false\char59{}\\
\ttfamily ~~~~~while\char40{}true\char41{}\\
\ttfamily ~~~~~\char123{}\\
\ttfamily ~~~~~~~~~nondet~\char124{}\char61{}~scrutenee\char46{}n\char45{}\char62{}nondet\char59{}\\
\ttfamily ~~~~~~~~~switch\char40{}TAG\char40{}scrutenee\char41{}\char41{}\\
\ttfamily ~~~~~~~~~\char123{}\\
\ttfamily ~~~~~~~~~~~~~\char46{}\char46{}\char46{}\\
\ttfamily ~~~~~~~~~~~~~case~True\char58{}\\
\ttfamily ~~~~~~~~~~~~~~~~~if\char40{}nondet\char41{}~\char46{}\char46{}\char46{}\\
\ttfamily ~~~~~~~~~~~~~~~~~set\char95{}int\char40{}root\char44{}~0\char41{}\char59{}\\
\ttfamily ~~~~~~~~~~~~~~~~~return\char59{}\\
\ttfamily ~~~~~~~~~~~~~\char46{}\char46{}\char46{}\\
\ttfamily ~~~~~~~~~\char125{}\\
\ttfamily ~~~~~\char125{}
\end{tabbing}
\caption{First attempt at compiling \ensuremath{\Varid{main}} with Shortcutting.}
\label{fig:RET1}
\end{figure}

This initial version actually works very well.
In fact, for \ensuremath{\Varid{fib}\#\Varid{worker}} we're able to remove the remaining 2 allocations.
This is fantastic, and we'll come back to this point later,
but before we celebrate, we need to deal with a looming problem.

\subsection{Non-deterministic RET Nodes}

The problem with the scheme we've developed so far is that
if \texttt{RET} is non-deterministic, 
then the rewrite rule we push on the backtracking stack may
contain a pointer to \texttt{RET}.
This is a major problem with this optimization,
because \texttt{RET} will almost certainly have been reused
by the time backtracking occurs.

This optimization was built on the idea that \texttt{RET}
is only ever used in a single case expression.
Therefore, it's important that we never put \texttt{RET} on the backtracking stack.
We need rethink on our idea.
Initially, we wanted to avoid allocating a node if a variable is used in a single case.
Instead, we will only allocate a node if \texttt{RET} is non-deterministic.
This means that for deterministic expression, we don't allocate any memory,
but for non-deterministic expression, we still have a persistent variable on the stack.
This lead to the second implementation in figure \ref{fig:RET2}.

\begin{figure}
\begin{tabbing}\ttfamily
~void~main\char95{}hnf\char40{}Node\char42{}~root\char41{}\\
\ttfamily ~\char123{}\\
\ttfamily ~~~~~set\char95{}f\char40{}RET\char44{}~make\char95{}int\char40{}3\char41{}\char41{}\char59{}\\
\ttfamily ~~~~~field~scrutinee~\char61{}~RET\char59{}\\
\ttfamily ~~~~~bool~nondet~\char61{}~false\char59{}\\
\ttfamily ~~~~~while\char40{}true\char41{}\\
\ttfamily ~~~~~\char123{}\\
\ttfamily ~~~~~~~~~nondet~\char124{}\char61{}~scrutinee\char46{}n\char45{}\char62{}nondet\char59{}\\
\ttfamily ~~~~~~~~~switch\char40{}scrutenee\char46{}n\char45{}\char62{}tag\char41{}\\
\ttfamily ~~~~~~~~~\char123{}\\
\ttfamily ~~~~~~~~~~~~~\char46{}\char46{}\char46{}\\
\ttfamily ~~~~~~~~~~~~~case~True\char58{}\\
\ttfamily ~~~~~~~~~~~~~~~~~if\char40{}nondet\char41{}\\
\ttfamily ~~~~~~~~~~~~~~~~~\char123{}\\
\ttfamily ~~~~~~~~~~~~~~~~~~~~~Node\char42{}~backup~\char61{}~copy\char40{}RET\char41{}\char59{}\\
\ttfamily ~~~~~~~~~~~~~~~~~~~~~stack\char95{}push\char40{}bt\char95{}stack\char44{}~root\char44{}~main\char95{}1\char40{}backup\char41{}\char41{}\char59{}\\
\ttfamily ~~~~~~~~~~~~~~~~~\char125{}\\
\ttfamily ~~~~~~~~~~~~~~~~~set\char95{}int\char40{}root\char44{}~0\char41{}\char59{}\\
\ttfamily ~~~~~~~~~~~~~~~~~return\char59{}\\
\ttfamily ~~~~~~~~~~~~~~~~~\char46{}\char46{}\char46{}\\
\ttfamily ~~~~~~~~~\char125{}\\
\ttfamily ~~~~~\char125{}
\end{tabbing}
\caption{Second attempt at compiling \ensuremath{\Varid{main}} with Shortcutting.}
\label{fig:RET2}
\end{figure}

\subsection{RET hnf Functions}

This solution is better, because any rewrites we push onto the stack
contain a copy of \texttt{RET}, but it's still not correct.
Three things can still go wrong here.
These are very subtle errors that are very easy to overlook,
and even harder to track down the real cause of the errors.

The first problem is that \texttt{RET} might have been reduced to a
forwarding node, so it might be deterministic, but forward to a non-deterministic node.
For example, in \ensuremath{\mathbf{case}\;\Varid{id}\;(\mathrm{0}\mathbin{?}\mathrm{1})\;\mathbf{of}\ldots }
there's clearly non-determinism,
but the \ensuremath{\Varid{id}} node isn't the cause of it, 
so that rewrite shouldn't be pushed on the backtracking stack.

Another problem is that, if \texttt{RET} is a forwarding node,
when evaluating the node it forwards to, we might have reused \texttt{RET}.
Consider the following program.
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{15}{@{}>{\hspre}l<{\hspost}@{}}%
\column{16}{@{}>{\hspre}l<{\hspost}@{}}%
\column{22}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{h}\;\Varid{x}\mathrel{=}\mathbf{case}\;{}\<[15]%
\>[15]{}\Varid{x}\mathbin{>}\mathrm{3}\;\mathbf{of}{}\<[E]%
\\
\>[15]{}\Conid{False}{}\<[22]%
\>[22]{}\to \mathrm{3}{}\<[E]%
\\
\>[15]{}\Conid{True}{}\<[22]%
\>[22]{}\to \mathrm{4}{}\<[E]%
\\
\>[3]{}\Varid{main}\mathrel{=}\mathbf{case}\;{}\<[16]%
\>[16]{}(\Varid{h}\;\mathrm{4}\mathbin{?}\Varid{h}\;\mathrm{2})\;\mathbf{of}{}\<[E]%
\\
\>[16]{}\mathrm{4}\to \Conid{True}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
Here \ensuremath{\Varid{main}} evaluates \ensuremath{\Varid{h}\;\mathrm{4}\mathbin{?}\Varid{h}\;\mathrm{2}}.
Since \ensuremath{\mathbin{?}} is non-deterministic, and reduces to a forwarding node,
we need to make a copy of \texttt{RET} 
as part of the rewrite we push on the backtracking stack.
However, before we can even do that, we need to evaluate \ensuremath{\Varid{h}\;\mathrm{4}},
and the expression \ensuremath{\Varid{x}\mathbin{>}\mathrm{3}} will be stored in \texttt{RET}.
Now we've lost the information in \texttt{RET} before we can copy it.

Finally, we still haven't avoided putting \texttt{RET} on the backtracking stack.
Recall our program from before.
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{15}{@{}>{\hspre}l<{\hspost}@{}}%
\column{16}{@{}>{\hspre}l<{\hspost}@{}}%
\column{22}{@{}>{\hspre}l<{\hspost}@{}}%
\column{23}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{f}\;\Varid{x}\mathrel{=}\mathbf{case}\;{}\<[15]%
\>[15]{}\Varid{g}\;\Varid{x}\;\mathbf{of}{}\<[E]%
\\
\>[15]{}\Conid{True}{}\<[22]%
\>[22]{}\to \Conid{False}{}\<[E]%
\\
\>[15]{}\Conid{False}{}\<[22]%
\>[22]{}\to \Conid{True}{}\<[E]%
\\[\blanklineskip]%
\>[3]{}\Varid{main}\mathrel{=}\mathbf{case}\;{}\<[16]%
\>[16]{}\Varid{f}\;\mathrm{3}\;\mathbf{of}{}\<[E]%
\\
\>[16]{}\Conid{True}{}\<[23]%
\>[23]{}\to \mathrm{0}{}\<[E]%
\\
\>[16]{}\Conid{False}{}\<[23]%
\>[23]{}\to \mathrm{1}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
If the expression \ensuremath{\Varid{g}\;\Varid{x}} is non-deterministic, 
then the node containing \ensuremath{\Varid{f}} will be marked as non-deterministic.
However, \ensuremath{\Varid{f}\;\mathrm{3}} was stored in the \texttt{RET} node,
so the \texttt{root} parameter will be \texttt{RET}.
Now \texttt{RET} is still pushed on the backtracking stack,
but this time it's on the left hand side of the rewrite.

This is starting to seem hopeless,
when we fix one problem, 3 much more subtle problems pop up.
How can we avoid creating nodes for deterministic expressions,
but still only create a single node that the 
caller and callee agree on if the expression is non-deterministic?

The answer is that we need to change how \texttt{RET} nodes are reduced.
Specifically, we create a new reduction function that only handles nodes stored in \texttt{RET}.
In the case of \ensuremath{\Varid{f}}, we would create a 
\texttt{f\_hnf}, a \texttt{f\_1\_hnf} and a \texttt{f\_RET\_hnf}.
The third function only reduces \ensuremath{\Varid{f}} that has been stored in a \texttt{RET} node.

The difference between \texttt{f\_hnf} and \texttt{f\_RET\_hnf} is that
instead of passing the root node, we pass \texttt{Node* backup}.
The \texttt{backup} node is where we'll store the contents of \texttt{RET}
if we discover evaluating the expression rooted by \ensuremath{\Varid{f}} is non-deterministic.
Finally we return \texttt{backup}.
Now both the caller and callee agree on \texttt{backup}.
Furthermore, since \texttt{backup} is a local variable,
it's not affected if \ensuremath{\Varid{f}} reuses \texttt{RET} over the course of its evaluation.
We can see the final implementation of shortcutting for \ensuremath{\Varid{main}} in figure \ref{fig:RET3}.
We also give the definition for \texttt{f\_RET\_hnf} in figure \ref{fig:RET_f}.

\begin{figure}
\begin{tabbing}\ttfamily
~void~main\char95{}hnf\char40{}Node\char42{}~root\char41{}\\
\ttfamily ~\char123{}\\
\ttfamily ~~~~~set\char95{}f\char40{}RET\char44{}~make\char95{}int\char40{}3\char41{}\char41{}\char59{}\\
\ttfamily ~~~~~field~scrutinee~\char61{}~RET\char59{}\\
\ttfamily ~~~~~Node\char42{}~f\char95{}backup~\char61{}~f\char95{}RET\char95{}hnf\char40{}NULL\char41{}\char59{}\\
\ttfamily ~~~~~bool~nondet~\char61{}~false\char59{}\\
\ttfamily ~~~~~if\char40{}f\char95{}backup~\char33{}\char61{}~NULL\char41{}\\
\ttfamily ~~~~~\char123{}\\
\ttfamily ~~~~~~~~~nondet~\char61{}~true\char59{}\\
\ttfamily ~~~~~~~~~memcpy\char40{}f\char95{}backup\char44{}~RET\char46{}n\char44{}~sizeof\char40{}Node\char41{}\char41{}\char59{}\\
\ttfamily ~~~~~\char125{}\\
\ttfamily ~~~~~else~if\char40{}RET\char46{}n\char45{}\char62{}tag~\char61{}\char61{}~FORWARD\char95{}TAG\char41{}\\
\ttfamily ~~~~~\char123{}\\
\ttfamily ~~~~~~~~~f\char95{}backup~\char61{}~RET\char46{}n\char45{}\char62{}children\char91{}0\char93{}\char59{}\\
\ttfamily ~~~~~\char125{}\\
\ttfamily ~\\
\ttfamily ~~~~~while\char40{}true\char41{}\\
\ttfamily ~~~~~\char123{}\\
\ttfamily ~~~~~~~~~nondet~\char124{}\char61{}~scrutinee\char46{}n\char45{}\char62{}nondet\char59{}\\
\ttfamily ~~~~~~~~~switch\char40{}scrutenee\char46{}n\char45{}\char62{}tag\char41{}\\
\ttfamily ~~~~~~~~~\char123{}\\
\ttfamily ~~~~~~~~~~~~~\char46{}\char46{}\char46{}\\
\ttfamily ~~~~~~~~~~~~~case~True\char58{}\\
\ttfamily ~~~~~~~~~~~~~~~~~if\char40{}nondet\char41{}\\
\ttfamily ~~~~~~~~~~~~~~~~~\char123{}\\
\ttfamily ~~~~~~~~~~~~~~~~~~~~~stack\char95{}push\char40{}bt\char95{}stack\char44{}~root\char44{}~main\char95{}1\char40{}f\char95{}backup\char41{}\char41{}\char59{}\\
\ttfamily ~~~~~~~~~~~~~~~~~\char125{}\\
\ttfamily ~~~~~~~~~~~~~~~~~set\char95{}int\char40{}root\char44{}~0\char41{}\char59{}\\
\ttfamily ~~~~~~~~~~~~~~~~~return\char59{}\\
\ttfamily ~~~~~~~~~~~~~~~~~\char46{}\char46{}\char46{}\\
\ttfamily ~~~~~~~~~\char125{}\\
\ttfamily ~~~~~\char125{}
\end{tabbing}
\caption{Final version of \ensuremath{\Varid{main}} with Shortcutting.}
\label{fig:RET3}
\end{figure}

\begin{figure}
\begin{tabbing}\ttfamily
~Node\char42{}~f\char95{}RET\char95{}hnf\char40{}Node\char42{}~backup\char41{}\\
\ttfamily ~\char123{}\\
\ttfamily ~~~~~Node\char42{}~v1~\char61{}~RET\char45{}\char62{}children\char91{}0\char93{}\char59{}\\
\ttfamily ~~~~~set\char95{}g\char40{}RET\char44{}~v1\char41{}\char59{}\\
\ttfamily ~~~~~field~scrutenee~\char61{}~RET\char59{}\\
\ttfamily ~~~~~Node\char42{}~g\char95{}backup~\char61{}~g\char95{}RET\char95{}hnf\char40{}NULL\char41{}\char59{}\\
\ttfamily ~~~~~bool~nondet~\char61{}~false\char59{}\\
\ttfamily ~~~~~if\char40{}g\char95{}backup~\char33{}\char61{}~NULL\char41{}~\char123{}\\
\ttfamily ~~~~~~~~~nondet~\char61{}~true\char59{}\\
\ttfamily ~~~~~~~~~memcpy\char40{}g\char95{}backup\char44{}~RET\char46{}n\char44{}~sizeof\char40{}Node\char41{}\char41{}\char59{}\\
\ttfamily ~~~~~\char125{}\\
\ttfamily ~~~~~else~if\char40{}RET\char46{}n\char45{}\char62{}tag~\char61{}\char61{}~FORWARD\char95{}TAG\char41{}~\char123{}\\
\ttfamily ~~~~~~~~~g\char95{}backup~\char61{}~RET\char46{}n\char45{}\char62{}children\char91{}0\char93{}\char59{}\\
\ttfamily ~~~~~\char125{}\\
\ttfamily ~~~~~while\char40{}true\char41{}~\char123{}\\
\ttfamily ~~~~~~~~~nondet~\char124{}\char61{}~scrutenee\char46{}n\char45{}\char62{}nondet\char59{}\\
\ttfamily ~~~~~~~~~switch\char40{}RET\char95{}forward\char45{}\char62{}tag\char41{}~\char123{}\\
\ttfamily ~~~~~~~~~~~~~\char46{}\char46{}\char46{}\\
\ttfamily ~~~~~~~~~~~~~case~True\char58{}\\
\ttfamily ~~~~~~~~~~~~~~~~~if\char40{}nondet\char41{}~\char123{}\\
\ttfamily ~~~~~~~~~~~~~~~~~~~~~if\char40{}\char33{}backup\char41{}~\char123{}\\
\ttfamily ~~~~~~~~~~~~~~~~~~~~~~~~~backup~\char61{}~\char40{}Node\char42{}\char41{}malloc\char40{}sizeof\char40{}Node\char41{}\char41{}\char59{}\\
\ttfamily ~~~~~~~~~~~~~~~~~~~~~\char125{}\\
\ttfamily ~~~~~~~~~~~~~~~~~~~~~set\char95{}False\char40{}backup\char41{}\char59{}\\
\ttfamily ~~~~~~~~~~~~~~~~~~~~~stack\char95{}push\char40{}bt\char95{}stack\char44{}~backup\char44{}~g\char95{}backup\char41{}\char59{}\\
\ttfamily ~~~~~~~~~~~~~~~~~\char125{}\\
\ttfamily ~~~~~~~~~~~~~~~~~set\char95{}False\char40{}RET\char41{}\char59{}\\
\ttfamily ~~~~~~~~~~~~~~~~~return~backup\char59{}\\
\ttfamily ~~~~~~~~~~~~~\char46{}\char46{}\char46{}\\
\ttfamily ~~~~~~~~~\char125{}\\
\ttfamily ~~~~~\char125{}
\end{tabbing}
\caption{Compiling \ensuremath{\Varid{f}} with Shortcutting.}
\label{fig:RET_f}
\end{figure}

Now, we finally have a working function.
We only allocate memory if the scrutinee of the case is non-deterministic.
If the expression is non-deterministic in multiple places,
then the same \texttt{backup} node is pushed on the stack,
so our expression graphs stay consistent.

This also works well if we have multiple reductions in a row.
Suppose we have the following Curry code:
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{15}{@{}>{\hspre}l<{\hspost}@{}}%
\column{16}{@{}>{\hspre}l<{\hspost}@{}}%
\column{23}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{main}\mathrel{=}\mathbf{case}\;{}\<[16]%
\>[16]{}\Varid{f}\;\mathrm{4}\;\mathbf{of}{}\<[E]%
\\
\>[16]{}\Conid{True}{}\<[23]%
\>[23]{}\to \Conid{False}{}\<[E]%
\\
\>[16]{}\Conid{False}{}\<[23]%
\>[23]{}\to \Conid{False}{}\<[E]%
\\[\blanklineskip]%
\>[3]{}\Varid{f}\;\Varid{n}\mathrel{=}\mathbf{case}\;{}\<[15]%
\>[15]{}\Varid{n}\;\mathbf{of}{}\<[E]%
\\
\>[15]{}\mathrm{0}\to \Conid{True}{}\<[E]%
\\
\>[15]{}\anonymous \to \Varid{f}\;(\Varid{n}\mathbin{-}\mathrm{1}){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
In this case \ensuremath{\Varid{f}} is a recursive function,
so when we reduce \ensuremath{\Varid{f}\;\mathrm{4}}, we need to reduce \ensuremath{\Varid{f}\;\mathrm{3}}.
This is no problem at all, because we're reducing \ensuremath{\Varid{f}\;\mathrm{4}} with \texttt{f\_RET\_hnf}.
Ignoring the complications of Unboxing for the moment, we can generate the following code
for the return of \ensuremath{\Varid{f}}.

\begin{tabbing}\ttfamily
~field~v2~\char61{}~make\char95{}int\char40{}n\char45{}1\char41{}\\
\ttfamily ~set\char95{}f\char40{}RET\char44{}~v2\char41{}\char59{}\\
\ttfamily ~return~f\char95{}RET\char95{}hnf\char40{}backup\char41{}\char59{}
\end{tabbing}

\subsection{Shortcutting Results}

Before we move onto our next optimization, we should look back at what we've done so far.
Initially, we had a \ensuremath{\Varid{fib}} function that allocated 5 nodes for every recursive call.
Then, through Unboxing, we were able to cut that down to only 2 allocations per call.
Finally, using Shortcutting, we were able to eliminate those two allocations.
We would expect a substantial speedup by reducing memory consumption by 60\%,
but removing those last two allocations is a difference in kind.
The \ensuremath{\Varid{fib}} function runs in exponential time,
and since each step allocates some memory, the original \ensuremath{\Varid{fib}} function
allocated an exponential amount of memory on the heap.
However, our fully optimized \ensuremath{\Varid{fib}} function only allocates a static node at startup.
We've moved from exponential memory allocated on the heap to constant space.
While \ensuremath{\Varid{fib}} still runs in exponential time,
it runs much faster, since it doesn't need to allocate memory.
Surprisingly, \ensuremath{\Varid{fib}} is still just as efficient with non-deterministic arguments.
If the argument is non-deterministic, the wrapper function will evaluate it
before calling the worker.

Now that we've removed most of the implicitly allocated memory
with Unboxing and Shortcutting, 
we can work on removing explicitly allocated memory
with a technique from functional languages.

\section{Deforestation}
We now turn to our final optimization, Deforestation.
The goal of this optimization is to remove intermediate data structures.
Programmers often write in a pipeline style when writing functional programs.
For example, consider the program:
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{15}{@{}>{\hspre}c<{\hspost}@{}}%
\column{15E}{@{}l@{}}%
\column{18}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{sumPrimes}{}\<[15]%
\>[15]{}\mathrel{=}{}\<[15E]%
\>[18]{}\Varid{sum}\mathbin{\circ}\Varid{filter}\;\Varid{isPrime}\mathbin{\circ}\Varid{enumFromTo}\;\mathrm{2}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
While this style is concise and readable, it isn't efficient.
First, we create a list of integers,
then we create a new list of all of the integers in our list that are prime,
and finally we sum the values in that list.
It would be much more efficient to compute this sum directly.
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{4}{@{}>{\hspre}l<{\hspost}@{}}%
\column{11}{@{}>{\hspre}l<{\hspost}@{}}%
\column{24}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{sumPrimes}\;\Varid{n}\mathrel{=}\Varid{go}\;\mathrm{2}\;\Varid{n}{}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mathbf{where}\;{}\<[11]%
\>[11]{}\Varid{go}\;\Varid{k}\;\Varid{n}{}\<[E]%
\\
\>[11]{}\mid \Varid{k}\geq \Varid{n}{}\<[24]%
\>[24]{}\mathrel{=}\mathrm{0}{}\<[E]%
\\
\>[11]{}\mid \Varid{isPrime}\;\Varid{k}{}\<[24]%
\>[24]{}\mathrel{=}\Varid{k}\mathbin{+}\Varid{go}\;(\Varid{k}\mathbin{+}\mathrm{1})\;\Varid{n}{}\<[E]%
\\
\>[11]{}\mid \Varid{otherwise}{}\<[24]%
\>[24]{}\mathrel{=}\Varid{go}\;(\Varid{k}\mathbin{+}\mathrm{1})\;\Varid{n}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks

This pipeline pattern is pervasive in functional programming,
so it's worth understanding and optimizing it.
In particular, we want to eliminate the two intermediate lists created here.
This is the goal of Deforestation.

\subsection{The Original Scheme}
Deforestation has actually gone through several forms throughout it's history.
The original optimization proposed by Wadler \cite{deforestationWadler}
was very general, but it required a complicated algorithm, and it could fail to terminate.
There have been various attempts to improve this algorithm \cite{turchin_supercompiler} and 
\cite{wadler_ferguson_deforest}
that have focused on restricting the form of programs.

An alternative was proposed by Gill in his dissertation \cite{gill_dissertation, shortcutDeforestation}
called \mbox{foldr-build} Deforestation or short-cut Deforestation. 
This approach is much simpler, always terminates, and has a nice correctness proof,
but it comes at the cost of generality.
\mbox{Foldr-build} Deforestation only works with functions that produce and consume lists.
Still, lists are common enough in functional languages that this optimization has proven to be effective.

Since then \mbox{foldr-build} Deforestation has been extended to Stream Fusion \cite{stream}.
While this optimization is able to cover more cases than \mbox{foldr-build} Deforestation,
it relies on more advanced compiler technology.

The \mbox{foldr-build} optimization itself is actually very simple.
It relies on an observation about the structure of a list.
All lists in Curry are built up from cons and nil cells.
The list \ensuremath{[\mskip1.5mu \mathrm{1},\mathrm{2},\mathrm{3},\mathrm{4}\mskip1.5mu]} is really \ensuremath{\mathrm{1}\mathbin{:}\mathrm{2}\mathbin{:}\mathrm{3}\mathbin{:}\mathrm{4}\mathbin{:}[\mskip1.5mu \mskip1.5mu]}.
One very common list processing technique is a fold,
which takes a binary operation and a starting element, and reduces a list to a single value.
In Curry, the \ensuremath{\Varid{foldr}} function is defined as:
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{23}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{foldr}\mathbin{::}(\Varid{a}\to \Varid{b}\to \Varid{b})\to \Varid{b}\to [\mskip1.5mu \Varid{a}\mskip1.5mu]\to \Varid{b}{}\<[E]%
\\
\>[3]{}\Varid{foldr} \oplus \Varid{z}\;[\mskip1.5mu \mskip1.5mu]{}\<[23]%
\>[23]{}\mathrel{=}\Varid{z}{}\<[E]%
\\
\>[3]{}\Varid{foldr} \oplus \Varid{z}\;(\Varid{x}\mathbin{:}\Varid{xs}){}\<[23]%
\>[23]{}\mathrel{=}\Varid{x} \oplus \Varid{foldr}\;\Varid{f}\;\Varid{z}\;\Varid{xs}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
As an example, we can define the \ensuremath{\Varid{sum}} function as \ensuremath{\Varid{sum}\;\Varid{xs}\mathrel{=}\Varid{foldr}\;(\mathbin{+})\;\mathrm{0}}.
To see what this is really doing we can unroll the recursion.
Suppose we evaluate \ensuremath{\Varid{foldr}\;(\mathbin{+})\;\mathrm{0}\;[\mskip1.5mu \mathrm{1},\mathrm{2},\mathrm{3},\mathrm{4},\mathrm{5}\mskip1.5mu]}, then we have:
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{foldr}\;(\mathbin{+})\;\mathrm{0}\;[\mskip1.5mu \mathrm{1},\mathrm{2},\mathrm{3},\mathrm{4},\mathrm{5}\mskip1.5mu]{}\<[E]%
\\
\>[3]{}\Rightarrow \mathrm{1}\mathbin{+}\Varid{foldr}\;(\mathbin{+})\;\mathrm{0}\;[\mskip1.5mu \mathrm{2},\mathrm{3},\mathrm{4},\mathrm{5}\mskip1.5mu]{}\<[E]%
\\
\>[3]{}\Rightarrow \mathrm{1}\mathbin{+}(\mathrm{2}\mathbin{+}\Varid{foldr}\;(\mathbin{+})\;\mathrm{0}\;[\mskip1.5mu \mathrm{3},\mathrm{4},\mathrm{5}\mskip1.5mu])){}\<[E]%
\\
\>[3]{}\Rightarrow \mathrm{1}\mathbin{+}(\mathrm{2}\mathbin{+}(\mathrm{3}\mathbin{+}\Varid{foldr}\;(\mathbin{+})\;\mathrm{0}\;[\mskip1.5mu \mathrm{4},\mathrm{5}\mskip1.5mu])){}\<[E]%
\\
\>[3]{}\Rightarrow \mathrm{1}\mathbin{+}(\mathrm{2}\mathbin{+}(\mathrm{3}\mathbin{+}(\mathrm{4}\mathbin{+}\Varid{foldr}\;(\mathbin{+})\;\mathrm{0}\;[\mskip1.5mu \mathrm{5}\mskip1.5mu]))){}\<[E]%
\\
\>[3]{}\Rightarrow \mathrm{1}\mathbin{+}(\mathrm{2}\mathbin{+}(\mathrm{3}\mathbin{+}(\mathrm{4}\mathbin{+}(\mathrm{5}\mathbin{+}\Varid{foldr}\;(\mathbin{+})\;\mathrm{0}\;[\mskip1.5mu \mskip1.5mu])))){}\<[E]%
\\
\>[3]{}\Rightarrow \mathrm{1}\mathbin{+}(\mathrm{2}\mathbin{+}(\mathrm{3}\mathbin{+}(\mathrm{4}\mathbin{+}(\mathrm{5}\mathbin{+}\mathrm{0})))){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
But wait, this looks very similar to our construction of a list.
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{6}{@{}>{\hspre}c<{\hspost}@{}}%
\column{6E}{@{}l@{}}%
\column{9}{@{}>{\hspre}l<{\hspost}@{}}%
\column{13}{@{}>{\hspre}c<{\hspost}@{}}%
\column{13E}{@{}l@{}}%
\column{16}{@{}>{\hspre}l<{\hspost}@{}}%
\column{20}{@{}>{\hspre}c<{\hspost}@{}}%
\column{20E}{@{}l@{}}%
\column{23}{@{}>{\hspre}l<{\hspost}@{}}%
\column{27}{@{}>{\hspre}c<{\hspost}@{}}%
\column{27E}{@{}l@{}}%
\column{30}{@{}>{\hspre}l<{\hspost}@{}}%
\column{34}{@{}>{\hspre}c<{\hspost}@{}}%
\column{34E}{@{}l@{}}%
\column{37}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathrm{1}{}\<[6]%
\>[6]{}\mathbin{:}{}\<[6E]%
\>[9]{}(\mathrm{2}{}\<[13]%
\>[13]{}\mathbin{:}{}\<[13E]%
\>[16]{}(\mathrm{3}{}\<[20]%
\>[20]{}\mathbin{:}{}\<[20E]%
\>[23]{}(\mathrm{4}{}\<[27]%
\>[27]{}\mathbin{:}{}\<[27E]%
\>[30]{}(\mathrm{5}{}\<[34]%
\>[34]{}\mathbin{:}{}\<[34E]%
\>[37]{}([\mskip1.5mu \mskip1.5mu]))))){}\<[E]%
\\
\>[3]{}\mathrm{1}{}\<[6]%
\>[6]{}\mathbin{+}{}\<[6E]%
\>[9]{}(\mathrm{2}{}\<[13]%
\>[13]{}\mathbin{+}{}\<[13E]%
\>[16]{}(\mathrm{3}{}\<[20]%
\>[20]{}\mathbin{+}{}\<[20E]%
\>[23]{}(\mathrm{4}{}\<[27]%
\>[27]{}\mathbin{+}{}\<[27E]%
\>[30]{}(\mathrm{5}{}\<[34]%
\>[34]{}\mathbin{+}{}\<[34E]%
\>[37]{}(\mathrm{0}))))){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
We've just replaced the \ensuremath{\mathbin{:}} with \ensuremath{\mathbin{+}} and the \ensuremath{[\mskip1.5mu \mskip1.5mu]} with \ensuremath{\mathrm{0}}.
If the compiler can find where we will do this replacement,
then we don't need to construct the list.
On its own, this is a very hard problem, but we can help the compiler along.
We just need a standard way to construct a list.
This can be done with the \ensuremath{\Varid{build}} function \cite{shortcutDeforestation}.
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{build}\mathbin{::}(\forall \;\Varid{b}\;(\Varid{a}\to \Varid{b}\to \Varid{b})\to \Varid{b}\to \Varid{b})\to [\mskip1.5mu \Varid{a}\mskip1.5mu]{}\<[E]%
\\
\>[3]{}\Varid{build}\;\Varid{g}\mathrel{=}\Varid{g}\;(\mathbin{:})\;[\mskip1.5mu \mskip1.5mu]{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
The \ensuremath{\Varid{build}} function takes a function that constructs a list.
However, instead of construction the list with \ensuremath{\mathbin{:}} and \ensuremath{[\mskip1.5mu \mskip1.5mu]},
we abstract this by passing the constructors in as arguments, which we call \ensuremath{\Varid{c}} and \ensuremath{\Varid{n}} respectively.
Now, with \ensuremath{\Varid{build}}, we can define what we mean by deforestation with a simple theorem from
\cite{shortcutDeforestation}.

\begin{theorem}
For all \ensuremath{\Varid{f}\mathbin{:}\Varid{a}\to \Varid{b}\to \Varid{b}}, \ensuremath{\Varid{z}\mathbin{:}\Varid{b}}, and \ensuremath{\Varid{g}\mathbin{:}(\forall \;\Varid{b}\;(\Varid{a}\to \Varid{b}\to \Varid{b})\to \Varid{b}\to \Varid{b})\to [\mskip1.5mu \Varid{a}\mskip1.5mu]},\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{foldr}\;\Varid{f}\;\Varid{z}\;(\Varid{build}\;\Varid{g})\mathrel{=}\Varid{g}\;\Varid{f}\;\Varid{z}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{theorem}

So, if we can construct standard list functions using \ensuremath{\Varid{build}} and \ensuremath{\Varid{foldr}},
then we can remove these function using the above theorem.
As an example, let's look at the function \ensuremath{\Varid{enumFromTo}\;\Varid{a}\;\Varid{b}} that constructs
a list of integers from \ensuremath{\Varid{a}} to \ensuremath{\Varid{b}}.\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{4}{@{}>{\hspre}l<{\hspost}@{}}%
\column{17}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{enumFromTo}\;\Varid{a}\;\Varid{b}{}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mid \Varid{a}\mathbin{>}\Varid{b}{}\<[17]%
\>[17]{}\mathrel{=}[\mskip1.5mu \mskip1.5mu]{}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mid \Varid{otherwise}{}\<[17]%
\>[17]{}\mathrel{=}\Varid{a}\mathbin{:}\Varid{enumFromTo}\;(\Varid{a}\mathbin{+}\mathrm{1})\;\Varid{b}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
We can turn this into a build function.\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{4}{@{}>{\hspre}l<{\hspost}@{}}%
\column{17}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{enumFromTo}\;\Varid{a}\;\Varid{b}\mathrel{=}\Varid{build}\;(\Varid{enumFromTo\char95 build}\;\Varid{a}\;\Varid{b}){}\<[E]%
\\
\>[3]{}\Varid{enumFromTo\char95 build}\;\Varid{a}\;\Varid{b}\;\Varid{c}\;\Varid{n}{}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mid \Varid{a}\mathbin{>}\Varid{b}{}\<[17]%
\>[17]{}\mathrel{=}\Varid{n}{}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mid \Varid{otherwise}{}\<[17]%
\>[17]{}\mathrel{=}\Varid{a}\mathbin{`\Varid{c}`}\Varid{enumFromTo\char95 build}\;(\Varid{a}\mathbin{+}\mathrm{1})\;\Varid{b}\;\Varid{c}\;\Varid{n}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
We can create build functions for several list creation functions
found in the standard library.
In fact, for this optimization we replace several functions in both the
Prelude and List library with equivalent functions constructed with \ensuremath{\Varid{foldr}} and \ensuremath{\Varid{build}}.
Now we're ready to apply Deforestation to Curry.
Unfortunately there are two problems we need to solve.
The first is an implementation problem,
and the second is a theoretical problem.
First, while we can apply foldr/build Deforestation, we can't actually optimize the results.
Second, we still need to show it's valid for curry.

\subsection{The Combinator Problem}

Let's look back at the motivating example,
and see how it could be optimized in Haskell,
or any language that can inline lambda expressions.
The derivation in figure \ref{fig:sumPrimes_deforest} comes from the 
original paper \cite{shortcutDeforestation}.

\begin{figure}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{5}{@{}>{\hspre}l<{\hspost}@{}}%
\column{19}{@{}>{\hspre}l<{\hspost}@{}}%
\column{20}{@{}>{\hspre}l<{\hspost}@{}}%
\column{25}{@{}>{\hspre}l<{\hspost}@{}}%
\column{35}{@{}>{\hspre}l<{\hspost}@{}}%
\column{39}{@{}>{\hspre}l<{\hspost}@{}}%
\column{41}{@{}>{\hspre}l<{\hspost}@{}}%
\column{42}{@{}>{\hspre}l<{\hspost}@{}}%
\column{47}{@{}>{\hspre}l<{\hspost}@{}}%
\column{50}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{sumPrimes}\;\Varid{m}\mathrel{=}\Varid{sum}\;(\Varid{filter}\;\Varid{isPrime}\;(\Varid{enumFromTo}\;\mathrm{2}\;\Varid{m})){}\<[E]%
\\
\>[3]{}\Rrightarrow {}\<[E]%
\\
\>[3]{}\Varid{sumPrimes}\;\Varid{m}\mathrel{=}\Varid{foldr}\;(\lambda \Varid{x}\;\Varid{y}\to \Varid{x}\mathbin{+}\Varid{y})\;\mathrm{0}\;{}\<[E]%
\\
\>[3]{}\hsindent{16}{}\<[19]%
\>[19]{}(\Varid{build}\;(\lambda \Varid{c}\;\Varid{n}\to \Varid{foldr}\;(\lambda \Varid{x}\;\Varid{y}\to \mathbf{if}\;\Varid{isPrime}\;\Varid{x}\;\mathbf{then}\;\Varid{x}\mathbin{`\Varid{c}`}\Varid{y}\;\mathbf{else}\;\Varid{y})\;\Varid{n}){}\<[E]%
\\
\>[19]{}\hsindent{1}{}\<[20]%
\>[20]{}(\Varid{build}\;\Varid{enumFromTo\char95 build}\;\mathrm{2}\;\Varid{m})){}\<[E]%
\\
\>[3]{}\Rrightarrow {}\<[E]%
\\
\>[3]{}\Varid{sumPrimes}\;\Varid{m}\mathrel{=}\Varid{foldr}\;(\lambda \Varid{x}\;\Varid{y}\to \Varid{x}\mathbin{+}\Varid{y})\;\mathrm{0}\;{}\<[E]%
\\
\>[3]{}\hsindent{16}{}\<[19]%
\>[19]{}(\Varid{build}\;(\lambda \Varid{c}\;\Varid{n}\to (\Varid{enumFromTo\char95 build}\;\mathrm{2}\;\Varid{x})\;(\lambda \Varid{x}\;\Varid{y}\to \mathbf{if}\;\Varid{isPrime}\;\Varid{x}\;\mathbf{then}\;\Varid{x}\mathbin{`\Varid{c}`}\Varid{y}\;\mathbf{else}\;\Varid{y})\;\Varid{n})){}\<[E]%
\\
\>[3]{}\Rrightarrow {}\<[E]%
\\
\>[3]{}\Varid{sumPrimes}\;\Varid{m}\mathrel{=}\Varid{enumFromTo\char95 build}\;\mathrm{2}\;\Varid{m}\;(\lambda \Varid{x}\;\Varid{y}\to \mathbf{if}\;\Varid{isPrime}\;\Varid{x}\;\mathbf{then}\;(\lambda \Varid{x}\;\Varid{y}\to \Varid{x}\mathbin{+}\Varid{y})\;\Varid{x}\;\Varid{y}\;\mathbf{else}\;\Varid{y})\;\mathrm{0}{}\<[E]%
\\
\>[3]{}\Rrightarrow {}\<[E]%
\\
\>[3]{}\Varid{sumPrimes}\;\Varid{m}\mathrel{=}\Varid{enumToFrom\char95 build}\;\mathrm{2}\;\Varid{m}\;(\lambda \Varid{x}\;\Varid{y}\to \mathbf{if}\;\Varid{isPrime}\;\Varid{x}\;\mathbf{then}\;\Varid{x}\mathbin{+}\Varid{y}\;\mathbf{else}\;\Varid{y})\;\mathrm{0}{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mathbf{where}\;\Varid{enumToFrom\char95 build}\;\Varid{k}\;\Varid{m}\;\Varid{c}\;\Varid{z}\mathrel{=}{}\<[39]%
\>[39]{}\mathbf{if}\;\Varid{k}\mathbin{>}\Varid{m}{}\<[E]%
\\
\>[5]{}\hsindent{20}{}\<[25]%
\>[25]{}\mathbf{then}\;\Varid{z}{}\<[E]%
\\
\>[5]{}\hsindent{20}{}\<[25]%
\>[25]{}\mathbf{else}\;\Varid{c}\;\Varid{k}\;(\Varid{enumToFrom\char95 build}\;(\Varid{k}\mathbin{+}\mathrm{1})\;\Varid{m}\;\Varid{c}\;\Varid{z}){}\<[E]%
\\
\>[3]{}\Rrightarrow {}\<[E]%
\\
\>[3]{}\Varid{sumPrimes}\;\Varid{m}\mathrel{=}\Varid{enumToFrom\char95 build}\;\mathrm{2}\;\Varid{m}\;(\lambda \Varid{x}\;\Varid{y}\to \mathbf{if}\;\Varid{isPrime}\;\Varid{x}\;\mathbf{then}\;\Varid{x}\mathbin{+}\Varid{y}\;\mathbf{else}\;\Varid{y})\;\mathrm{0}{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mathbf{where}\;\Varid{enumToFrom\char95 build}\;\Varid{k}\;\Varid{m}\;\Varid{c}\;\Varid{z}\mathrel{=}{}\<[39]%
\>[39]{}\mathbf{if}\;\Varid{k}\mathbin{>}\Varid{m}{}\<[E]%
\\
\>[39]{}\mathbf{then}\;\Varid{z}{}\<[E]%
\\
\>[39]{}\mathbf{else}\;(\lambda \Varid{x}\;\Varid{y}\to \mathbf{if}\;\Varid{isPrime}\;\Varid{x}\;\mathbf{then}\;\Varid{x}\mathbin{+}\Varid{y}\;\mathbf{else}\;\Varid{y})\;{}\<[E]%
\\
\>[39]{}\hsindent{8}{}\<[47]%
\>[47]{}\Varid{k}\;(\Varid{enumToFrom\char95 build}\;(\Varid{k}\mathbin{+}\mathrm{1})\;\Varid{m}\;\Varid{c}\;\Varid{z}){}\<[E]%
\\
\>[3]{}\Rrightarrow {}\<[E]%
\\
\>[3]{}\Varid{sumPrimes}\;\Varid{m}\mathrel{=}\Varid{enumToFrom\char95 build}\;\mathrm{2}\;\Varid{m}{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mathbf{where}\;\Varid{enumToFrom\char95 build}\;\Varid{k}\;\Varid{m}\mathrel{=}{}\<[35]%
\>[35]{}\mathbf{if}\;\Varid{k}\mathbin{>}\Varid{m}{}\<[E]%
\\
\>[35]{}\mathbf{then}\;\Varid{z}{}\<[E]%
\\
\>[35]{}\mathbf{else}\;(\lambda \Varid{x}\;\Varid{y}\to {}\<[50]%
\>[50]{}\mathbf{if}\;\Varid{isPrime}\;\Varid{x}\;\mathbf{then}\;\Varid{x}\mathbin{+}\Varid{y}\;\mathbf{else}\;\Varid{y})\;{}\<[E]%
\\
\>[35]{}\hsindent{7}{}\<[42]%
\>[42]{}\Varid{k}\;(\Varid{enumToFrom\char95 build}\;(\Varid{k}\mathbin{+}\mathrm{1})\;\Varid{m}\;\Varid{c}\;\Varid{z}){}\<[E]%
\\
\>[3]{}\Rrightarrow {}\<[E]%
\\
\>[3]{}\Varid{sumPrimes}\;\Varid{m}\mathrel{=}\Varid{enumToFrom\char95 build}\;\mathrm{2}\;\Varid{m}{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mathbf{where}\;\Varid{enumToFrom\char95 build}\;\Varid{k}\;\Varid{m}\mathrel{=}{}\<[35]%
\>[35]{}\mathbf{if}\;\Varid{k}\mathbin{>}\Varid{m}{}\<[E]%
\\
\>[35]{}\mathbf{then}\;\Varid{z}{}\<[E]%
\\
\>[35]{}\mathbf{else}\;{}\<[41]%
\>[41]{}\mathbf{if}\;\Varid{isPrime}\;\Varid{k}{}\<[E]%
\\
\>[41]{}\mathbf{then}\;\Varid{x}\mathbin{+}(\Varid{enumToFrom\char95 build}\;(\Varid{k}\mathbin{+}\mathrm{1})\;\Varid{m}\;\Varid{c}\;\Varid{z}){}\<[E]%
\\
\>[41]{}\mathbf{else}\;(\Varid{enumToFrom\char95 build}\;(\Varid{k}\mathbin{+}\mathrm{1})\;\Varid{m}\;\Varid{c}\;\Varid{z}){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\caption{Optimization derivation for for short-cut Deforestation}
\label{fig:sumPrimes_deforest}
\end{figure}

This looks good.
In fact, we obtained the original expression we were trying for.
Unfortunately we don't get the same optimization in Rice.
The problem is actually the definition of \ensuremath{\Varid{filter}}.
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{filter}\;\Varid{f}\mathrel{=}\Varid{build}\;(\lambda \Varid{c}\;\Varid{n}\to \Varid{foldr}\;(\lambda \Varid{x}\;\Varid{y}\to \mathbf{if}\;\Varid{f}\;\Varid{x}\;\mathbf{then}\;\Varid{x}\mathbin{`\Varid{c}`}\Varid{y}\;\mathbf{else}\;\Varid{y})\;\Varid{n}){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
Functions that transform lists, such as \ensuremath{\Varid{filter}}, \ensuremath{\Varid{map}}, and \ensuremath{\Varid{concat}},
are rewritten in the standard library as a build applied to a fold.
Unfortunately our inliner can't produce this derivation.
We don't inline lambda expressions, and reductions
can only be applied to let bound variables, so we simply can't do this reduction.
Instead we need a new solution.

\subsection{Solution build\_fold}

Our solution to this problem is to introduce a new combinator for transforming lists.
We call this \ensuremath{\Varid{build\char95 fold}} since it is a build applied to a fold.
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{build\char95 fold}\mathbin{::}((\Varid{c}\to \Varid{b}\to \Varid{b})\to (\Varid{a}\to \Varid{b}\to \Varid{b}))\to (\Varid{b}\to \Varid{b})\to [\mskip1.5mu \Varid{a}\mskip1.5mu]\to \Varid{b}{}\<[E]%
\\
\>[3]{}\Varid{build\char95 fold}\;\Varid{mkf}\;\Varid{mkz}\;\Varid{xs}\mathrel{=}\Varid{foldr}\;(\Varid{mkf}\;(\mathbin{:}))\;(\Varid{mkz}\;[\mskip1.5mu \mskip1.5mu])\;\Varid{xs}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
The idea behind this combinator is a combination of a build and a fold.
This function was designed to be easily composable with both build and fold.
Ideally, it could fit in the middle of build and fold and still reduce.
As and example:\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{foldr}\;(\mathbin{+})\;\mathrm{0}\;(\Varid{build\char95 fold}\;\Varid{filter\char95 mkf}\;\Varid{filter\char95 mkz}\;(\Varid{build}\;\Varid{enumFromTo\char95 build})){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
Ideally, this function should reduce into something relatively efficient,
Furthermore we wanted \ensuremath{\Varid{build\char95 fold}} to compose nicely with itself.
For example, \ensuremath{\Varid{map}\;\Varid{f}\mathbin{\circ}\Varid{map}\;\Varid{g}} should compose to something like \ensuremath{\Varid{map}\;(\Varid{f}\mathbin{\circ}\Varid{g})}.

We achieve this by combining pieces of both \ensuremath{\Varid{build}} and \ensuremath{\Varid{foldr}}.
The two functions \ensuremath{\Varid{mkf}} and \ensuremath{\Varid{mkz}} make the \ensuremath{\Varid{f}} and \ensuremath{\Varid{z}} functions from fold,
however they take \ensuremath{\Varid{c}} and \ensuremath{\Varid{n}} as arguments similar to \ensuremath{\Varid{build}}.
The idea is that \ensuremath{\Varid{mkf}} takes an \ensuremath{\Varid{f}} from \ensuremath{\Varid{foldr}} as a parameter,
and returns a new \ensuremath{\Varid{f}}.
The \ensuremath{\Varid{map}} and \ensuremath{\Varid{filter}} implementations are given below.
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{map}\;\Varid{f}\mathrel{=}\Varid{build\char95 fold}\;(\Varid{map\char95 mkf}\;\Varid{f})\;\Varid{map\char95 mkz}{}\<[E]%
\\
\>[3]{}\Varid{map\char95 mkf}\;\Varid{f}\;\Varid{c}\;\Varid{x}\;\Varid{y}\mathrel{=}\Varid{f}\;\Varid{x}\mathbin{`\Varid{c}`}\Varid{y}{}\<[E]%
\\
\>[3]{}\Varid{map\char95 mkz}\;\Varid{n}\mathrel{=}\Varid{n}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{filter}\;\Varid{p}\mathrel{=}\Varid{build\char95 fold}\;(\Varid{filter\char95 mkc}\;\Varid{p})\;\Varid{filter\char95 mkz}{}\<[E]%
\\
\>[3]{}\Varid{filter\char95 mkf}\;\Varid{p}\;\Varid{c}\;\Varid{x}\;\Varid{y}\mathrel{=}\mathbf{if}\;\Varid{p}\;\Varid{x}\;\mathbf{then}\;\Varid{x}\mathbin{`\Varid{c}`}\Varid{y}\;\mathbf{else}\;\Varid{y}{}\<[E]%
\\
\>[3]{}\Varid{filter\char95 mkz}\;\Varid{n}\mathrel{=}\Varid{n}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
The purpose of the convoluted definition of \ensuremath{\Varid{build\char95 fold}} is that
it plays nicely with \ensuremath{\Varid{build}} and \ensuremath{\Varid{foldr}}.
We have the following three theorems about \ensuremath{\Varid{build\char95 fold}}, which we will prove later.
These are analogous to the \ensuremath{\Varid{foldr}\mathbin{/}\Varid{build}} theorem.

\begin{theorem}
For all functions of the appropriate type that evaluate no $?$ expressions,
the following qualities hold.\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{build\char95 fold}\;\Varid{mkf}\;\Varid{mkz}\;(\Varid{build}\;\Varid{g})\mathrel{=}\Varid{build}\;(\lambda \Varid{c}\;\Varid{n}\to \Varid{g}\;(\Varid{mkf}\;\Varid{c})\;(\Varid{mkz}\;\Varid{n})){}\<[E]%
\\
\>[3]{}\Varid{foldr}\;\Varid{f}\;\Varid{z}\;(\Varid{build\char95 fold}\;\Varid{mkf}\;\Varid{mkz}\;\Varid{xs})\mathrel{=}\Varid{foldr}\;(\Varid{mkf}\;\Varid{f})\;(\Varid{mkz}\;\Varid{z})\;\Varid{xs}{}\<[E]%
\\
\>[3]{}\Varid{build\char95 fold}\;\Varid{mkf}_{\mathrm{1}}\;\Varid{mkz}_{\mathrm{1}}\;(\Varid{build\char95 fold}\;\Varid{mkf}_{\mathrm{2}}\;\Varid{mkz}_{\mathrm{2}}\;\Varid{xs})\mathrel{=}\Varid{build\char95 fold}\;(\Varid{mkf}_{\mathrm{2}}\mathbin{\circ}\Varid{mkf}_{\mathrm{1}})\;(\Varid{mkz}_{\mathrm{2}}\mathbin{\circ}\Varid{mkz}_{\mathrm{1}})\;\Varid{xs}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{theorem}

Now that we've removed all of the lambdas from our definitions,
we can look at the implementation.

\subsection{Implementation}

Deforestation turned out to be one of the easiest optimizations to implement.
The implementation is entirely in GAS, and it proceeds in two steps.
First we find any case where a \ensuremath{\Varid{build}} or \ensuremath{\Varid{build\char95 fold}}
occurs exactly once in either a \ensuremath{\Varid{build\char95 fold}} or \ensuremath{\Varid{fold}}.
If this is the case, we inline the variable that \ensuremath{\Varid{build}} is bound to into it's single use.
This temporarily takes our expression out of A-Normal Form,
but we will restore that with the second step,
which is the actual Deforestation transformation,
which applies either the \ensuremath{\Varid{foldr}\mathbin{/}\Varid{build}} theorem,
or one of the three \ensuremath{\Varid{build\char95 fold}} theorems from above.
The definitions for the deforest transformation are given in figure \ref{fig:deforest}
The optimization derivation for \ensuremath{\Varid{sumPrimes}} is in figure \ref{fig:sumOpt}.

\begin{figure}
\textbf{Inline foldr/build:}\\
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{5}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;\Varid{x}\mathrel{=}\Varid{build}\;\Varid{g}\;\mathbf{in}\;\Varid{e}{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mid \Varid{e}|_{\Varid{p}}\mathrel{=}\Varid{foldr}\;\Varid{x}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}  \ensuremath{\Rrightarrow }
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{e}[[\mskip1.5mu \Varid{p},\mathrm{2}\mskip1.5mu]\to\Varid{build}\;\Varid{g}]{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}\\
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{5}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;\Varid{x}\mathrel{=}\Varid{build}\;\Varid{g}\;\mathbf{in}\;\Varid{e}{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mid \Varid{e}|_{\Varid{p}}\mathrel{=}\Varid{build\char95 fold}\;\anonymous \;\anonymous \;\Varid{x}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}  \ensuremath{\Rrightarrow }
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{e}[[\mskip1.5mu \Varid{p},\mathrm{2}\mskip1.5mu]\to\Varid{build}\;\Varid{g}]{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}\\
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{5}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;\Varid{x}\mathrel{=}\Varid{build\char95 fold}\;\Varid{mkf}\;\Varid{mkz}\;\mathbf{in}\;\Varid{e}{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mid \Varid{e}|_{\Varid{p}}\mathrel{=}\Varid{foldr}\;\Varid{f}\;\Varid{z}\;\Varid{x}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage} \ensuremath{\Rrightarrow }
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{e}[[\mskip1.5mu \Varid{p},\mathrm{2}\mskip1.5mu]\to\Varid{build\char95 fold}\;\Varid{mkf}\;\Varid{mkz}]{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}\\
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{5}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;\Varid{x}\mathrel{=}\Varid{build\char95 fold}\;\Varid{mkf}\;\Varid{mkz}\;\mathbf{in}\;\Varid{e}{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mid \Varid{e}|_{\Varid{p}}\mathrel{=}\Varid{build\char95 fold}\;\anonymous \;\anonymous \;\Varid{x}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}  \ensuremath{\Rrightarrow }
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{e}[[\mskip1.5mu \Varid{p},\mathrm{2}\mskip1.5mu]\to\Varid{build\char95 fold}\;\Varid{mkf}\;\Varid{mkz}]{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}\\
\textbf{Deforest foldr/build:}\\
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{foldr}\;\Varid{f}\;\Varid{z}\;(\Varid{build}\;\Varid{g}){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage} \ensuremath{\Rrightarrow }
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{g}\;\Varid{f}\;\Varid{z}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}\\
\textbf{Deforest build\_fold/build:}\\
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{build\char95 fold}\;\Varid{mkf}\;\Varid{mkz}\;(\Varid{build}\;\Varid{g}){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage} \ensuremath{\Rrightarrow }
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{build}\;(\lambda \Varid{c}\;\Varid{n}\to \Varid{g}\;(\Varid{mkf}\;\Varid{c})\;(\Varid{mkz}\;\Varid{n})){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}\\
\textbf{Deforest foldr/build\_fold:}\\
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{foldr}\;\Varid{f}\;\Varid{z}\;(\Varid{build\char95 fold}\;\Varid{mkf}\;\Varid{mkz}\;\Varid{xs}){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage} \ensuremath{\Rrightarrow }
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{11}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;{}\<[11]%
\>[11]{}\Varid{f}_{\mathrm{1}}\mathrel{=}\Varid{mkf}\;\Varid{f}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\mathbf{let}\;{}\<[11]%
\>[11]{}\Varid{z\char95 1}\mathrel{=}\Varid{mkz}\;\Varid{z}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\Varid{foldr}\;\Varid{f}_{\mathrm{1}}\;\Varid{z\char95 1}\;\Varid{xs}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}\\
\textbf{Deforest build\_fold/build\_fold:}\\
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{6}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{build\char95 fold}\;\Varid{mkf}_{\mathrm{1}}\;\Varid{mkz}_{\mathrm{1}}\;{}\<[E]%
\\
\>[3]{}\hsindent{3}{}\<[6]%
\>[6]{}(\Varid{build\char95 fold}\;\Varid{mkf}_{\mathrm{2}}\;\Varid{mkz}_{\mathrm{2}}\;\Varid{xs}){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage} \ensuremath{\Rrightarrow }
\begin{minipage}{.40\textwidth}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{11}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;{}\<[11]%
\>[11]{}\Varid{f}_{\mathrm{1}}\mathrel{=}\Varid{mkf}_{\mathrm{2}}\mathbin{\circ}\Varid{mkf}_{\mathrm{1}}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\mathbf{let}\;{}\<[11]%
\>[11]{}\Varid{z\char95 1}\mathrel{=}\Varid{mkz}_{\mathrm{2}}\mathbin{\circ}\Varid{mkz}_{\mathrm{1}}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\Varid{build\char95 fold}\;\Varid{f}_{\mathrm{1}}\;\Varid{z\char95 1}\;\Varid{xs}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{minipage}\\
\caption{The Deforestation optimization. \\
         The lambda in the build rule is a call to a known function.\\
         The lets are added to keep the expression in A-Normal Form.\\
         The expression \ensuremath{\Varid{e}\mid \Varid{cond}\Rrightarrow \Varid{e'}} should be read as
         ``\ensuremath{\Varid{e}} rewrites to \ensuremath{\Varid{e'}} given that \ensuremath{\Varid{cond}} holds.''}
\label{fig:deforest}
\end{figure}


\begin{figure}\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;\Varid{v}_{\mathrm{1}}\mathrel{=}\boxed{\Varid{enumFromTo}\;\mathrm{2}\;\Varid{n}}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\mathbf{let}\;\Varid{v}_{\mathrm{2}}\mathrel{=}\boxed{\Varid{filter}\;\Varid{isPrime}\;\Varid{v}_{\mathrm{1}}}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\boxed{\Varid{sum}\;\Varid{v}_{\mathrm{2}}}{}\<[E]%
\\
\>[3]{}\Rrightarrow \textbf{Reduce Useful}{}\<[E]%
\\
\>[3]{}\mathbf{let}\;\Varid{v}_{\mathrm{1}}\mathrel{=}\Varid{build}\;\Varid{enumFromTo\char95 build}\;\mathrm{2}\;\Varid{n}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\mathbf{let}\;\Varid{v}_{\mathrm{2}}\mathrel{=}\Varid{build\char95 fold}\;(\Varid{filter\char95 mkf}\;\Varid{isPrime})\;\Varid{id}\;\Varid{v}_{\mathrm{1}}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\Varid{foldr}\;(\mathbin{+})\;\mathrm{0}\;\boxed{\Varid{v}_{\mathrm{2}}}{}\<[E]%
\\
\>[3]{}\Rrightarrow \textbf{Inline foldr/build\_fold}{}\<[E]%
\\
\>[3]{}\mathbf{let}\;\Varid{v}_{\mathrm{1}}\mathrel{=}\Varid{build}\;\Varid{enumFromTo\char95 build}\;\mathrm{2}\;\Varid{n}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\mathbf{let}\;\Varid{v}_{\mathrm{2}}\mathrel{=}\Varid{build\char95 fold}\;(\Varid{filter\char95 mkf}\;\Varid{isPrime})\;\Varid{id}\;\Varid{v}_{\mathrm{1}}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\boxed{\Varid{foldr}\;(\mathbin{+})\;\mathrm{0}\;(\Varid{build\char95 fold}\;(\Varid{filter\char95 mkf}\;\Varid{isPrime})\;\Varid{id}\;\Varid{v}_{\mathrm{1}})}{}\<[E]%
\\
\>[3]{}\Rrightarrow \textbf{Deforest foldr/build\_fold}{}\<[E]%
\\
\>[3]{}\mathbf{let}\;\Varid{v}_{\mathrm{1}}\mathrel{=}\Varid{build}\;\Varid{enumFromTo\char95 build}\;\mathrm{2}\;\Varid{n}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\mathbf{let}\;\Varid{v}_{\mathrm{2}}\mathrel{=}\Varid{build\char95 fold}\;(\Varid{filter\char95 mkf}\;\Varid{isPrime})\;\Varid{id}\;\Varid{v}_{\mathrm{1}}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\mathbf{let}\;\Varid{z}\mathrel{=}\Varid{id}\;\mathrm{0}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\mathbf{let}\;\Varid{f}\mathrel{=}\Varid{filter\char95 mkf}\;\Varid{isPrime}\;(\mathbin{+}){}\<[E]%
\\
\>[3]{}\mathbf{in}\;\Varid{foldr}\;\Varid{f}\;\Varid{z}\;\boxed{\Varid{v}_{\mathrm{1}}}{}\<[E]%
\\
\>[3]{}\Rrightarrow \textbf{Inline foldr/build}{}\<[E]%
\\
\>[3]{}\mathbf{let}\;\Varid{v}_{\mathrm{1}}\mathrel{=}\Varid{build}\;\Varid{enumFromTo\char95 build}\;\mathrm{2}\;\Varid{n}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\mathbf{let}\;\Varid{v}_{\mathrm{2}}\mathrel{=}\Varid{build\char95 fold}\;(\Varid{filter\char95 mkf}\;\Varid{isPrime})\;\Varid{id}\;\Varid{v}_{\mathrm{1}}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\mathbf{let}\;\Varid{z}\mathrel{=}\Varid{id}\;\mathrm{0}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\mathbf{let}\;\Varid{f}\mathrel{=}\Varid{filter\char95 mkf}\;\Varid{isPrime}\;(\mathbin{+}){}\<[E]%
\\
\>[3]{}\mathbf{in}\;\boxed{\Varid{foldr}\;\Varid{f}\;\Varid{z}\;(\Varid{build}\;\Varid{enumFromTo\char95 build}\;\mathrm{2}\;\Varid{n})}{}\<[E]%
\\
\>[3]{}\Rrightarrow \textbf{Deforest foldr/build}{}\<[E]%
\\
\>[3]{}\mathbf{let}\;\boxed{\Varid{v}_{\mathrm{1}}\mathrel{=}\Varid{build}\;\Varid{enumFromTo\char95 build}\;\mathrm{2}\;\Varid{n}}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\mathbf{let}\;\boxed{\Varid{v}_{\mathrm{2}}\mathrel{=}\Varid{build\char95 fold}\;(\Varid{filter\char95 mkf}\;\Varid{isPrime})\;\Varid{id}\;\Varid{v}_{\mathrm{1}}}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\mathbf{let}\;\Varid{z}\mathrel{=}\Varid{id}\;\mathrm{0}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\mathbf{let}\;\Varid{f}\mathrel{=}\Varid{filter\char95 mkf}\;\Varid{isPrime}\;(\mathbin{+}){}\<[E]%
\\
\>[3]{}\mathbf{in}\;\Varid{enumFromTo\char95 build}\;\mathrm{2}\;\Varid{n}\;\Varid{f}\;\Varid{z}{}\<[E]%
\\
\>[3]{}\Rrightarrow \textbf{Dead Code}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\mathbf{let}\;\Varid{z}\mathrel{=}\Varid{id}\;\mathrm{0}{}\<[E]%
\\
\>[3]{}\mathbf{in}\;\mathbf{let}\;\Varid{f}\mathrel{=}\Varid{filter\char95 mkf}\;\Varid{isPrime}\;(\mathbin{+}){}\<[E]%
\\
\>[3]{}\mathbf{in}\;\Varid{enumFromTo\char95 build}\;\mathrm{2}\;\Varid{n}\;\Varid{f}\;\Varid{z}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\caption{Derivation for \ensuremath{\Varid{sumPrimes}}}
\label{fig:sumOpt}
\end{figure}

So far we've done a decent job.
It's not as efficient as the Haskell version,
but that's not surprising.
However, we can still improve this.
The main problem here is that we can't optimize a partial application.
This is unfortunate, because the \ensuremath{\Varid{build\char95 fold}}
function tends to create large expressions of partially applied functions.
Fortunately we've already solved this problem earlier in our compiler.
We already have a way to detect if an expression is partially applied,
so, in the post processing phase, we do a scan for any partially applied functions.
If we find one, then we move the code into a newly created function, and attempt to optimize it.
We call this function outlining, since it's the opposite of inlining.
If we can't optimize the outlined function, then we do nothing.
Otherwise, we make a new function, and replace the call to the partially applied function
with a call to the outlined function.
This would actually be worth doing even if we didn't implement Deforestation.
With function outlining our final optimized code is given below.
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{4}{@{}>{\hspre}l<{\hspost}@{}}%
\column{17}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{sumPrimes}\;\Varid{n}\mathrel{=}\Varid{enumFromTo\char95 build}\;\mathrm{2}\;\Varid{n}\;\Varid{f'}\;\mathrm{0}{}\<[E]%
\\[\blanklineskip]%
\>[3]{}\Varid{f'}\;\Varid{x}\;\Varid{y}\mathrel{=}\mathbf{if}\;\Varid{isPrime}\;\Varid{x}\;\mathbf{then}\;\Varid{x}\mathbin{+}\Varid{y}\;\mathbf{else}\;\Varid{y}{}\<[E]%
\\[\blanklineskip]%
\>[3]{}\Varid{enumFromTo\char95 build}\;\Varid{a}\;\Varid{b}\;\Varid{c}\;\Varid{n}{}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mid \Varid{a}\mathbin{>}\Varid{b}{}\<[17]%
\>[17]{}\mathrel{=}\Varid{n}{}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mid \Varid{otherwise}{}\<[17]%
\>[17]{}\mathrel{=}\Varid{a}\mathbin{`\Varid{c}`}\Varid{enumFromTo\char95 build}\;(\Varid{a}\mathbin{+}\mathrm{1})\;\Varid{b}\;\Varid{c}\;\Varid{n}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
This certainly isn't perfect, but it's much closer to what we were hoping for.
Combining this with Unboxing and Shortcutting gives us some very efficient code.
While these results are very promising, we still need to know if Deforestation is even valid for Curry.

\subsection{Correctness}
First we show that the \ensuremath{\Varid{build\char95 fold}} theorems are valid for a deterministic subset of Curry
using the same reasoning as the original foldr-build rule.
Without non-determinism and free variables, we can apply the same arguments as the original paper
on shortcut deforestation \cite{shortcutDeforestation}.

\begin{theorem}
For any deterministic \ensuremath{\Varid{f}}, \ensuremath{\Varid{z}}, \ensuremath{\Varid{g}}, \ensuremath{\Varid{mkf}}, and \ensuremath{\Varid{mkz}},
the following equations hold.\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{build\char95 fold}\;\Varid{mkf}\;\Varid{mkz}\;(\Varid{build}\;\Varid{g})\mathrel{=}\Varid{build}\;(\lambda \Varid{c}\;\Varid{n}\to \Varid{g}\;(\Varid{mkf}\;\Varid{c})\;(\Varid{mkz}\;\Varid{n})){}\<[E]%
\\
\>[3]{}\Varid{foldr}\;\Varid{f}\;\Varid{z}\;(\Varid{build\char95 fold}\;\Varid{mkf}\;\Varid{mkz}\;\Varid{xs})\mathrel{=}\Varid{foldr}\;(\Varid{mkf}\;\Varid{f})\;(\Varid{mkz}\;\Varid{z})\;\Varid{xs}{}\<[E]%
\\
\>[3]{}\Varid{build\char95 fold}\;\Varid{mkf}_{\mathrm{1}}\;\Varid{mkz}_{\mathrm{1}}\;(\Varid{build\char95 fold}\;\Varid{mkf}_{\mathrm{2}}\;\Varid{mkz}_{\mathrm{2}}\;\Varid{xs})\mathrel{=}\Varid{build\char95 fold}\;(\Varid{mkf}_{\mathrm{2}}\mathbin{\circ}\Varid{mkf}_{\mathrm{1}})\;(\Varid{mkz}_{\mathrm{2}}\mathbin{\circ}\Varid{mkz}_{\mathrm{1}})\;\Varid{xs}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{theorem}

\begin{proof}
Recall that the free theorem\cite{theoremsForFree} for \ensuremath{\Varid{build}}
is for all \ensuremath{\Varid{h}}, \ensuremath{\Varid{f}}, and \ensuremath{\Varid{f'}} of the appropriate type:\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}(\forall \;(\Varid{a}\mathbin{:}\Conid{A})\;(\forall \;(\Varid{b}\mathbin{:}\Conid{B})\;\Varid{h}\;(\Varid{f}\;\Varid{a}\;\Varid{b})\mathrel{=}\Varid{f'}\;\Varid{a}\;(\Varid{h}\;\Varid{b})))\Rightarrow {}\<[E]%
\\
\>[3]{}\forall \;(\Varid{b}\mathbin{:}\Conid{B})\;\Varid{h}\;(\Varid{g}_{\Conid{B}}\;\Varid{f}\;\Varid{b})\mathrel{=}\Varid{g}_{\Conid{B}}'\;\Varid{f'}\;(\Varid{h}\;\Varid{b}){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
We substitute \ensuremath{\Varid{build\char95 fold}\;\Varid{mkf}\;\Varid{mkz}} for \ensuremath{\Varid{h}}, \ensuremath{(\mathbin{:})} for \ensuremath{\Varid{f}} and \ensuremath{\Varid{mkf}\;(\mathbin{:})} for \ensuremath{\Varid{f'}}.
From the definition of \ensuremath{\Varid{build\char95 fold}} we have
\ensuremath{\Varid{build\char95 fold}\;\Varid{mkf}\;\Varid{mkz}\;(\Varid{a}\mathbin{:}\Varid{b})\mathrel{=}(\Varid{mkf}\;(\mathbin{:}))\;\Varid{a}\;(\Varid{build\char95 fold}\;\Varid{mkf}\;\Varid{mkz}\;\Varid{b})}\\
and \ensuremath{\Varid{build\char95 fold}\;\Varid{mkf}\;\Varid{mkz}\;[\mskip1.5mu \mskip1.5mu]\mathrel{=}\Varid{mkz}\;[\mskip1.5mu \mskip1.5mu]}.
Therefore we have \ensuremath{\Varid{build\char95 fold}\;\Varid{mkf}\;\Varid{mkz}\;(\Varid{g}\;(\mathbin{:})\;\Varid{b})\mathrel{=}\Varid{g}\;(\Varid{mkf}\;(\mathbin{:}))\;(\Varid{build\char95 fold}\;\Varid{mkf}\;\Varid{mkz}\;\Varid{b})}\\
This gives us the following result.\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{build\char95 fold}\;\Varid{mkf}\;\Varid{mkz}\;(\Varid{build}\;\Varid{g})\mathrel{=}\Varid{g}\;(\Varid{mkf}\;(\mathbin{:}))\;(\Varid{mkz}\;[\mskip1.5mu \mskip1.5mu]){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
Finally, working backwards from the definition of \ensuremath{\Varid{build}} we have our theorem.\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{build\char95 fold}\;\Varid{mkf}\;\Varid{mkz}\;(\Varid{build}\;\Varid{g})\mathrel{=}\Varid{build}\;(\lambda \Varid{c}\;\Varid{n}\to \Varid{g}\;(\Varid{mkf}\;\Varid{c})\;(\Varid{mkz}\;\Varid{n})){}\<[E]%
\ColumnHook
\end{hscode}\resethooks

\noindent
Again with \ensuremath{\Varid{foldr}} we have the free theorem\\
if \ensuremath{\forall \;(\Varid{a}\mathbin{:}\Conid{A})\;(\forall \;(\Varid{b}\mathbin{:}\Conid{B})\;\Varid{b}\;(\Varid{x}\;\oplus\;\Varid{y})\mathrel{=}(\Varid{a}\;\Varid{x})\;\otimes\;(\Varid{b}\;\Varid{y})} and \ensuremath{\Varid{b}\;\Varid{u}\mathrel{=}\Varid{u'}}\\
then \ensuremath{\Varid{b}\mathbin{\circ}\Varid{fold}\;\oplus\;\Varid{u}\mathrel{=}\Varid{fold}\;\otimes\;\Varid{u'}\mathbin{\circ}(\Varid{map}\;\Varid{a})}\\
Here we take \ensuremath{\Varid{b}\mathrel{=}\Varid{build\char95 fold}\;\Varid{mkf}\;\Varid{mkz}}, \ensuremath{\oplus\mathrel{=}\Varid{f}}, and \ensuremath{\otimes\mathrel{=}\Varid{mkf}\;\Varid{f}} \ensuremath{\Varid{a}\mathrel{=}\Varid{id}}\\
then the statment becomes:\\
$\ $\\
if \ensuremath{\Varid{build\char95 fold}\;\Varid{mkf}\;\Varid{mkz}\;(\Varid{f}\;\Varid{x}\;\Varid{y})\mathrel{=}(\Varid{mkf}\;\Varid{f})\;\Varid{x}\;(\Varid{build\char95 fold}\;\Varid{mkf}\;\Varid{mkz}\;\Varid{y})}\\
and \ensuremath{\Varid{build\char95 fold}\;\Varid{mkf}\;\Varid{mkz}\;[\mskip1.5mu \mskip1.5mu]\mathrel{=}\Varid{mkz}\;[\mskip1.5mu \mskip1.5mu]}\\
then \ensuremath{\Varid{build\char95 fold}\;\Varid{mkf}\;\Varid{mkz}\mathbin{\circ}\Varid{fold}\;\Varid{f}\;\Varid{z}\mathrel{=}\Varid{fold}\;(\Varid{mkf}\;\Varid{f})\;(\Varid{mkz}\;\Varid{z})}\\
$\ $\\
Since both conditions follow directly from the definition of \ensuremath{\Varid{build\char95 fold}} we are left with\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{build\char95 fold}\;\Varid{mkf}\;\Varid{mkz}\mathbin{\circ}\Varid{fold}\;\Varid{f}\;\Varid{z}\mathrel{=}\Varid{fold}\;(\Varid{mkf}\;\Varid{f})\;(\Varid{mkz}\;\Varid{z}){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
which is exactly what we wanted.
Free theorems are fun!\\


\noindent
Finally for \ensuremath{\Varid{build\char95 fold}\mathbin{/}\Varid{build\char95 fold}} rule
suppose we have the expression\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{foldr}\;\Varid{f}\;\Varid{z}\;(\Varid{build\char95 fold}\;\Varid{mkf}_{\mathrm{1}}\;\Varid{mkz}_{\mathrm{1}}\;(\Varid{build\char95 fold}\;\Varid{mkf}_{\mathrm{2}}\;\Varid{mkz}_{\mathrm{2}}\;\Varid{xs})){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
From the previous result we have:\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{foldr}\;(\Varid{mkf}_{\mathrm{1}}\;\Varid{f})\;(\Varid{mkz}_{\mathrm{1}}\;\Varid{z})\;(\Varid{build\char95 fold}\;\Varid{mkf}_{\mathrm{2}}\;\Varid{mkz}_{\mathrm{2}}\;\Varid{xs}){}\<[E]%
\\
\>[3]{}\mathrel{=}\Varid{foldr}\;(\Varid{mkf}_{\mathrm{2}}\;(\Varid{mkf}_{\mathrm{1}}\;\Varid{f}))\;(\Varid{mkz}_{\mathrm{2}}\;(\Varid{mkz}_{\mathrm{1}}\;\Varid{z}))\;\Varid{xs}{}\<[E]%
\\
\>[3]{}\mathrel{=}\Varid{foldr}\;((\Varid{mkf}_{\mathrm{2}}\mathbin{\circ}\Varid{mkf}_{\mathrm{1}})\;\Varid{f})\;((\Varid{mkz}_{\mathrm{2}}\mathbin{\circ}\Varid{mkz}_{\mathrm{1}})\;\Varid{z})\;\Varid{xs}{}\<[E]%
\\
\>[3]{}\mathrel{=}\Varid{foldr}\;\Varid{f}\;\Varid{z}\;(\Varid{build\char95 fold}\;(\Varid{mkf}_{\mathrm{2}}\mathbin{\circ}\Varid{mkf}_{\mathrm{1}})\;(\Varid{mkz}_{\mathrm{2}}\mathbin{\circ}\Varid{mkz}_{\mathrm{1}})\;\Varid{xs}){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
which establishes our result:\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{build\char95 fold}\;\Varid{mkf}_{\mathrm{1}}\;\Varid{mkz}_{\mathrm{1}}\;(\Varid{build\char95 fold}\;\Varid{mkf}_{\mathrm{2}}\;\Varid{mkz}_{\mathrm{2}})\mathrel{=}\Varid{build\char95 fold}\;(\Varid{mkf}_{\mathrm{2}}\mathbin{\circ}\Varid{mkf}_{\mathrm{1}})\;(\Varid{mkz}_{\mathrm{2}}\mathbin{\circ}\Varid{mkz}_{\mathrm{1}}){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{proof}

While this gives us confidence that Deforestation is a possible optimization,
we've already seen that referential transparency \cite{whyFPmatters}, 
and therefore equational reasoning, doesn't always apply in Curry.
We need to show that both expressions will evaluate to the same set of values in
any contest.
In fact, as they are currently stated, 
These theorems don't actually hold for Curry.
However, with a few assumptions, we can remedy this problem.
First, we need to rewrite our rules so that the reduced expression is in A-Normal form.
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{35}{@{}>{\hspre}l<{\hspost}@{}}%
\column{40}{@{}>{\hspre}l<{\hspost}@{}}%
\column{45}{@{}>{\hspre}l<{\hspost}@{}}%
\column{54}{@{}>{\hspre}l<{\hspost}@{}}%
\column{57}{@{}>{\hspre}l<{\hspost}@{}}%
\column{59}{@{}>{\hspre}l<{\hspost}@{}}%
\column{62}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{build\char95 fold}\;\Varid{mkf}\;\Varid{mkz}\;(\Varid{build}\;\Varid{g})\mathrel{=}{}\<[35]%
\>[35]{}\mathbf{let}\;\Varid{g'}\mathrel{=}(\lambda \Varid{c}\;\Varid{n}\to {}\<[54]%
\>[54]{}\mathbf{let}\;{}\<[59]%
\>[59]{}\Varid{f}\mathrel{=}\Varid{mkf}\;\Varid{c}{}\<[E]%
\\
\>[59]{}\Varid{z}\mathrel{=}\Varid{mkz}\;\Varid{n}{}\<[E]%
\\
\>[54]{}\mathbf{in}\;{}\<[59]%
\>[59]{}\Varid{g}\;\Varid{f}\;\Varid{z}){}\<[E]%
\\
\>[35]{}\mathbf{in}\;\Varid{build}\;\Varid{g'}{}\<[E]%
\\
\>[3]{}\Varid{foldr}\;\Varid{f}\;\Varid{z}\;(\Varid{build\char95 fold}\;\Varid{mkf}\;\Varid{mkz}\;\Varid{xs})\mathrel{=}{}\<[40]%
\>[40]{}\mathbf{let}\;{}\<[45]%
\>[45]{}\Varid{f'}\mathrel{=}\Varid{mkf}\;\Varid{f}{}\<[E]%
\\
\>[45]{}\Varid{z'}\mathrel{=}\Varid{mkz}\;\Varid{z}{}\<[E]%
\\
\>[40]{}\mathbf{in}\;{}\<[45]%
\>[45]{}\Varid{foldr}\;\Varid{f'}\;\Varid{z'}\;\Varid{xs}{}\<[E]%
\\
\>[3]{}\Varid{build\char95 fold}\;\Varid{mkf}_{\mathrm{1}}\;\Varid{mkz}_{\mathrm{1}}\;(\Varid{build\char95 fold}\;\Varid{mkf}_{\mathrm{2}}\;\Varid{mkz}_{\mathrm{2}}\;\Varid{xs})\mathrel{=}{}\<[57]%
\>[57]{}\mathbf{let}\;{}\<[62]%
\>[62]{}\Varid{mkf}\mathrel{=}\Varid{mkf}_{\mathrm{2}}\mathbin{\circ}\Varid{mkf}_{\mathrm{1}}{}\<[E]%
\\
\>[62]{}\Varid{mkz}\mathrel{=}\Varid{mkz}_{\mathrm{2}}\mathbin{\circ}\Varid{mkz}_{\mathrm{1}}{}\<[E]%
\\
\>[57]{}\mathbf{in}\;{}\<[62]%
\>[62]{}\Varid{build\char95 fold}\;\Varid{mkf}\;\Varid{mkz}\;\Varid{xs}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
Now we are ready to state our result.
\begin{theorem}
suppose \ensuremath{\Varid{f}}, \ensuremath{\Varid{z}}, \ensuremath{\Varid{g}}, \ensuremath{\Varid{mkf}}, and \ensuremath{\Varid{mkz}} are all FlatCurry functions
who's right had side is an expression in A-Normal form,
then the following equations are valid.\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{35}{@{}>{\hspre}l<{\hspost}@{}}%
\column{40}{@{}>{\hspre}l<{\hspost}@{}}%
\column{45}{@{}>{\hspre}l<{\hspost}@{}}%
\column{54}{@{}>{\hspre}l<{\hspost}@{}}%
\column{57}{@{}>{\hspre}l<{\hspost}@{}}%
\column{59}{@{}>{\hspre}l<{\hspost}@{}}%
\column{62}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{build\char95 fold}\;\Varid{mkf}\;\Varid{mkz}\;(\Varid{build}\;\Varid{g})\mathrel{=}{}\<[35]%
\>[35]{}\mathbf{let}\;\Varid{g'}\mathrel{=}(\lambda \Varid{c}\;\Varid{n}\to {}\<[54]%
\>[54]{}\mathbf{let}\;{}\<[59]%
\>[59]{}\Varid{f}\mathrel{=}\Varid{mkf}\;\Varid{c}{}\<[E]%
\\
\>[59]{}\Varid{z}\mathrel{=}\Varid{mkz}\;\Varid{n}{}\<[E]%
\\
\>[54]{}\mathbf{in}\;{}\<[59]%
\>[59]{}\Varid{g}\;\Varid{f}\;\Varid{z}){}\<[E]%
\\
\>[35]{}\mathbf{in}\;\Varid{build}\;\Varid{g'}{}\<[E]%
\\
\>[3]{}\Varid{foldr}\;\Varid{f}\;\Varid{z}\;(\Varid{build\char95 fold}\;\Varid{mkf}\;\Varid{mkz}\;\Varid{xs})\mathrel{=}{}\<[40]%
\>[40]{}\mathbf{let}\;{}\<[45]%
\>[45]{}\Varid{f'}\mathrel{=}\Varid{mkf}\;\Varid{f}{}\<[E]%
\\
\>[45]{}\Varid{z'}\mathrel{=}\Varid{mkz}\;\Varid{z}{}\<[E]%
\\
\>[40]{}\mathbf{in}\;{}\<[45]%
\>[45]{}\Varid{foldr}\;\Varid{f'}\;\Varid{z'}\;\Varid{xs}{}\<[E]%
\\
\>[3]{}\Varid{build\char95 fold}\;\Varid{mkf}_{\mathrm{1}}\;\Varid{mkz}_{\mathrm{2}}\;(\Varid{build\char95 fold}\;\Varid{mkf}_{\mathrm{2}}\;\Varid{mkz}_{\mathrm{2}}\;\Varid{xs})\mathrel{=}{}\<[57]%
\>[57]{}\mathbf{let}\;{}\<[62]%
\>[62]{}\Varid{mkf}\mathrel{=}\Varid{mkf}_{\mathrm{2}}\mathbin{\circ}\Varid{mkf}_{\mathrm{1}}{}\<[E]%
\\
\>[62]{}\Varid{mkz}\mathrel{=}\Varid{mkz12}\mathbin{\circ}\Varid{mkz}_{\mathrm{1}}{}\<[E]%
\\
\>[57]{}\mathbf{in}\;{}\<[62]%
\>[62]{}\Varid{build\char95 fold}\;\Varid{mkf}\;\Varid{mkz}\;\Varid{xs}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{theorem}

\begin{proof}
We show the result for foldr-build, and the rest are similar calculations.
We intend to show that for any \ensuremath{\Varid{f}}, \ensuremath{\Varid{z}}, and \ensuremath{\Varid{g}} that the following equation holds.\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{fold}\;\Varid{f}\;\Varid{z}\;(\Varid{build}\;\Varid{g}\;(\mathbin{:})\;[\mskip1.5mu \mskip1.5mu])\mathrel{=}\Varid{g}\;\Varid{f}\;\Varid{z}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
That is, we show that \ensuremath{\Varid{fold}\;\Varid{f}\;\Varid{z}\;(\Varid{build}\;\Varid{g}\;(\mathbin{:})\;[\mskip1.5mu \mskip1.5mu])} reduces to the same values as
\ensuremath{\Varid{g}\;\Varid{f}\;\Varid{z}}.

We proceed in a manner similar to \cite{freeTheoremsCurry}.
First, notice that \ensuremath{\Varid{build}\;\Varid{g}\;(\mathbin{:})\;[\mskip1.5mu \mskip1.5mu]} is constructing a list.
However, since \ensuremath{\Varid{g}} is potentially non-deterministic, and it might fail,
we may have a non-deterministic alternation of lists when evaluating this expression.
Let's make this explicit.
After evaluating \ensuremath{\Varid{build}\;\Varid{g}\;(\mathbin{:})\;[\mskip1.5mu \mskip1.5mu]} we will produce an alternation of several lists.
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{19}{@{}>{\hspre}l<{\hspost}@{}}%
\column{21}{@{}>{\hspre}c<{\hspost}@{}}%
\column{21E}{@{}l@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{build}\;\Varid{g}\;(\mathbin{:})\;[\mskip1.5mu \mskip1.5mu]{}\<[19]%
\>[19]{}\mathrel{=}g_{1,1}\mathbin{:}g_{1,2}\mathbin{:}g_{1,3}\mathbin{:}\ldots end_1{}\<[E]%
\\
\>[19]{}\mathbin{?}g_{2,1}\mathbin{:}g_{2,2}\mathbin{:}g_{2,3}\mathbin{:}\ldots end_2{}\<[E]%
\\
\>[19]{}\hsindent{2}{}\<[21]%
\>[21]{}\ldots {}\<[21E]%
\\
\>[19]{}\mathbin{?}g_{k,1}\mathbin{:}g_{k,2}\mathbin{:}g_{k,3}\mathbin{:}\ldots end_k{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
Where, for all \ensuremath{\Varid{i}}, \ensuremath{end_i\mathrel{=}[\mskip1.5mu \mskip1.5mu]\mathbin{?}\bot }.

Here we have a alternation of \ensuremath{\Varid{k}} lists,
and each list ends either with the empty list, or the computation may have failed along the way.
Therefore, \ensuremath{end_i} may be either \ensuremath{[\mskip1.5mu \mskip1.5mu]} or \ensuremath{\bot }.
In fact, it might be the case that an entire list is \ensuremath{\bot },
but this is fine, because that would still fit this form defined above.

We can generalize this by passing arbitrary arguments to build.
The expression \ensuremath{\Varid{build}\;\Varid{g} \oplus \Varid{z}} evaluates to the following alternation of values.\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{5}{@{}>{\hspre}c<{\hspost}@{}}%
\column{5E}{@{}l@{}}%
\column{8}{@{}>{\hspre}l<{\hspost}@{}}%
\column{9}{@{}>{\hspre}c<{\hspost}@{}}%
\column{9E}{@{}l@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{build}\;\Varid{g} \oplus \Varid{z}{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mathrel{=}{}\<[5E]%
\>[8]{}(g_{1,1} \oplus g_{1,2} \oplus g_{1,3} \oplus \ldots \Varid{z}_{end_1})\mathbin{?}{}\<[E]%
\\
\>[8]{}(g_{2,1} \oplus g_{2,2} \oplus g_{2,3} \oplus \ldots \Varid{z}_{end_2})\mathbin{?}{}\<[E]%
\\
\>[8]{}\hsindent{1}{}\<[9]%
\>[9]{}\ldots {}\<[9E]%
\\
\>[8]{}(g_{k,1} \oplus g_{k,2} \oplus g_{k,3} \oplus \ldots \Varid{z}_{end_k}){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
Where, for all \ensuremath{\Varid{i}}, \ensuremath{\Varid{z}_{end_i}} is \ensuremath{\bot } if \ensuremath{end_i} is \ensuremath{\bot } and \ensuremath{\Varid{z}} otherwise.

Now, let's see what happens when we normalize the entire expression.
Recall that if \ensuremath{\Varid{f}} is a dominator of \ensuremath{\Varid{a}\mathbin{?}\Varid{b}}, then \ensuremath{\Varid{f}\;(\Varid{a}\mathbin{?}\Varid{b})\mathrel{=}\Varid{f}\;\Varid{a}\mathbin{?}\Varid{f}\;\Varid{b}} \cite{bubbling}.
Therefore if all arguments are in A-Normal form, then function application distributes over choice.
Since \ensuremath{\Varid{foldr}} is a dominator of everything in \ensuremath{\Varid{foldr} \oplus \Varid{z}\;(\Varid{build}\;\Varid{g}\;(\mathbin{:})\;[\mskip1.5mu \mskip1.5mu]} we have the following
derivation.
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{5}{@{}>{\hspre}c<{\hspost}@{}}%
\column{5E}{@{}l@{}}%
\column{8}{@{}>{\hspre}l<{\hspost}@{}}%
\column{9}{@{}>{\hspre}c<{\hspost}@{}}%
\column{9E}{@{}l@{}}%
\column{12}{@{}>{\hspre}l<{\hspost}@{}}%
\column{19}{@{}>{\hspre}l<{\hspost}@{}}%
\column{20}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{foldr} \oplus \Varid{z}\;(\Varid{build}\;\Varid{g}\;(\mathbin{:})\;[\mskip1.5mu \mskip1.5mu]){}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mathrel{=}{}\<[5E]%
\>[8]{}\mathbf{let}\;\Varid{fold}\mathrel{=}\Varid{foldr} \oplus \Varid{z}{}\<[E]%
\\
\>[8]{}\mathbf{in}\;\Varid{fold}\;(\Varid{build}\;\Varid{g}\;(\mathbin{:})\;[\mskip1.5mu \mskip1.5mu]){}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mathrel{=}{}\<[5E]%
\>[8]{}\mathbf{let}\;\Varid{fold}\mathrel{=}\Varid{foldr} \oplus \Varid{z}{}\<[E]%
\\
\>[8]{}\mathbf{in}\;\Varid{fold}\;({}\<[19]%
\>[19]{}g_{1,1}\mathbin{:}g_{1,2}\mathbin{:}g_{1,3}\mathbin{:}\ldots end_1\mathbin{?}{}\<[E]%
\\
\>[19]{}g_{2,1}\mathbin{:}g_{2,2}\mathbin{:}g_{2,3}\mathbin{:}\ldots end_2\mathbin{?}{}\<[E]%
\\
\>[19]{}\ldots {}\<[E]%
\\
\>[19]{}g_{k,1}\mathbin{:}g_{k,2}\mathbin{:}g_{k,3}\mathbin{:}\ldots end_k){}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mathrel{=}{}\<[5E]%
\>[8]{}\mathbf{let}\;\Varid{fold}\mathrel{=}\Varid{foldr} \oplus \Varid{z}{}\<[E]%
\\
\>[8]{}\mathbf{in}\;{}\<[12]%
\>[12]{}\Varid{fold}\;({}\<[20]%
\>[20]{}g_{1,1}\mathbin{:}g_{1,2}\mathbin{:}g_{1,3}\mathbin{:}\ldots end_1)\mathbin{?}{}\<[E]%
\\
\>[12]{}\Varid{fold}\;({}\<[20]%
\>[20]{}g_{2,1}\mathbin{:}g_{2,2}\mathbin{:}g_{2,3}\mathbin{:}\ldots end_2)\mathbin{?}{}\<[E]%
\\
\>[20]{}\ldots {}\<[E]%
\\
\>[12]{}\Varid{fold}\;({}\<[20]%
\>[20]{}g_{k,1}\mathbin{:}g_{k,2}\mathbin{:}g_{k,3}\mathbin{:}\ldots end_k){}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mathrel{=}{}\<[5E]%
\>[8]{}(g_{1,1} \oplus g_{1,2} \oplus g_{1,3} \oplus \ldots \Varid{z}_{end_1})\mathbin{?}{}\<[E]%
\\
\>[8]{}(g_{2,1} \oplus g_{2,2} \oplus g_{2,3} \oplus \ldots \Varid{z}_{end_2})\mathbin{?}{}\<[E]%
\\
\>[8]{}\hsindent{1}{}\<[9]%
\>[9]{}\ldots {}\<[9E]%
\\
\>[8]{}(g_{k,1} \oplus g_{k,2} \oplus g_{k,3} \oplus \ldots \Varid{z}_{end_k}){}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mathrel{=}{}\<[5E]%
\>[8]{}\Varid{g} \oplus \Varid{z}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
Where, for all \ensuremath{\Varid{i}}, \ensuremath{\Varid{z}_{end_i}} is \ensuremath{\bot } if \ensuremath{end_i} is \ensuremath{\bot } and \ensuremath{\Varid{z}} otherwise.

This proves the result.

\end{proof}

Note that while this does prove the result, there are still some interesting points here.
First, we never made any assumptions about \ensuremath{\Varid{f}} or \ensuremath{\Varid{z}}.
In fact, we didn't really make any assumptions about \ensuremath{\Varid{g}},
but we did at least give an explicit form for its values.
This form is guaranteed by the type.
This line of reasoning looks like a promising direction
for future explorations into parametricity for functional-logic programming.

Second, it should be noted that branches in \ensuremath{\Varid{g}} that produce \ensuremath{\bot } don't necessarily
fail when evaluated.
If \ensuremath{\Varid{f}} is strict, then any failure in the list will cause the entire branch to fail.
Consider the following expression:\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{foldr}\;(\lambda \Varid{x}\;\Varid{y}\to \mathrm{1})\;\mathrm{0}\;(\Varid{build}\;(\lambda \Varid{c}\;\Varid{n}\to \mathrm{0}\mathbin{`\Varid{c}`}\mathrm{1}\mathbin{`\Varid{c}`}\bot )){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
Evaluating the expression rooted by \ensuremath{\Varid{build}} to constructor normal form would produce a failure,
since the tail of the list is \ensuremath{\bot }.
However, since the first parameter in the expression rooted by \ensuremath{\Varid{foldr}} 
never looks at either of it's arguments,
this branch of the computation can still return a result.


In this chapter we've developed three optimizations to help reduce the memory allocated by
Curry programs.
These optimizations seem effective, and we've shown why they're correct,
but we still need to find out how effective they are.
In the next chapter we show how well our compiler compares to 
Pakcs, Kics2, and MCC on the benchmarking suite provided by Kics2.
We also show the results for each optimization individually, and then combined.


\chapter{Results} \label{ch:Results}


Now that we've finally implemented all of the optimizations, we need
to see if they were actually effective.
Before we can look at the results, we need to discuss methodology.
The test suite is based on the test suite from the Kics2 compiler \cite{kics2}.
We've removed some tests, and added others in order to test specific properties
of our compiler.

Specifically, we removed all of the tests that evaluated the unification operator
\ensuremath{\cuUnify} or the functional pattern operator \ensuremath{\cuFunPat}.
While the \ricesp compiler does support these operations,
they are primitive operations with respect to Curry that can potentially
do a substantial amount of work.
This means that the operators are typically implemented in the target language
of the compiler.
While \ricesp does perform well with code containing these operators,
we felt that it was an unfair comparison.
It measured the implementation of the operators, instead of the quality of the generated code.

Furthermore, we added a few tests to demonstrate the effectiveness of deforestation.
The benchmark suite for Kics2 contained very few examples of code with multiple
list operations.

In order to characterize the effectiveness of our optimiztions,
we are interested in two measurements.
First, we want to show that the execution time of the programs is improved.
Second, we want to show that optimized programs consume less memory.
The second goal is very easy to achieve.
We simply augment the runtime system with a counter that we increment
every time we allocate memory.
When the program is finished running, we simply print out the number of
memory allocations.

Execution time turns out to be much more difficult to measure.
There are many factors which can affect the execution time of a program.
To help aliviate these problems, we took the approach outlined by Mytkowicz et al. \cite{wrongData}.
All programs were run multiple times, and compiled in multiple environments
for each compiler.  We took the lowest execution time.
We believe these results are as unbiased as we can hope for;
however, it is important to remember that our results may vary across machines and environments.
For most of our results the \ricesp compiler is a clear winner.


\section{Tests}

Our test suite is based on the Kics2 test suite \cite{kics2}.
We split the functions into three groups:
Numeric computations meant to test Unboxing;
non-deterministic computations;
and list computations meant to test Deforestation.
We don't have any specific tests for shortcutting, because it
applies in almost every program.

\begin{itemize}

\item \textbf{Numeric computations:}

\begin{itemize}
\item \textbf{fib} is the Fibonacci program from chapter 5.

\item \textbf{fibNondet} This is the same program, but we call it with a non-deterministic argument.

\item \textbf{tak} computes a long, mutually recursive, function with many numeric calculations.
\end{itemize}

\item \textbf{Non-deterministic computations:}

\begin{itemize}
\item \textbf{cent} attempts to find all expressions
containing the numbers 1 to 5 that evaluate to 100.

\item \textbf{half} computes half of a number defined using piano arithmetic by trial and error starting from 0.\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{4}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{half}\;\Varid{n}\mid \Varid{x}\mathbin{+}\Varid{x}\Varid{==}\Varid{n}\mathrel{=}\Varid{x}{}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mathbf{where}\;\Varid{x}\;\textbf{free} {}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\item \textbf{ndTest} computes a variant of \ensuremath{\Varid{fib}} that non-deterministically returns many results.\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{4}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{fib}\;\Varid{n}{}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mid \Varid{n}\mathbin{<}\mathrm{2}\mathrel{=}\mathrm{0}\mathbin{?}\mathrm{1}{}\<[E]%
\\
\>[3]{}\hsindent{1}{}\<[4]%
\>[4]{}\mid \Varid{otherwise}\mathrel{=}\Varid{fib}\;(\Varid{n}\mathbin{-}\mathrm{1})\mathbin{+}\Varid{fib}\;(\Varid{n}\mathbin{-}\mathrm{2}){}\<[E]%
\ColumnHook
\end{hscode}\resethooks

\item \textbf{perm} computes all of the permutations of a list
by computing a single permutation non-deterministically.

\item \textbf{queensPerm} is the program from the introduction.
It computes solutions to the n-queens problem
by permuting a list, and checking if it's a valid solution.

\item \textbf{primesort} non-deterministically sorts a list of very large prime numbers.

\item \textbf{sort} sorts a list by finding a sorted permutation.
\end{itemize}


\item \textbf{Deforestation:}

\begin{itemize}
\item \textbf{queensDet} computes solutions to the n-queens problem
using a backtracking solution and list comprehension.

\item \textbf{reverseBuiltin} reverses a list without using functions or data types
                                defined in the standard Prelude.

\item \textbf{reverseFoldr} reverses a list using a reverse function written as a fold.

\item \textbf{reversePrim} reverses a list using the built-in reverse function and primitive numbers.

\item \textbf{sumSquares} computes \ensuremath{\Varid{sum}\mathbin{\circ}\Varid{map}\;\Varid{sqaure}\mathbin{\circ}\Varid{filter}\;\Varid{odd}\mathbin{\circ}\Varid{enumFromTo}\;\mathrm{1}}.

\item \textbf{buildFold} computes a long chain of list processing functions.

\item \textbf{primes} computes a list of primes.

\item \textbf{sieve} computes \ensuremath{\Varid{sumPrimes}} from Chapter 5.
\end{itemize}

\end{itemize}


The results of running the tests are given in figure \ref{fig:time_rice} for timing,
and \ref{fig:memory} for memory.
All times are normalized.
In figure \ref{fig:time} the times are normalized to \rice,
and in figure \ref{fig:time_rice} all results normalized to the unoptimized version
in order to see the improvement of optimizations.
Memory results are measured in the number of allocations of nodes.
We also include a comparison all of 3 prominent Curry compilers, Pakcs, Kics2, and Mcc, against \ricesp
in figure \ref{fig:time}.
We optimized these compilers as much as possible to get the best results.
For example Kics2 executed much quicker when run in the primitive depth first search mode.
We increased the input size for tak, buildFold, and sieve in order to get a better comparison
with these compilers.
However, we were not able to run the buildFold test, or the reverseBuiltin test, for the Pakcs compiler. 
They were both killed by the Operating System before they could complete.
We timed every program with Kics2 \cite{kics2}, Pakcs \cite{pakcs}, and the Mcc \cite{mcc} compiler.
Unfortunately we were not able to get an accurate result on how much memory any of these compilers
allocated, so we were unable to compare our memory results.


%\begin{figure}
%\begin{tabular}{||||l||||r||r||r||r||||}
%\hhline{||||=||||=||=||=||=||||}
%                &  pakcs   & kics2 & mcc   & rice \\
%\hhline{||||=||||=||=||=||=||||}
%fib             &    30.24 &  0.06 &  0.03 & 0.00 \\
%\hline
%fibNondet       &    30.90 &  3.37 &  0.03 & 0.00 \\
%\hline
%tak             & 6,867.54 & 13.32 & 17.66 & 0.94 \\
%\hhline{||||=||||=||=||=||=||||}
%cent            &    65.63 & 26.74 &  0.28 & 0.43 \\
%\hline
%half            &   983.57 & 25.27 &  1.58 & 0.52 \\
%\hline
%ndtest          &   383.05 & 13.78 &  1.21 & 0.78 \\
%\hline
%perm            &    45.10 &  4.00 &  1.10 & 0.62 \\
%\hline
%queensPerm      &   568.81 &  2.98 &  0.11 & 0.11 \\
%\hline
%primesort       & 1,481.83 &  0.31 &  1.11 & 0.15 \\
%\hline
%sort            &   212.33 &  8.07 &  0.24 & 0.23 \\
%\hhline{||||=||||=||=||=||=||||}
%queensDet       &  1051.78 &  1.07 &  1.18 & 0.23 \\
%\hline
%reverseBuiltin  &      OoM &  0.79 &  0.44 & 0.28 \\
%\hline
%reverseFoldr    &   262.14 &  0.17 &  0.07 & 0.02 \\
%\hline
%reversePrim     &    27.96 &  0.18 &  0.05 & 0.02 \\
%\hline
%sumSquare       &    33.48 &  0.08 &  0.05 & 0.00 \\
%\hline
%buildFold       &      OoM & 13.98 &  5.16 & 0.58 \\
%\hline
%primes          & 6,480.61 & 31.36 &  7.52 & 0.62 \\
%\hline
%sieve           & 2,845.30 &  3.17 &  4.48 & 1.03 \\
%\hhline{||||=||||=||=||=||=||||}
%\end{tabular}
%
%\caption{Comparison of execution time for Pakcs, Kics2, Mcc, and \rice.\\
%         Time is measured in seconds.}
%\label{fig:time}
%\end{figure}
%
%\begin{figure}
%\begin{tabular}{||||l||||r||r||r||r||r||r||||}
%\hhline{||||=||||=||=||=||=||=||=||||}
%                &   unopt & basic & unbox & shortcut & deforest &  all \\
%\hhline{||||=||||=||=||=||=||=||=||||}
%fib             &    0.05 &  0.05 &  0.02 &     0.03 &     0.05 & 0.00 \\
%\hline
%fibNondet       &    0.05 &  0.04 &  0.02 &     0.04 &     0.06 & 0.00 \\
%\hline
%tak             &    2.15 &  2.02 &  0.52 &     0.70 &     2.07 & 0.16 \\
%\hhline{||||=||||=||=||=||=||=||=||||}
%cent            &    1.00 &  0.90 &  0.74 &     0.91 &     0.94 & 0.43 \\
%\hline
%half            &    0.88 &  0.84 &  0.83 &     0.95 &     0.79 & 0.52 \\
%\hline
%ndtest          &    1.53 &  1.31 &  1.31 &     1.12 &     1.28 & 0.78 \\
%\hline
%perm            &    0.82 &  0.83 &  0.81 &     0.85 &     0.82 & 0.62 \\
%\hline
%queensPerm      &    0.60 &  0.38 &  0.17 &     0.30 &     0.37 & 0.11 \\
%\hline
%primesort       &    0.40 &  0.29 &  0.22 &     0.23 &     0.31 & 0.15 \\
%\hline
%sort            &    0.61 &  0.40 &  0.34 &     0.40 &     0.43 & 0.23 \\
%\hhline{||||=||||=||=||=||=||=||=||||}
%queensDet       &    2.68 &  1.71 &  0.53 &     0.26 &     1.48 & 0.23 \\
%\hline
%reverseBuiltin  &    0.50 &  0.53 &  0.48 &     0.46 &     0.50 & 0.28 \\
%\hline
%reverseFoldr    &    0.06 &  0.08 &  0.03 &     0.07 &     0.07 & 0.02 \\
%\hline
%reversePrim     &    0.06 &  0.08 &  0.02 &     0.05 &     0.08 & 0.02 \\
%\hline
%sumSquare       &    0.08 &  0.09 &  0.02 &     0.04 &     0.06 & 0.00 \\
%\hline
%buildFold       &    2.84 &  2.31 &  1.59 &     2.15 &     1.24 & 0.23 \\
%\hline
%primes          &    1.96 &  1.45 &  0.97 &     1.18 &     1.48 & 0.62 \\
%\hline
%sieve           &    1.87 &  2.08 &  0.90 &     1.86 &     1.26 & 0.32 \\
%\hhline{||||=||||=||=||=||=||=||=||||}
%\end{tabular}
%
%\caption{Results for execution time between the \rice compiler at several levels of optimization.\\
%         \emph{unopt} is the compiler without optimizations,
%         \emph{basic} is the optimizations described in chapter \ref{ch:Basic Optimizations},
%         \emph{unbox} is the unboxing optimization,
%         \emph{shortcut} is the shortcutting optimization,
%         \emph{deforest} is the deforestation optimization,
%         and \emph{all} is the compiler with all optimizations turned on.}
%\label{fig:time_rice}
%\end{figure}
%
%\begin{figure}
%\begin{tabular}{||||l||||r||r||r||r||r||r||||}
%\hhline{||||=||||=||=||=||=||=||=||||}
%                &    unopt &    basic &   unbox &  shortcut &  deforest &     all \\
%\hhline{||||=||||=||=||=||=||=||=||||}
%fib             &   1,907K &   1,906K &    635K &    12,71K &    1,906K &       0 \\
%\hline
%fibNondet       &   1,907K &   1,906K &    635K &    12,71K &    1,906K &       5 \\
%\hline
%tak             &  94,785K &  94,784K & 28,435K &       267 &   94,784K &       0 \\
%\hhline{||||=||||=||=||=||=||=||=||||}
%cent            &  22,644K &  21,358K & 18,304K &   21,358K &   21,358K & 18,304K \\
%\hline
%half            &  25,165K &  25,179K & 25,120K &   25,164K &   25,179K & 25,120K \\
%\hline
%ndtest          &  14,282K &  14,282K & 17,005K &   14,282K &   14,282K & 17,005K \\
%\hline
%perm            &   2,041K &   2,041K &  2,041K &    2,041K &    2,041K &  2,041K \\
%\hline
%queensPerm      &  19,362K &  11,899K &  4,122K &    7,543K &   11,899K &  2,940K \\
%\hline
%primesort       &  10,546K &   8,458K &  6,344K &    6,375K &    8,454K &  6,340K \\
%\hline
%sort            &  20,295K &  14,332K & 11,949K &   11,949K &   14,332K & 11,949K \\
%\hhline{||||=||||=||=||=||=||=||=||||}
%queensDet       &  96,894K &  53,781K & 16,599K &   33,385K &   48,360K &  9,372K \\
%\hline
%reverseBuiltin  &  16,819K &  16,819K & 16,819K &   16,819K &   16,819K & 16,819K \\
%\hline
%reverseFoldr    &   2,883K &   3,407K &  1,572K &    3,145K &    3,145K &  1,310K \\
%\hline
%reversePrim     &   2,621K &   3,145K &  1,310K &    2,883K &    3,145K &  1,310K \\
%\hline
%sumSquare       &   2,500K &   2,899K &  1,199K &    2,499K &    2,499K &    599K \\
%\hline
%buildFold       & 120,000K &  99,999K & 71,999K &   95,999K &   67,999K &       3 \\
%\hline
%primes          &  40,705K &  32,589K & 24,442K &   24,477K &   32,585K & 24,438K \\
%\hline
%sieve           &  96,622K & 109,936K & 48,235K &  102,998K &   82,231K &     21K \\
%\hhline{||||=||||=||=||=||=||=||=||||}
%\end{tabular}
%\caption{Results for amount of memory consumed while running programs compiled at each optimization level.}
%\label{fig:memory}
%\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Normalized Figures
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{figure}
\begin{tabular}{||l||r|r|r|r||}
\hhline{||=||=|=|=|=||}
                &  pakcs   & kics2 & mcc   & rice \\
\hhline{||=||=|=|=|=||}
fib             &    2,945 &    16 &     7 &    1 \\
\hline
fibNondet       &    2,945 &   839 &     8 &    1 \\
\hline
tak             &    7,306 &    14 &    19 &    1 \\
\hhline{||=||=|=|=|=||}
cent            &      152 &    62 &  0.65 &    1 \\
\hline
half            &    1,891 &    49 &     3 &    1 \\
\hline
ndtest          &      491 &    18 &     2 &    1 \\
\hline
perm            &       73 &     6 &     2 &    1 \\
\hline
queensPerm      &     5171 &    27 &     1 &    1 \\
\hline
primesort       &    9,879 &     3 &     7 &    1 \\
\hline
sort            &      923 &    35 &     1 &    1 \\
\hhline{||=||=|=|=|=||}
queensDet       &     4573 &     5 &     5 &    1 \\
\hline
reverseBuiltin  & $\infty$ &     3 &     2 &    1 \\
\hline
reverseFoldr    &   13,107 &     8 &     4 &    1 \\
\hline
reversePrim     &    1,398 &     9 &     3 &    1 \\
\hline
sumSquare       &      140 &    10 &    22 &    1 \\
\hline
buildFold       & $\infty$ &    24 &     9 &    1 \\
\hline
primes          &   10,453 &    51 &    12 &    1 \\
\hline
sieve           &    2,762 &     3 &     4 &    1 \\
\hhline{||=||=|=|=|=||}
\end{tabular}

\caption{Comparison of execution time for Pakcs, Kics2, Mcc, and \rice.\\
         Time is measured in seconds.}
\label{fig:time}
\end{figure}

\begin{figure}
\begin{tabular}{||l||r|r|r|r|r|r||}
\hhline{||=||=|=|=|=|=|=||}
                &   unopt & basic & unbox & shortcut & deforest &  all \\
\hhline{||=||=|=|=|=|=|=||}
fib             &    1.00 &  0.94 &  0.34 &     0.75 &     1.00 & 0.13 \\
\hline
fibNondet       &    1.00 &  1.07 &  0.33 &     0.73 &     1.07 & 0.13 \\
\hline
tak             &    1.00 &  0.94 &  0.24 &     0.33 &     0.96 & 0.07 \\
\hhline{||=||=|=|=|=|=|=||}
cent            &    1.00 &  0.90 &  0.74 &     0.91 &     0.94 & 0.43 \\
\hline
half            &    1.00 &  0.95 &  0.94 &     1.08 &     0.90 & 0.59 \\
\hline
ndtest          &    1.00 &  0.86 &  0.86 &     0.73 &     0.84 & 0.51 \\
\hline
perm            &    1.00 &  1.01 &  0.99 &     1.04 &     1.00 & 0.76 \\
\hline
queensPerm      &    1.00 &  0.63 &  0.28 &     0.50 &     0.62 & 0.18 \\
\hline
primesort       &    1.00 &  0.72 &  0.55 &     0.58 &     0.77 & 0.37 \\
\hline
sort            &    1.00 &  0.66 &  0.56 &     0.66 &     0.70 & 0.38 \\
\hhline{||=||=|=|=|=|=|=||}
queensDet       &    1.00 &  0.64 &  0.20 &     0.10 &     0.55 & 0.08 \\
\hline
reverseBuiltin  &    1.00 &  1.06 &  0.96 &     0.92 &     1.00 & 0.56 \\
\hline
reverseFoldr    &    1.00 &  1.33 &  0.50 &     1.17 &     1.17 & 0.33 \\
\hline
reversePrim     &    1.00 &  1.33 &  0.33 &     0.83 &     1.33 & 0.33 \\
\hline
sumSquare       &    1.00 &  1.10 &  0.42 &     1.02 &     0.82 & 0.16 \\
\hline
buildFold       &    1.00 &  0.81 &  0.56 &     0.76 &     0.44 & 0.08 \\
\hline
primes          &    1.00 &  0.74 &  0.49 &     0.60 &     0.76 & 0.32 \\
\hline
sieve           &    1.00 &  1.11 &  0.48 &     0.99 &     0.67 & 0.17 \\
\hhline{||=||=|=|=|=|=|=||}
\end{tabular}

\caption{Results for execution time between the \rice compiler at several levels of optimization.\\
         \emph{unopt} is the compiler without optimizations,
         \emph{basic} is the optimizations described in chapter \ref{ch:Basic Optimizations},
         \emph{unbox} is the unboxing optimization,
         \emph{shortcut} is the shortcutting optimization,
         \emph{deforest} is the deforestation optimization,
         and \emph{all} is the compiler with all optimizations turned on.}
\label{fig:time_rice}
\end{figure}

\begin{figure}
\begin{tabular}{||l||r|r|r|r|r|r||}
\hhline{||=||=|=|=|=|=|=||}
                &    unopt &    basic &   unbox &  shortcut &  deforest &     all \\
\hhline{||=||=|=|=|=|=|=||}
fib             &   1,907K &   1,906K &    635K &    12,71K &    1,906K &       0 \\
\hline
fibNondet       &   1,907K &   1,906K &    635K &    12,71K &    1,906K &       5 \\
\hline
tak             &  94,785K &  94,784K & 28,435K &       267 &   94,784K &       0 \\
\hhline{||=||=|=|=|=|=|=||}
cent            &  22,644K &  21,358K & 18,304K &   21,358K &   21,358K & 18,304K \\
\hline
half            &  25,165K &  25,179K & 25,120K &   25,164K &   25,179K & 25,120K \\
\hline
ndtest          &  14,282K &  14,282K & 17,005K &   14,282K &   14,282K & 17,005K \\
\hline
perm            &   2,041K &   2,041K &  2,041K &    2,041K &    2,041K &  2,041K \\
\hline
queensPerm      &  19,362K &  11,899K &  4,122K &    7,543K &   11,899K &  2,940K \\
\hline
primesort       &  10,546K &   8,458K &  6,344K &    6,375K &    8,454K &  6,340K \\
\hline
sort            &  20,295K &  14,332K & 11,949K &   11,949K &   14,332K & 11,949K \\
\hhline{||=||=|=|=|=|=|=||}
queensDet       &  96,894K &  53,781K & 16,599K &   33,385K &   48,360K &  9,372K \\
\hline
reverseBuiltin  &  16,819K &  16,819K & 16,819K &   16,819K &   16,819K & 16,819K \\
\hline
reverseFoldr    &   2,883K &   3,407K &  1,572K &    3,145K &    3,145K &  1,310K \\
\hline
reversePrim     &   2,621K &   3,145K &  1,310K &    2,883K &    3,145K &  1,310K \\
\hline
sumSquare       &   2,500K &   2,899K &  1,199K &    2,499K &    2,499K &    599K \\
\hline
buildFold       & 120,000K &  99,999K & 71,999K &   95,999K &   67,999K &       3 \\
\hline
primes          &  40,705K &  32,589K & 24,442K &   24,477K &   32,585K & 24,438K \\
\hline
sieve           &  96,622K & 109,936K & 48,235K &  102,998K &   82,231K &     21K \\
\hhline{||=||=|=|=|=|=|=||}
\end{tabular}
\caption{Results for amount of memory consumed while running programs compiled at each optimization level.}
\label{fig:memory}
\end{figure}

There are a lot of interesting results in tables \ref{fig:time}, \ref{fig:time_rice}, and \ref{fig:memory}
that we feel are worth pointing out.
First, it should be noted that the Mcc compiler performed very well,
not only against both Kics2 and Pakcs, but it also performed well against \rice.
In most examples it was competitive with the unoptimized code, and ahead of it in several tests.
It even outperformed the optimized version in the cent example.
We are currently unsure of why this happened, but we have two theories.
First, the code generation and run-time system of Mcc may just be more efficient than \rice.
While we worked to make the run-time system as efficient as possible, 
it was not the focus of this compiler.
Mcc also translated the code to Continuation Passing Style \cite{continuationsAppel}
before generating target code.
This may be responsible for the faster execution times.
Our other theory is that Mcc supports an older version of Curry that does not include type classes.
Mcc may have performed better simply by not having to deal with that overhead.

Aside from the surprising performance of Mcc,
we found a couple of results in our optimizations that surprised us as well.
First, the \ensuremath{\Varid{half}} program used more memory with basic optimizations turned on
then it did with no optimizations.
This is because strictness analysis created a worker function, but it wasn't able to cancel
out any of the new \ensuremath{\Conid{Int}} constructors.
While this did cause memory usage to go up a little, it didn't effect the execution time.
However, we could disable strictness analysis unless unboxing is turned on.
Second, the \ensuremath{\Varid{ndtest}} used a bit (about 0.05\%) more memory with the unboxing optimization.
This is because of a confluence of two side effects of the optimization.
Without unboxing we can't determine that the parameters to primitive operations are
needed, so we can't force evaluation.
This means that instead of evaluating each piece of the Fibonacci function separately,
we need to construct the entire contractum \ensuremath{\Varid{fib}\;(\Varid{n}\mathbin{-}\mathrm{1})\mathbin{+}\Varid{fib}\;(\Varid{n}\mathbin{-}\mathrm{2})} and evaluate it.
Because of this, the optimized code only contains a single case expression.
The other factor is our solution to the non-determinism problem from section
\ref{Non-determinism}.
Since we are returning several results, and the unboxed \ensuremath{\Varid{fib}} function contains several cases,
we have to push more case functions onto the backtracking stack.
While this does allocate a little more memory, we believe that the 2x speed-up
in execution time is worth the sacrifice.

In terms of effectiveness, unboxing seemed to be the clear winner.
Deforestation did not seem to be nearly as effective, but we believe this
is more related to the test suite than anything else.
These are all small programs that don't include many list processing operations.
We believe that, on larger programs, deforestation would have more opportunities to fire.
Shortcutting typically performed well, and compensated for the lack of unboxing in several situations.
We think the most interesting part of these results is the effect of combining these optimizations.
In particular, unboxing and shortcutting work very well together, 
often reducing the amount of memory consumed more than either optimization alone.

Generally \ricesp compares very favorably with all of the current compilers,
only losing out to Mcc on the cent example.
We focus on the Kics2 compiler, because that was the best performing compiler
that is still in active development.
With this comparison \ricesp performs very well,
showing anywhere form a 2x to 50x execution speed-up on all of the non-deterministic programs,
and a 3x to 50x improvement on the deterministic programs.
Even comparing against Mcc, we typically see a 2x speed-up.
The only excepts are cent, and programs that cannot be optimized, such as perm.
We also see a very impressive speedup on \ensuremath{\Varid{fibNondet}} compared to Kics2.
However, this is a known issue with the evaluate of non-deterministic expressions
with functions with non-linear rules.
We do believe that this is important to note, because these programs are common in Curry,
and is the reason that we could not use Kics2 to develop \rice.

This is a very impressive speed-up, but we've already discussed the reason for it.
After we applied Unboxing and Shortcutting, we were able eliminate all
but a constant number of heap allocations from the program.
This would be a great result on it's own, but it gets even better when we compare it to GHC.
Compiling the same \ensuremath{\Varid{fib}} algorithm on GHC produced code
that ran about twice as fast as our optimized \ricesp code,
and when we turned off Optimizations for GHC we ran faster by a factor of 8.
It's not surprising to us that our code ran slower than GHC.
The run time system is likely much faster than ours,
and there are several optimization in GHC that we have not implemented.
In fact, we would be shocked if it managed to keep up.
What is surprising, and encouraging, is that we were competitive at all.
It suggests that Curry isn't inherently slower than Haskell.
We believe that a more mature Curry compiler could run as fast as GHC for deterministic functions.
This would give us the benefits of Curry, such as non-determinism and free variables,
without sacrificing the speed of modern functional languages.


In this chapter we've justified the benefit of these optimizations to Curry.
In the next chapter we look at possible future directions to take this work, and we conclude.



\chapter{Conclusion} \label{ch:Conclusion}




These results were honestly significantly better than we ever expected with this project.
Initially, we hoped to compete with Kics2, since it was leveraging GHC's optimizer
to produce efficient code.
However, we found that could we beat Kics2 in all cases,
and in many cases the results were simply incomparable.
In some cases we were even able to compete with GHC itself.
Furthermore, we've shown that the memory optimizations really were effective for Curry programs.
This isn't much of a surprise.
Allocating less memory is a good strategy for improving run-time performance.
It is good to know that the presence of non-determinism doesn't affect this commonly held belief.

It's a little more surprising that these optimizations all turned out to be valid in Curry.
In fact, a surprising number of optimizations are valid in Curry under suitable conditions.
This might not seem very significant until we look at what optimizations aren't valid.
For example, common sub-expression elimination was not included in this compiler,
because it simply isn't a valid Curry transformation.
It introduces sharing where none existed.
If the common sub-expression is non-deterministic, then we will change the set of results.
On the other hand, common sub-expression elimination is fairly innocuous in most other languages.

\subsection{Future Work}

Most curries are made from curry powder and coconut milk,
however our Curry was mostly made from low hanging fruit.
As nice as our results are,
we would like to see this work extended in the future.
We believe that a better inliner and strictness analyzer
would go a long way to producing even more efficient code.

In fact, a general theory of inlining in Curry would be hugely beneficial.
One of the biggest drawbacks to this compiler is that we can't represent 
lambda expressions in FlatCurry, and inline them.
Before we could even attempt this,
we would need to know when it's safe to inline a lambda in Curry.

We would also like to move from short-cut Deforestation to Stream Fusion.
This should be possible, but it would require a more sophisticated strictness analyzer,
and we may not be able to get away with our combinator approach.

We would also like to see the development of new, Curry specific, optimizations.
Right now the \ensuremath{\mathbin{?}} operator acts as a hard barrier.
We can move let-bound variables outside of it, but we can't move the choice itself.
However, there may be an option for using pull-tabbing or bubbling
to move the choice to make room for more optimizations.

For personal reasons we would also like to bootstrap \ricesp with itself.
This would significantly decrease the time it takes to compile large Curry programs.
Right now, \ricesp is compiled using Pakcs.
Currently Kics2 isn't a feasible option for compiling \rice,
because of performance issues with non-deterministic function.
So, compiling \ricesp in itself would significantly improve the performance of the compiler.

We would also like to move from C to LLVM.
This would allow for more optimizations including Tail Call Optimization.
We currently are limited by the recursion depth of the machine,
and TCO could allow us to compile more programs.
Moving to LLVM would also greatly help in the development of a garbage collector.

Finally, developing a better run-time system would also be an important improvement.
While we did work to make sure our run time system was efficient,
it could certainly be better.
Integrating this work with the Sprite \cite{sprite} compiler might solve this issue.

\subsection{Conclusion and Related Work}

We have presented the \ricesp Optimizing Curry compiler.
The compiler was primarily built to test the effectiveness of various optimizations on Curry programs.
While testing these optimizations, we've also built
an efficient evaluation method for backtracking Curry programs,
as well as a general system for describing and implementing optimizations.
The compiler itself is written in Curry.

This system incorporated a lot of work from the functional language community,
and the Haskell community in particular.
The work on general optimizations \cite{haskellOpt}, 
Inlining \cite{haskellInliner}, Unboxing \cite{unboxing},
Deforestation \cite{shortcutDeforestation}, and the STG-machine \cite{evalApply, stg} 
were all instrumental in the creation of this compiler,
as well as the work by Appel and Peyton-Jones about functional compiler construction 
 \cite{compilersAppel, continuationsAppel, lazyFunctionalCompilers}.

While there has been some work on optimizations for functional-logic programs,
there doesn't seem to be a general theory of optimization.
Peem{\"o}ller and Ramos et al. \cite{peval, offlinePeval}
have developed a theory of partial evaluation for Curry programs,
and Moreno \cite{foldUnfold} has worked on the Fold/Unfold transformation from Logic programming.
We hope that our work can help bridge the gap to traditional compiler optimizations.

The implementation of the GAS system was instrumental in developing optimizations for this compiler.
It not only allowed us to implement optimizations more efficiently,
but also to test new optimizations,
and through optimization derivations,
discover which optimizations were effective,
which were never used, and which were wrong.
This greatly simplified debugging optimizations,
but it also allowed us to test more complicated optimizations.
Often we would just try an idea to see what code it produced,
and if it fired in unintended places.
It's difficult to overstate just how useful this system was in the compiler.

While the run-time system was not the primary focus of this dissertation,
we were able to produce some useful results.
The path compression theorem,
and the resulting improvement to backtracking,
is a significant improvement to the current state-of-the-art for backtracking Curry programs.

When starting this project, Shortcutting was already known
to be valid for Inductively Sequential Rewrite Systems.
It was developed for them specifically,
so it's not too surprising that the idea can be translated to Curry programs.
However, it was a nice surprise to find that
Unboxing and Deforestation were both valid in Curry.
It was even more remarkable that, with some simple restrictions,
we could make inlining and reduction valid in Curry as well.

We believe that this work is a good start for optimizing Curry compilers,
and we would like to see it continue.
After having a taste of optimized Curry, we want to turn up the heat,
and deliver an even hotter dish.
But for now, we've made a tasty Curry with \rice.


% \appendix
%
% \chapter{Derivation of fib} \label{ch:Derivation of fib}
% 
% %include A1_fib.lcurry
% 
% \chapter{Benchmarks Programs} \label{ch:Benchmarks Programs}
% 
% %include A2_benchmarks.lcurry


\printindex
\bibliographystyle{plain}
\bibliography{bibliography}
%\printindex
\end{document}
