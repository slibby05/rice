
In this chapter we develop three new optimizations for Curry.
First, Unboxing is an attempt to remove boxed values from our language.
We discuss our implementation of primitive values and operations,
and how explicitly representing the boxes around these values leads to optimizations.
Second, we look at an entirely new idea for removing 
node constructions that are quickly evaluated by case expressions
that we call Case Shortcutting.
Finally, Deforestation, specifically Shortcut Deforestation,
is a optimization for removing intermediate lists.
This has been studied extensively in functional languages,
but it has not been shown to be valid in the presence of non-determinism.
We prove its validity in Curry,
and give a formulation that can apply to combinator languages.

\section{Unboxing}

So far we have avoided talking about operations in Curry for 
primitive data types |Int|, |Char|, and |Float|.
This is primarily because in all current implementations of Curry,
primitive values are boxed.
A \emph{box}\index{boxed} for a primitive value is a node in the expression graph
that holds the primitive value.
This is done primarily to give a uniform representation of nodes in our expression graph.
There are many reasons why we would want to box primitive values.
It makes the implementations of run-time systems, garbage collectors, and debugging software much easier.
The choice of how we represent boxes has a pervasive effect on the compiler.
Since we knew how we intended to implement Unboxing, 
we decided to use our representation from the beginning.

We chose to follow the style of Unboxing from Launchbury et al. \cite{unboxing}
and represent all boxes explicitly in FlatCurry,
as opposed to other system which may represent the boxes at run-time,
but do not mention the boxes at compile time.
This has several advantages, but one of the most important
is that we can apply optimizations to the boxes themselves.

\subsection{Boxed Values}

Before we get into the process of unboxing values,
we need to look at how we represent boxed values.
The idea of boxing primitive values is common in higher level languages,
since it allows us to simplify the run-time system.
This is especially true in lazy languages where 
expressions such as |3 + 5| are represented by an expression
graph that will eventually hold the value |8| after it is evaluated.
It is important that every node that points to the expression graph of |3 + 5|
at run-time will then point to the expression graph of |8| after it is evaluated.
This update is difficult if |8| is the literal C integer \texttt 8.
However, if |8| is instead a constructor node containing the value 8, then this is fine.
We just replace the contents of the node labeled by |+| by a node labeled by |Int| with one child,
which is the C integer 8.

The purpose of unboxing is not to remove boxes entirely.
Instead we try to find cases where we replace the creation of new nodes in the expression graph
with primitive arithmetic operations.
The idea from Launchbury \cite{unboxing}
is that we can find these cases where we can remove boxes more easily if the boxes
are explicitly represented in the intermediate representation.
In order to represent boxes we need to make three changes to our FlatCurry programs.

The first is that every primitive value, a literal value of type |Int|, |Float|, or |Char|
is replaced with a constructor of the appropriate type.
For example |5 + 6| is transformed into the expression |(Int 5) + (Int 6)|.

Second, we need to wrap cases of literal values with cases that remove the box.
This can best be demonstrated with the example in figure \ref{fig:caseWrap}.
The value |x| is evaluated down to an |Int| node, then we extract
the unboxed integer |x_p| and proceed with the primitive case statement.
We also add one dummy branch to the unboxing case for each branch in the primitive case.
These branches are there to instruct the code generator on what values a free variable could
take on.

\begin{boxfigure}
\begin{minipage}{.4\textwidth}
> case  x of
>       0 -> False
>       1 -> True
\end{minipage} |==>|
\begin{minipage}{.4\textwidth}
> case  x of
>       Int x_p -> case  x_p of
>                        0 -> False
>                        1 -> True
>       0 -> free case
>       1 -> free case
\end{minipage}
\caption{Wrapping a primitive case with a case to remove the box.}
\label{fig:caseWrap}
\end{boxfigure}

Finally we need to give new definitions for primitive operations such as |+| and |<=|.
All of the operators fit the same pattern, so we only give the definitions for |+| and |<=| for integers
in figure \ref{fig:primOp}.
In order to evaluate a |+| node, we evaluate the first argument to its box,
then we unbox it with the case statement.
We do not have any dummy branches for free variables.
This represents the fact that |+| is a rigid operation.
We proceed to evaluate and unbox the second argument.
Finally, we return the result inside of a new box.
The |pl_p| operation performs the addition, and is translated to an add expression in C.
The |le_p| operation performs a comparison between two integers, and returns either
|True| or |False| based on the result.

\begin{boxfigure}
> (+) :: Int -> Int -> Int
> x + y = case  x of
>               Int x_p -> case  y of
>                                Int y_p ->  let v = x_p pl_p y_p
>                                            in Int v
>
> (<=) :: Int -> Int -> Bool
> x <= y = case  x of
>                Int x_p -> case  y of
>                                 Int y_p -> x_p le_p y_p 
\caption{Definitions for |+| and |<=| taking boxed integers.}
\label{fig:primOp}
\end{boxfigure}

Before we even look at trying to remove these boxes,
it is worth taking a second to see if we can optimize literal values.
There are actually a couple of significant improvements we can make
that apply more broadly.

The first is that for any constructor with no arguments, such as |True| or |Nothing|,
we can create a single static node to represent that constructor.
This eliminates the need to allocate memory for each instance of |True|.
While this is great, we might expect to go further.
For example, if we could turn case statements of Boolean expressions into
simple if statements in C.
We could compare the scrutinee to |True|, and if it is, then we evaluate the true branch,
otherwise we evaluate the false branch.
Unfortunately, this does not work for two reasons.
First, not all instances of |True| can be the static |True| nodes.
As an example, at run-time |not False| will evaluate to |True|,
but the node is going to be in the same location as the original |not| node.
Second, even if we have a Boolean expression that has been evaluated to a value,
it could still be a \texttt{FAIL} or \texttt{FREE} node.

The next optimization we can make is for the primitive types |Int|, |Char|, and |Float|.
Since these constructors have an argument, namely the primitive value,
we cannot make a single static node for them.
We might try to create a single static node for every literal value used in the program.
Unfortunately this does not tend to help us that much.
\begin{samepage}
Consider the standard factorial program:

> fac n = case  n of
>               0 -> 1
>               n -> n * fac(n-1)
\end{samepage}

Now if we evaluate |fac 42|, we will allocate memory up front for |0|, |1|, and |42|.
This will certainly save some memory, but not as much as we would hope.
We will still construct every number between |2| and |41|.

A better solution is to employ the flyweight pattern similar to the JVM.
The idea is that small integers are likely to come up often.
So, we statically allocate all of the integers between |-128| and |128|.
We do a similar allocation for characters.
Unfortunately, this patterns did not show improved performance for floating point numbers.

Now that we have seen how to represent boxes,
we can work on removing them, and see what we actually gain from it.

\subsection{Unboxed Values}


In order to get an idea of the effectiveness of unboxing, let us look at an example.
Consider the function to compute Fibonacci numbers if figure \ref{fig:fib}.
We will work with this example extensively in the next couple of optimizations,
in an attempt to see how much we can optimize it.

\begin{boxfigure}
> fib :: Int -> Int
> fib n = case  n <= 1 of
>               True   -> n
>               False  -> fib (n-1) + fib (n-2)

After translating to A-Normal Form:

> fib :: Int -> Int
> fib n =  let cond = n <= 1
>          in case  cond of
>                   True   ->  n
>                   False  ->  let n_1 = n-1
>                              in let f_1 = fib n_1
>                              in let n_2 = n-2
>                              in let f_2 = fib n_2
>                              in f_1 + f_2

After adding boxes:

> fib :: Int -> Int
> fib n =  let cond = n <= Int 1
>          in case  cond of
>                   True   ->  n
>                   False  ->  let n_1 = n - Int 1
>                              in let f_1 = fib n_1
>                              in let n_2 = n - Int 2
>                              in let f_2 = fib n_2
>                              in f_1 + f_2

\caption{A program for generating Fibonacci numbers translated to ANF, and adding boxes.}
\label{fig:fib}
\end{boxfigure}

Unfortunately, using the optimizations we have already discussed,
this function can not be optimized any further.
The |fib| function is recursive, so we can not reduce it,
and |n-1| contains a primitive operation.
However, we allocate a lot of memory while evaluating this function.
We create 5 nodes for each recursive call, |cont, n_1, f_1, n_2, f_2|.
We do not create a node for |f_1 + f_2| since that will replace the root node
during evaluation.
We can statically allocate a node for each integer, because the integers are constant.
However, there is still no need for this much allocation.
The problem is that each of our primitive operations and recursive calls 
must be represented as a node to fit in with our definition of an expression graph.

However, after explicitly representing the boxes, and using our
new definitions for |+| and |<=|,
we can optimize |fib| to the program given in figure \ref{fig:fibOpt1}.

\begin{boxfigure}
> fib n = case  n of
>               Int  v_2 ->  let  cond = v_2 le_p 1
>                            in  case  cond
>                                      True   ->  n
>                                      False  ->  let n_1     = v_2 mi_p 1
>                                                 in let f_1  = fib (Int n_1)
>                                                 in case  f_1 of
>                                                          Int p_1 ->  let n_2     = v_2 mi_p 2
>                                                                      in let f_2  = fib (Int n_2)
>                                                                      in case  f_2 of
>                                                                               Int p_2 ->  let r = p_1 pl_p p_2
>                                                                                           in Int r
\caption{Optimized |fib| after Unboxing}
\label{fig:fibOpt1}
\end{boxfigure}

As we can see, the code is significantly longer,
but now we have included the primitive operations in our code.
The variables |v_2, n_1, n_2, p_1, p_2| are all primitive values, so we do not need to allocate
any memory for them, so they will not be represented as nodes in our expression graph.
This seems like a big win, but it is a little deceptive.
We are still allocating 1 node for |cond, f_1, f_2| and 2 nodes for the |Int| constructors.
So, we are still allocating 5 nodes, which is just as much memory as before.
This is an improvement in efficiency, but we can certainly do better.

\subsection{Primitive Conditions}

The first optimization is that we really do not need to allocate memory for |cond|.
|x le_p y| should compile down to an expression involving the primitive \texttt{<=} operation in C,
and return a Boolean value.
However, right now there is no way to signal that to the code generator,
so we introduce the |pcase| construct.

The |primCond| must be a primitive condition expression, which is either |eq_p| or |le_p|,
and the arguments must be primitive values.
Perhaps surprisingly, these are the only primitive relational operators in Curry.
All other relations operators are converted to combinations of |eq_p|, |le_p|, and |not|.
The semantics of |pcase| are exactly what be expected,
but now we can translate it into a simple \texttt{if} 
statement in C, as shown in figure \ref{fig:primcond}.

\begin{boxfigure}
> pcase  primCond of
>        True -> e_t
>        False -> e_f
$\ $\\
\begin{tabular}{l}
$\mathcal{B}($|pcase primCond of {True -> e_t; False -> e_f}|$) \coloneqq $\\
$\ \ $ \tif{$\mathcal{E}_M(primCond)$}\\
$\ \ $ \texttt{\{}\\
$\ \ \ \ \ \ $ $\mathcal{B}(e_t)$\\
$\ \ $ \texttt{\}}\\
$\ \ $ \texttt{else}\\
$\ \ $ \texttt{\{}\\
$\ \ \ \ \ \ $ $\mathcal{B}(e_f)$\\
$\ \ $ \texttt{\}}\\
\end{tabular}
\caption{The syntax and translation for |primcond|}
\label{fig:primcond}
\end{boxfigure}

This has several advantages.
First we do not construct a node for the boolean value.
Even if we are statically allocating a single node value for |True|
and |False|, we avoid the cost of switch case loop,
and the cost of checking if |primcond| is non-deterministic.
It must be deterministic, because both of its operands are primitive values.
After implementing this construct, the new version is in figure \ref{fig:fibOpt2}.
Now we are down to 4 nodes, but we can still do better.
The next challenge is unboxing the arguments in the call to |fib|.

\begin{boxfigure}
> fib n = case  n of
>               Int v_2 -> pcase  v_2 le_p 1
>                                 True   ->  n
>                                 False  ->  let     n_1 = v_2 mi_p 1
>                                            in let  f_1 = fib (Int n_1)
>                                            in case  f_1 of
>                                                     Int p_1 ->  let     n_2 = v_2 mi_p 2
>                                                                 in let  f_2 = fib (Int n_2)
>                                                                 in case  f_2 of
>                                                                          Int p_2 ->  let  r = p_1 pl_p p_2
>                                                                                      in   Int r
\caption{The |fib| function with primitive cases}
\label{fig:fibOpt2}
\end{boxfigure}

\subsection{Strictness Analysis}

The problems with eliminating boxes from arguments of function calls
is strongly related to the run-time system and how we represent nodes
in our expression graph.
Recall that our expression graph is made up of node structs
that point to other node structs.
If we have a |fib| node, then the argument to this node
is expected to be another node.
In C we can get around this by using a union.
We created a union \texttt{field}, defined in figure \ref{fig:field}
that can either represent an |Int|, |Char|, |Float|, \texttt{Node}, or an array of \texttt{Node*}
in case a node has more than 3 children.

\begin{boxfigure}

\begin{verbatim}
typedef union field
{
    struct Node*  n; //normal node child
    union field*  a; //array child
    unsigned long c; //primitive character
    long          i; //primitive int
    double        f; //primitive float
} field;
\end{verbatim}
\caption{Definition of \texttt{field} type.}
\label{fig:field}
\end{boxfigure}

The problem with storing a primitive value in a node,
instead moves to identifying when a value is primitive.
There is no way to distinguish between 
\texttt{Node*} and \texttt{unsigned long}.
Instead of trying to figure out when a child of a node is supposed 
to represent a primitive value at run-time.  
We need to keep track of this information at compile time.
Fortunately, this is a well studied problem 
\cite{strictProj, strictAbstract, strictBack}.

Lazy functional languages often try to remove laziness for efficiency reasons.
We do not want to create an expression for a primitive value 
if we are only going to deconstruct it,
so it becomes useful to know what parameters in a function must be evaluated,
A parameter that must be evaluated by a function is called \emph{strict}\index{strict}.
Formally, a function |f| is strict in its parameter if 
|f EXEMPT = EXEMPT|.

We use |EXEMPT| here to mean that the value of it is parameter does not evaluate to a value,
this can come from a call to the |error| function, or
an infinite computation.
It does not mean that |f| failed to return a value.
We explicitly exclude that case, because that can change the results of some Curry programs.
\begin{samepage}
For example consider the function:

> f x = head []
\end{samepage}

\begin{samepage}
If we were to mark |x| as strict, then we may try to evaluate |x| before computing |f|.
This could cause an infinite loop in the following program:

> loop = loop
> main = (f loop) ? 1
\end{samepage}

This should return a single result, and never try to evaluate |loop|.
For this reason we consider failing computations to be 
similar to expressions rooted by constructors for the purposes of strictness analysis.

We implemented an earlier form of strictness analysis described by Peyton Jones et al. \cite{haskellOpt}.
This is a very limited form of abstract interpretation.
The idea is that we start by assuming every function is strict in all its parameters.
Then as we analyze a function we determine which parameters can be relaxed.
\begin{samepage}
For example consider the following function:

> f x y z = case  x of
>                 True   -> y
>                 False  -> y + z
\end{samepage}

It is clear that |x| must be strict, but we do not know about |y| or |z|.
After analyzing the case branches, we see that since |y| appears in both branches,
and |+| is strict in both of it is arguments, |y| must be strict as well.
Finally, since there is a branch that |z| does not appear in, |z| may not be evaluated,
so it is not strict.

This syntactic traversal of an expression is useful,
but it fails when working with a recursively defined function.
\begin{samepage}
Consider the factorial function with an accumulator:

> faca n acc = case  n == 0 of
>                    True   -> acc
>                    False  -> n * faca (n-1) (n*acc)
\end{samepage}

We can see with a syntactic check that |n| is strict, but what about |acc|.
|acc| does appear in both branches, but it is the argument to the recursive call of |faca|.
Therefore we have |acc|, the second parameter of |faca|, is strict if, and only if, the second
parameter of |faca| is strict.
We can solve this problem by iteratively running the strictness analyzer on |faca| until
it converges to a single set of strict parameters.
Formally, since a variable can be either strict or not strict,
we can represent it with a 2 element set $\{0,1\}$, and our strictness analyzer is a monotonic function, 
so we are computing a least fixed point in the strictness analyzer over the set $2^n$
where $n$ is the arity of the function.

There are much more sophisticated implementations of strictness analysis.
We do not analyze deeper than a single pattern, and we are very conservative
in regard to recursive functions.
Mycroft's original work was to interpret functions as Boolean formulas \cite{strictAbstract}.
This can find several cases of strict parameters that our implementation does not.
There has also been a lot of work on projection based strictness analysis \cite{strictProj}.
The current state of the art for Haskell is backwards projection analysis \cite{strictBack}.
Studying the validity and implementation of these strictness analyzers in regard to Curry
would all be great candidates for future work.

Once we know which arguments are strict we can split the function into a wrapper function
and a worker function \cite{strictBack}.
We can see this with |fib|.
We take the current optimized version in figure \ref{fig:fibOpt2},
and apply the worker/wrapper split in figure \ref{fig:fibOpt3}.
This creates two functions, |fib|, which simply evaluates and unboxes the parameter,
,and |fib#worker|, which does the rest of the computation.
Then we optimize the function again resulting in figure \ref{fig:fibOpt4}.
Notice that since |fib| is no longer recursive we can inline it.
\begin{samepage}
So we can inline the call to |fib| in the following code:

> let  f_1 = fib (Int n_1)


This results in:

> let  f_1 = case (Int n_1) of
>               Int v_2 -> fib#worker v_2


Which can be optimized to:

> let  f_1 = fib#worker n_1
\end{samepage}

\begin{boxfigure}
> fib n = case  n of
>               Int v_2 -> fib#worker v_2
>
> fib#worker v_1 =  
>    let n = Int v_1
>    in case n of
>           Int v_2 -> pcase  v_2 le_p 1 of
>                             True   ->  n
>                             False  ->  let     n_1 = v_2 mi_p 1
>                                        in let  f_1 = fib (Int n_1)
>                                        in case  f_1 of
>                                               Int p_1 ->  let     n_2 = v_2 mi_p 2
>                                                           in let  f_2 = fib (Int n_2)
>                                                           in case  f_2 of
>                                                                  Int p_2 ->  let r = p_1 pl_p p_2
>                                                                              in Int r
\caption{The |fib| function after strictness analysis.}
\label{fig:fibOpt3}
\end{boxfigure}

\begin{boxfigure}
> fib#worker v_2 = 
>   pcase  v_2 le_p 1 of
>          True  ->  Int v_2
>          False ->  let n_1 = v_2 mi_p 1
>                    in let f_1 = fib#worker n_1
>                    in case  f_1 of
>                             Int p_1 ->  let n_2 = v_2 mi_p 2
>                                         in let f_2 = fib#worker n_2
>                                         in case  f_2 of
>                                                  Int p_2 ->  let r = p_1 pl_p p_2
>                                                              in Int r
\caption{The |fib| function after strictness analysis and optimization.}
\label{fig:fibOpt4}
\end{boxfigure}

We are down to allocating 2 nodes.
We only need to allocate nodes for the calls to |fib#worker|.
This means that we have reduced our memory consumption by 60\%.
That is a huge improvement, but we can still do better.
With the next optimization we look at how to remove the remaining allocations.

\section{Case Shortcutting}

In the last section were able to optimize the |fib| function from allocating 
5 nodes per recursive call to only allocating 2 nodes per recursive call.
\begin{samepage}
However, we were left with a problem that we can not solve by a code transformation.

> let f_1 = fib#worker n_1
> in case  f_1 of
>          Int p_1 ->  ...
\end{samepage}

In this section we aim to eliminate these final two nodes.
However, in order to do this, we will have to step outside of compile-time optimizations,
and look into previous work on run-time optimizations for Curry.
Specifically we are going to use an idea inspired by the shortcutting optimizations \cite{shortcutting}.
However, shortcutting was designed for rewrite systems,
and the idea doesn't quite match how our run-time evaluates expressions.
However the goal of shortcutting was to eliminate the construction of
nodes using a systematic transformation of the rewriting system.
In this spirit, we have transformed the generated code
to eliminate nodes that are constructed, only to be quickly evaluated
and deconstructed by case statements.
This ``case shortcutting'' has proven to be very effective in eliminating
many memory allocations.

We will often find examples of expressions that are constructed,
and immediately evaluated by a case statement,
after which, the results are never used again.
Both $f_1$ and $f_2$ in figure \ref{fig:fibOpt4} are excellent examples of such expressions.
Typically a compiler for a lazy language would recognize this situation,
and instead of generating a node only to evaluate it, the compiler would produce a function call
that would return the value of that node.

It is worth looking at an attempt to try to replace the node with a function call.
One possibility would be to try to statically analyze a function |f| and determine if it is deterministic.
This is a reasonable idea, but it has two major drawbacks.
First, determining if a function is non-deterministic is undecidable,
so the best we could do is an approximation.
Second, even if |f| is deterministic, the expression |f x|
could still be non-deterministic if |x| is.
This is going to be very restrictive for any possible optimization.

In the example in figure \ref{fig:fibOpt4} we need a node to hold the value for |fib#worker n_1|,
but this value will only be used in the case expression.
In fact, it is not possible for this node to be shared with any part of the expression graph.
If this expression is only ever scrutinized by the case expression,
then we only need to keep the value around temporarily.
The idea here is simple, but the implementation becomes tricky.
We want to use a single, statically allocated, node for every variable
that is only used as the scrutinee of a case.

There are two steps to the optimization.
The first step is marking every node that is only used as the scrutinee.
The second step happens during code generation.
Instead of dynamically allocating memory for a marked node,
we store all of the information in a single, statically allocated, node.
We call this node \texttt{RET} for return.

This effectively removes the rest of the dynamically allocated nodes from our |fib|
function, but before we celebrate, we need to make sure that 
code generated using this transformation actually produces the same results.
There are a few things the can potentially go wrong.

First, let us look at the case where the scrutinee is deterministic.
In that case, there is only one thing that could go wrong.
It is possible that in order to reduce the scrutinee 
we need to reduce another expression that could be stored in \texttt{RET}.
\begin{samepage}
For example, consider the following program:

> f x = case  g x of
>             True   -> False
>             False  -> True
>
> main = case  f 3 of
>              True   -> 0
>              False  -> 1
\end{samepage}

In the evaluation of |main|, |f 3| can be stored in the \texttt{RET} node,
then we can evaluate |f 3| to head constructor form,
but while we are evaluating |f 3|, we store |g 3| in the same \texttt{RET} node.
While this is concerning, it is not actually a problem.
As shown in chapter \ref{ch:The Generated Code}, 
at the beginning of \texttt{f\_hnf}, 
we store all of the children of \texttt{root} as local variables, 
and then when we have computed the value, we overwrite the \texttt{root} node.
In our case the \texttt{root} node in our function is \texttt{RET}.
However, aside from the very start and end of the function, 
we never interact with the \texttt{root} node,
so even if we reuse \texttt{RET} in the middle of evaluating |f|, it does not actually
affect the results.

A portion of the generated code for |f| can be seen in figure \ref{fig:gen_f}.
As we can see, the only time that we use the \texttt{root} node 
is at the very start of the function to store the variables,
and right before we return.
Even if \texttt{root} happens to be \texttt{RET},
this does not actually affect the evaluation.
The \texttt{RET} node is overwritten with the contents of |g x|,
then it is evaluated, and finally it is overwritten with the result of |f| right before returning.

\begin{boxfigure}
\begin{verbatim}
void f_hnf(Node* root)
{
  field x = root->children[0];
  set_g(RET, make_int(3));
  field scrutenee = RET;
  bool nondet = false;
  while(true)
  {
    nondet |= scrutenee.n->nondet;
    switch(TAG(scrutenee))
    {
      ...
      case True:
        if(nondet) push_frame(root, make_Prelude_f_1(x));
        set_Prelude_False(root, 0);
        return;
    }
  }
}
\end{verbatim}
\caption{Part of the generated code for |f|.}
\label{fig:gen_f}
\end{boxfigure}

It seems like we should be able to 
store these marked variables in the \texttt{RET} node, and then 
just call the appropriate \texttt{\_hnf} function.
In fact this was the first idea we tried.
The generated code for main is given in figure \ref{fig:RET1}.

\begin{boxfigure}
\begin{verbatim}
void main_hnf(Node* root)
{
    set_f(RET, make_int(3));
    field scrutenee = RET;
    bool nondet = false;
    while(true)
    {
        nondet |= scrutenee.n->nondet;
        switch(TAG(scrutenee))
        {
            ...
            case True:
                if(nondet) ...
                set_int(root, 0);
                return;
            ...
        }
    }
\end{verbatim}
\caption{First attempt at compiling |main| with Shortcutting.}
\label{fig:RET1}
\end{boxfigure}

This initial version actually works very well.
In fact, for |fib#worker| we are able to remove the remaining 2 allocations.
This is fantastic, and we will come back to this point later,
but we need to deal with a looming problem.

\subsection{Non-deterministic RET Nodes}

The problem with the scheme we have developed so far is that
if \texttt{RET} is non-deterministic, 
then the rewrite rule we push on the backtracking stack may
contain a pointer to \texttt{RET}.
This is a major problem with this optimization,
because \texttt{RET} will almost certainly have been reused
by the time backtracking occurs.

This optimization was built on the idea that \texttt{RET}
is only ever used in a single case expression.
Therefore, it is important that we never put \texttt{RET} on the backtracking stack.
We need rethink on our idea.
Initially, we wanted to avoid allocating a node if a variable is used in a single case.
Instead, we will only allocate a node if \texttt{RET} is non-deterministic.
This means that for deterministic expression, we do not allocate any memory,
but for non-deterministic expression, we still have a persistent variable on the stack.
This lead to the second implementation in figure \ref{fig:RET2}.

\begin{boxfigure}
\begin{verbatim}
void main_hnf(Node* root)
{
    set_f(RET, make_int(3));
    field scrutinee = RET;
    bool nondet = false;
    while(true)
    {
        nondet |= scrutinee.n->nondet;
        switch(scrutenee.n->tag)
        {
            ...
            case True:
                if(nondet)
                {
                    Node* backup = copy(RET);
                    stack_push(bt_stack, root, main_1(backup));
                }
                set_int(root, 0);
                return;
                ...
        }
    }
\end{verbatim}
\caption{Second attempt at compiling |main| with Shortcutting.}
\label{fig:RET2}
\end{boxfigure}

\subsection{RET hnf Functions}

This solution is better, because any rewrites we push onto the stack
contain a copy of \texttt{RET}, but it is still not correct.
Three things can still go wrong here.
These are very subtle errors that are very easy to overlook,
and even harder to track down the real cause of the errors.

The first problem is that \texttt{RET} might have been reduced to a
forwarding node, so it might be deterministic, but forward to a non-deterministic node.
For example, in |case id (0 ? 1) of ...|
there is clearly non-determinism,
but the |id| node is not the cause of it, 
so that rewrite should not be pushed on the backtracking stack.

Another problem is that, if \texttt{RET} is a forwarding node,
when evaluating the node it forwards to, we might have reused \texttt{RET}.
\begin{samepage}
Consider the following program:

> h x = case  x > 3 of 
>             False  -> 3
>             True   -> 4
> main = case  (h 4 ? h 2) of
>              4 -> True
\end{samepage}

Here |main| evaluates |h 4 ? h 2|.
Since |?| is non-deterministic, and reduces to a forwarding node,
we need to make a copy of \texttt{RET} 
as part of the rewrite we push on the backtracking stack.
However, before we can even do that, we need to evaluate |h 4|,
and the expression |x > 3| will be stored in \texttt{RET}.
Now we have lost the information in \texttt{RET} before we can copy it.

\begin{samepage}
Finally, we still have not avoided putting \texttt{RET} on the backtracking stack.
Recall our program from before.

> f x = case  g x of
>             True   -> False
>             False  -> True
>
> main = case  f 3 of
>              True   -> 0
>              False  -> 1
\end{samepage}

If the expression |g x| is non-deterministic, 
then the node containing |f| will be marked as non-deterministic.
However, |f 3| was stored in the \texttt{RET} node,
so the \texttt{root} parameter will be \texttt{RET}.
Now \texttt{RET} is still pushed on the backtracking stack,
but this time it is on the left hand side of the rewrite.

This is starting to seem hopeless,
when we fix one problem, 3 much more subtle problems pop up.
How can we avoid creating nodes for deterministic expressions,
but still only create a single node that the 
caller and callee agree on if the expression is non-deterministic?

The answer is that we need to change how \texttt{RET} nodes are reduced.
Specifically, we create a new reduction function that only handles nodes stored in \texttt{RET}.
In the case of |f|, we would create a 
\texttt{f\_hnf}, a \texttt{f\_1\_hnf} and a \texttt{f\_RET\_hnf}.
The third function only reduces |f| that has been stored in a \texttt{RET} node.

The difference between \texttt{f\_hnf} and \texttt{f\_RET\_hnf} is that
instead of passing the root node, we pass \texttt{Node* backup}.
The \texttt{backup} node is where we will store the contents of \texttt{RET}
if we discover evaluating the expression rooted by |f| is non-deterministic.
Finally we return \texttt{backup}.
Now both the caller and callee agree on \texttt{backup}.
Furthermore, since \texttt{backup} is a local variable,
it is not affected if |f| reuses \texttt{RET} over the course of its evaluation.
We can see the final implementation of shortcutting for |main| in figure \ref{fig:RET3}.
We also give the definition for \texttt{f\_RET\_hnf} in figure \ref{fig:RET_f}.

\begin{boxfigure}
\begin{verbatim}
void main_hnf(Node* root)
{
    set_f(RET, make_int(3));
    field scrutinee = RET;
    Node* f_backup = f_RET_hnf(NULL);
    bool nondet = false;
    if(f_backup != NULL)
    {
        nondet = true;
        memcpy(f_backup, RET.n, sizeof(Node));
    }
    else if(RET.n->tag == FORWARD_TAG)
    {
        f_backup = RET.n->children[0];
    }

    while(true)
    {
        nondet |= scrutinee.n->nondet;
        switch(scrutenee.n->tag)
        {
            ...
            case True:
                if(nondet)
                {
                    stack_push(bt_stack, root, main_1(f_backup));
                }
                set_int(root, 0);
                return;
                ...
        }
    }
\end{verbatim}
\caption{Final version of |main| with Shortcutting.}
\label{fig:RET3}
\end{boxfigure}

\begin{boxfigure}
\begin{verbatim}
Node* f_RET_hnf(Node* backup)
{
    Node* v1 = RET->children[0];
    set_g(RET, v1);
    field scrutenee = RET;
    Node* g_backup = g_RET_hnf(NULL);
    bool nondet = false;
    if(g_backup != NULL) {
        nondet = true;
        memcpy(g_backup, RET.n, sizeof(Node));
    }
    else if(RET.n->tag == FORWARD_TAG) {
        g_backup = RET.n->children[0];
    }
    while(true) {
        nondet |= scrutenee.n->nondet;
        switch(RET_forward->tag) {
            ...
            case True:
                if(nondet) {
                    if(!backup) {
                        backup = (Node*)malloc(sizeof(Node));
                    }
                    set_False(backup);
                    stack_push(bt_stack, backup, g_backup);
                }
                set_False(RET);
                return backup;
            ...
        }
    }
\end{verbatim}
\caption{Compiling |f| with Shortcutting.}
\label{fig:RET_f}
\end{boxfigure}

Now, we finally have a working function.
We only allocate memory if the scrutinee of the case is non-deterministic.
If the expression is non-deterministic in multiple places,
then the same \texttt{backup} node is pushed on the stack,
so our expression graphs stay consistent.

\begin{samepage}
This also works well if we have multiple reductions in a row.
Suppose we have the following Curry code:

> main = case  f 4 of
>              True   -> False
>              False  -> False
>
> f n = case  n of
>             0 -> True
>             _ -> f (n-1)
\end{samepage}

In this case |f| is a recursive function,
so when we reduce |f 4|, we need to reduce |f 3|.
This is no problem at all, because we are reducing |f 4| with \texttt{f\_RET\_hnf}.
Ignoring the complications of Unboxing for the moment, we can generate the following code
for the return of |f|.

\begin{verbatim}
field v2 = make_int(n-1)
set_f(RET, v2);
return f_RET_hnf(backup);
\end{verbatim}

\subsection{Shortcutting Results}

Before we move onto our next optimization, we should look back at what we have done so far.
Initially, we had a |fib| function that allocated 5 nodes for every recursive call.
Then, through Unboxing, we were able to cut that down to only 2 allocations per call.
Finally, using Shortcutting, we were able to eliminate those two allocations.
We would expect a substantial speedup by reducing memory consumption by 60\%,
but removing those last two allocations is a difference in kind.
The |fib| function runs in exponential time,
and since each step allocates some memory, the original |fib| function
allocated an exponential amount of memory on the heap.
However, our fully optimized |fib| function only allocates a static node at startup.
We have moved from exponential memory allocated on the heap to constant space.
While |fib| still runs in exponential time,
it runs much faster, since it does not need to allocate memory.
Surprisingly, |fib| is still just as efficient with non-deterministic arguments.
If the argument is non-deterministic, the wrapper function will evaluate it
before calling the worker.

Now that we have removed most of the implicitly allocated memory
with Unboxing and Shortcutting, 
we can work on removing explicitly allocated memory
with a technique from functional languages.

\section{Deforestation}
We now turn to our final optimization, Deforestation.
The goal of this optimization is to remove intermediate data structures.
Programmers often write in a pipeline style when writing functional programs.
\begin{samepage}
For example, consider the program:

> sumPrimes   =  sum . filter isPrime . enumFromTo 2
\end{samepage}

While this style is concise and readable, it is not efficient.
First, we create a list of integers,
then we create a new list of all of the integers in our list that are prime,
and finally we sum the values in that list.
\begin{samepage}
It would be much more efficient to compute this sum directly.

> sumPrimes n = go 2 n
>  where  go k n
>         | k >= n     = 0
>         | isPrime k  = k + go (k+1) n
>         | otherwise  = go (k+1) n
\end{samepage}


This pipeline pattern is pervasive in functional programming,
so it is worth understanding and optimizing it.
In particular, we want to eliminate the two intermediate lists created here.
This is the goal of Deforestation.

\subsection{The Original Scheme}
Deforestation has actually gone through several forms throughout it is history.
The original optimization proposed by Wadler \cite{deforestationWadler}
was very general, but it required a complicated algorithm, and it could fail to terminate.
There have been various attempts to improve this algorithm \cite{turchin_supercompiler} and 
\cite{wadler_ferguson_deforest}
that have focused on restricting the form of programs.

An alternative was proposed by Gill in his dissertation \cite{gill_dissertation, shortcutDeforestation}
called \mbox{foldr-build} Deforestation or short-cut Deforestation. 
This approach is much simpler, always terminates, and has a nice correctness proof,
but it comes at the cost of generality.
\mbox{Foldr-build} Deforestation only works with functions that produce and consume lists.
Still, lists are common enough in functional languages that this optimization has proven to be effective.

Since then \mbox{foldr-build} Deforestation has been extended to Stream Fusion \cite{stream}.
While this optimization is able to cover more cases than \mbox{foldr-build} Deforestation,
it relies on more advanced compiler technology.

The \mbox{foldr-build} optimization itself is actually very simple.
It relies on an observation about the structure of a list.
All lists in Curry are built up from cons and nil cells.
The list |[1,2,3,4]| is really |1 : 2 : 3 : 4 : []|.
One very common list processing technique is a fold,
which takes a binary operation and a starting element, and reduces a list to a single value.
\begin{samepage}
In Curry, the |foldr| function is defined as:

> foldr :: (a -> b -> b) -> b -> [a] -> b
> foldr `f` z []      = z
> foldr `f` z (x:xs)  = x `f` foldr f z xs
\end{samepage}

\begin{samepage}
As an example, we can define the |sum| function as |sum xs = foldr (+) 0|.
To see what this is really doing we can unroll the recursion.
Suppose we evaluate |foldr (+) 0 [1,2,3,4,5]|, then we have:

> foldr (+) 0 [1,2,3,4,5]
> => 1 + foldr (+) 0 [2,3,4,5]
> => 1 + (2 + foldr (+) 0 [3,4,5]))
> => 1 + (2 + (3 + foldr (+) 0 [4,5]))
> => 1 + (2 + (3 + (4 + foldr (+) 0 [5])))
> => 1 + (2 + (3 + (4 + (5 + foldr (+) 0 []))))
> => 1 + (2 + (3 + (4 + (5 + 0))))
\end{samepage}

\begin{samepage}
But wait, this looks very similar to our construction of a list.

> 1  :  (2  :  (3  :  (4  :  (5  :  ([])))))
> 1  +  (2  +  (3  +  (4  +  (5  +  (0)))))
\end{samepage}

We have just replaced the |:| with |+| and the |[]| with |0|.
If the compiler can find where we will do this replacement,
then we do not need to construct the list.
On its own, this is a very hard problem, but we can help the compiler along.
We just need a standard way to construct a list.
\begin{samepage}
This can be done with the |build| function \cite{shortcutDeforestation}.

> build :: (forall b (a -> b -> b) -> b -> b) -> [a]
> build g = g (:) []
\end{samepage}

The |build| function takes a function that constructs a list.
However, instead of construction the list with |:| and |[]|,
we abstract this by passing the constructors in as arguments, which we call |c| and |n| respectively.
Now, with |build|, we can define what we mean by deforestation with a simple theorem from
\cite{shortcutDeforestation}.

\begin{theorem}
For all |f : a -> b -> b|, |z : b|, and |g : (forall b (a -> b -> b) -> b -> b) -> [a]|,
> foldr f z (build g) = g f z
\end{theorem}

So, if we can construct standard list functions using |build| and |foldr|,
then we can remove these function using the above theorem.
\begin{samepage}
As an example, let us look at the function |enumFromTo a b| that constructs
a list of integers from |a| to |b|.
> enumFromTo a b
>  | a > b      = []
>  | otherwise  = a : enumFromTo (a+1) b
\end{samepage}

\begin{samepage}
We can turn this into a build function.
> enumFromTo a b = build (enumFromTo_build a b)
> enumFromTo_build a b c n
>  | a > b      = n
>  | otherwise  = a `c` enumFromTo_build (a+1) b c n
\end{samepage}

We can create build functions for several list creation functions
found in the standard library.
In fact, for this optimization we replace several functions in both the
Prelude and List library with equivalent functions constructed with |foldr| and |build|.
Now we are ready to apply Deforestation to Curry.
Unfortunately there are two problems we need to solve.
The first is an implementation problem,
and the second is a theoretical problem.
First, while we can apply foldr/build Deforestation, we can not actually optimize the results.
Second, we still need to show it is valid for curry.

\subsection{The Combinator Problem}

Let us look back at the motivating example,
and see how it could be optimized in Haskell,
or any language that can inline lambda expressions.
The derivation in figure \ref{fig:sumPrimes_deforest} comes from the 
original paper \cite{shortcutDeforestation}.

\begin{boxfigure}
> sumPrimes m = sum (filter isPrime (enumFromTo 2 m))
> ==>
> sumPrimes m = foldr (\x y -> x + y) 0 
>                 (build (\c n -> foldr (\x y -> if isPrime x then x `c` y else y) n)
>                  (build enumFromTo_build 2 m))
> ==>
> sumPrimes m = foldr (\x y -> x + y) 0 
>                 (build (\c n -> (enumFromTo_build 2 x) (\x y -> if isPrime x then x `c` y else y) n))
> ==>
> sumPrimes m = enumFromTo_build 2 m (\x y -> if isPrime x then (\x y -> x + y) x y else y) 0
> ==>
> sumPrimes m = enumToFrom_build 2 m (\x y -> if isPrime x then x + y else y) 0
>   where enumToFrom_build k m c z =  if k > m 
>                       then z
>                       else c k (enumToFrom_build (k+1) m c z)
> ==>
> sumPrimes m = enumToFrom_build 2 m (\x y -> if isPrime x then x + y else y) 0
>   where enumToFrom_build k m c z =  if k > m 
>                                     then z
>                                     else (\x y -> if isPrime x then x + y else y) 
>                                             k (enumToFrom_build (k+1) m c z)
> ==>
> sumPrimes m = enumToFrom_build 2 m
>   where enumToFrom_build k m =  if k > m 
>                                 then z
>                                 else (\x y ->  if isPrime x then x + y else y)
>                                        k (enumToFrom_build (k+1) m c z)
> ==>
> sumPrimes m = enumToFrom_build 2 m
>   where enumToFrom_build k m =  if k > m 
>                                 then z
>                                 else  if isPrime k 
>                                       then x + (enumToFrom_build (k+1) m c z) 
>                                       else (enumToFrom_build (k+1) m c z)
\caption{Optimization derivation for for short-cut Deforestation}
\label{fig:sumPrimes_deforest}
\end{boxfigure}

This looks good.
In fact, we obtained the original expression we were trying for.
Unfortunately we do not get the same optimization in Rice.
\begin{samepage}
The problem is actually the definition of |filter|.

> filter f = build (\c n -> foldr (\x y -> if f x then x `c` y else y) n)
\end{samepage}

Functions that transform lists, such as |filter|, |map|, and |concat|,
are rewritten in the standard library as a build applied to a fold.
Unfortunately our inliner can not produce this derivation.
We do not inline lambda expressions, and reductions
can only be applied to let bound variables, so we simply can not do this reduction.
Instead we need a new solution.

\subsection{Solution build\_fold}

\begin{samepage}
Our solution to this problem is to introduce a new combinator for transforming lists.
We call this |build_fold| since it is a build applied to a fold.

> build_fold :: ((c -> b -> b) -> (a -> b -> b)) -> (b -> b) -> [a] -> b
> build_fold mkf mkz xs = foldr (mkf (:)) (mkz []) xs
\end{samepage}

The idea behind this combinator is a combination of a build and a fold.
This function was designed to be easily composable with both build and fold.
Ideally, it could fit in the middle of build and fold and still reduce.
\begin{samepage}
As and example:
> foldr (+) 0 (build_fold filter_mkf filter_mkz (build enumFromTo_build))
\end{samepage}

Ideally, this function should reduce into something relatively efficient,
Furthermore we wanted |build_fold| to compose nicely with itself.
For example, |map f . map g| should compose to something like |map (f . g)|.

We achieve this by combining pieces of both |build| and |foldr|.
The two functions |mkf| and |mkz| make the |f| and |z| functions from fold,
however they take |c| and |n| as arguments similar to |build|.
The idea is that |mkf| takes an |f| from |foldr| as a parameter,
and returns a new |f|.
\begin{samepage}
The |map| and |filter| implementations are given below.

> map f = build_fold (map_mkf f) map_mkz
> map_mkf f c x y = f x `c` y
> map_mkz n = n

> filter p = build_fold (filter_mkc p) filter_mkz
> filter_mkf p c x y = if p x then x `c` y else y
> filter_mkz n = n
\end{samepage}

The purpose of the convoluted definition of |build_fold| is that
it plays nicely with |build| and |foldr|.
We have the following three theorems about |build_fold|, which we will prove later.
These are analogous to the |foldr/build| theorem.

\begin{theorem}
\label{thm:buildFold}
For all functions of the appropriate type that evaluate no $?$ expressions,
the following qualities hold.
> build_fold mkf mkz (build g) = build (\c n -> g (mkf c) (mkz n))
> foldr f z (build_fold mkf mkz xs) = foldr (mkf f) (mkz z) xs
> build_fold mkf_1 mkz_1 (build_fold mkf_2 mkz_2 xs) = build_fold (mkf_2 . mkf_1) (mkz_2 . mkz_1) xs
\end{theorem}

The proof of this theorem will be given in the next section.
Now that we have removed all of the lambdas from our definitions,
we can look at the implementation.

\subsection{Implementation}

Deforestation turned out to be one of the easiest optimizations to implement.
The implementation is entirely in GAS, and it proceeds in two steps.
First we find any case where a |build| or |build_fold|
occurs exactly once in either a |build_fold| or |fold|.
If this is the case, we inline the variable that |build| is bound to into it is single use.
This temporarily takes our expression out of A-Normal Form,
but we will restore that with the second step,
which is the actual Deforestation transformation,
which applies either the |foldr/build| theorem,
or one of the three |build_fold| theorems from above.
The definitions for the deforest transformation are given in figure \ref{fig:deforest}
The optimization derivation for |sumPrimes| is in figure \ref{fig:sumOpt}.

\begin{boxfigure}
\textbf{Inline foldr/build:}\\
\begin{minipage}{.40\textwidth}
> let x = build g in e 
>   | path e p = foldr x 
\end{minipage}  |==>|
\begin{minipage}{.40\textwidth}
> extend e [p,2] (build g)
\end{minipage}\\
\begin{minipage}{.40\textwidth}
> let x = build g in e 
>   | path e p = build_fold _ _ x
\end{minipage}  |==>|
\begin{minipage}{.40\textwidth}
> extend e [p,2] (build g)
\end{minipage}\\
\begin{minipage}{.40\textwidth}
> let x = build_fold mkf mkz in e 
>   | path e p = foldr f z x 
\end{minipage} |==>|
\begin{minipage}{.40\textwidth}
> extend e [p,2] (build_fold mkf mkz)
\end{minipage}\\
\begin{minipage}{.40\textwidth}
> let x = build_fold mkf mkz in e 
>   | path e p = build_fold _ _ x
\end{minipage}  |==>|
\begin{minipage}{.40\textwidth}
> extend e [p,2] (build_fold mkf mkz)
\end{minipage}\\
\textbf{Deforest foldr/build:}\\
\begin{minipage}{.40\textwidth}
> foldr f z (build g)
\end{minipage} |==>|
\begin{minipage}{.40\textwidth}
> g f z
\end{minipage}\\
\textbf{Deforest build\_fold/build:}\\
\begin{minipage}{.40\textwidth}
> build_fold mkf mkz (build g)
\end{minipage} |==>|
\begin{minipage}{.40\textwidth}
> build (\c n -> g (mkf c) (mkz n))
\end{minipage}\\
\textbf{Deforest foldr/build\_fold:}\\
\begin{minipage}{.40\textwidth}
> foldr f z (build_fold mkf mkz xs)
\end{minipage} |==>|
\begin{minipage}{.40\textwidth}
> let     f_1 = mkf f
> in let  z_1 = mkz z
> in foldr f_1 z_1 xs
\end{minipage}\\
\textbf{Deforest build\_fold/build\_fold:}\\
\begin{minipage}{.40\textwidth}
> build_fold mkf_1 mkz_1 
>    (build_fold mkf_2 mkz_2 xs)
\end{minipage} |==>|
\begin{minipage}{.40\textwidth}
> let     f_1 = mkf_2 . mkf_1
> in let  z_1 = mkz_2 . mkz_1
> in build_fold f_1 z_1 xs

\end{minipage}\\
\caption{The Deforestation optimization. \\
         The lambda in the build rule is a call to a known function.\\
         The lets are added to keep the expression in A-Normal Form.\\
         The expression |e || cond ==> e'| should be read as
         ``|e| rewrites to |e'| given that |cond| holds.''}
\label{fig:deforest}
\end{boxfigure}


\begin{boxfigure}
> let v_1 = appOpt (enumFromTo 2 n)
> in let v_2 = appOpt (filter isPrime v_1)
> in appOpt (sum v_2)
> ==> REDUCE_USEFUL
> let v_1 = build enumFromTo_build 2 n
> in let v_2 = build_fold (filter_mkf isPrime) id v_1
> in foldr (+) 0 (appOpt v_2)
> ==> INLINE_BF
> let v_1 = build enumFromTo_build 2 n
> in let v_2 = build_fold (filter_mkf isPrime) id v_1
> in appOpt (foldr (+) 0 (build_fold (filter_mkf isPrime) id v_1))
> ==> FOLD_BF
> let v_1 = build enumFromTo_build 2 n
> in let v_2 = build_fold (filter_mkf isPrime) id v_1
> in let z = id 0
> in let f = filter_mkf isPrime (+)
> in foldr f z (appOpt v_1)
> ==> INLINE_BUILD
> let v_1 = build enumFromTo_build 2 n
> in let v_2 = build_fold (filter_mkf isPrime) id v_1
> in let z = id 0
> in let f = filter_mkf isPrime (+)
> in appOpt (foldr f z (build enumFromTo_build 2 n))
> ==> FOLD_BUILD
> let appOpt (v_1 = build enumFromTo_build 2 n)
> in let appOpt (v_2 = build_fold (filter_mkf isPrime) id v_1)
> in let z = id 0
> in let f = filter_mkf isPrime (+)
> in enumFromTo_build 2 n f z
> ==> DEAD_CODE
> in let z = id 0
> in let f = filter_mkf isPrime (+)
> in enumFromTo_build 2 n f z
\caption{Derivation for |sumPrimes|}
\label{fig:sumOpt}
\end{boxfigure}

So far we have done a decent job.
It is not as efficient as the Haskell version,
but that is not surprising.
However, we can still improve this.
The main problem here is that we can not optimize a partial application.
This is unfortunate, because the |build_fold|
function tends to create large expressions of partially applied functions.
Fortunately we have already solved this problem earlier in our compiler.
We already have a way to detect if an expression is partially applied,
so, in the post processing phase, we do a scan for any partially applied functions.
If we find one, then we move the code into a newly created function, and attempt to optimize it.
We call this function outlining, since it is the opposite of inlining.
If we can not optimize the outlined function, then we do nothing.
Otherwise, we make a new function, and replace the call to the partially applied function
with a call to the outlined function.
This would actually be worth doing even if we did not implement Deforestation.
\begin{samepage}
With function outlining our final optimized code is given below.

> sumPrimes n = enumFromTo_build 2 n f' 0
>
> f' x y = if isPrime x then x + y else y
>
> enumFromTo_build a b c n
>  | a > b      = n
>  | otherwise  = a `c` enumFromTo_build (a+1) b c n
\end{samepage}

This certainly is not perfect, but it is much closer to what we were hoping for.
Combining this with Unboxing and Shortcutting gives us some very efficient code.
While these results are very promising, we still need to know if Deforestation is even valid for Curry.

\subsection{Correctness}
First we show that the |build_fold| theorems are valid for a deterministic subset of Curry
using the same reasoning as the original foldr-build rule.
Without non-determinism and free variables, we can apply the same arguments as the original paper
on shortcut deforestation \cite{shortcutDeforestation}.

\begin{refThm}
For any deterministic |f|, |z|, |g|, |mkf|, and |mkz|,
the following equations hold.
> build_fold mkf mkz (build g) = build (\c n -> g (mkf c) (mkz n))
> foldr f z (build_fold mkf mkz xs) = foldr (mkf f) (mkz z) xs
> build_fold mkf_1 mkz_1 (build_fold mkf_2 mkz_2 xs) = build_fold (mkf_2 . mkf_1) (mkz_2 . mkz_1) xs
\end{refThm}

\begin{proof}
Recall that the free theorem\cite{theoremsForFree} for |build|
is for all |h|, |f|, and |f'| of the appropriate type:
> (forall (a : A) (forall (b : B) h (f a b) = f' a (h b))) =>
> forall (b : B) h (g_B f b) = g_B' f' (h b)

We substitute |build_fold mkf mkz| for |h|, |(:)| for |f| and |mkf (:)| for |f'|.
From the definition of |build_fold| we have
|build_fold mkf mkz (a : b) = (mkf (:)) a (build_fold mkf mkz b)|\\
and |build_fold mkf mkz [] = mkz []|.
Therefore we have |build_fold mkf mkz (g (:) b) = g (mkf (:)) (build_fold mkf mkz b)|\\
This gives us the following result.
> build_fold mkf mkz (build g) = g (mkf (:)) (mkz [])
Finally, working backwards from the definition of |build| we have our theorem.
> build_fold mkf mkz (build g) = build (\c n -> g (mkf c) (mkz n))


\noindent
Again with |foldr| we have the free theorem\\
if |forall (a : A) (forall (b : B) b (x op y) = (a x) ot (b y)| and |b u = u'|\\
then |b . foldr op u = foldr ot u' . (map a)|\\
Here we take |b = build_fold mkf mkz|, |op = f|, and |ot = mkf f| |a = id|\\
then the statement becomes:\\
$\ $\\
if |build_fold mkf mkz (f x y) = (mkf f) x (build_fold mkf mkz y)|\\
and |build_fold mkf mkz [] = mkz []|\\
then |build_fold mkf mkz . foldr f z = foldr (mkf f) (mkz z)|\\
$\ $\\
Since both conditions follow directly from the definition of |build_fold| we are left with
> build_fold mkf mkz . foldr f z = foldr (mkf f) (mkz z)
which is exactly what we wanted.
Free theorems are fun!\\


\noindent
Finally for |build_fold/build_fold| rule
suppose we have the expression
> foldr f z (build_fold mkf_1 mkz_1 (build_fold mkf_2 mkz_2 xs))
From the previous result we have:
> foldr (mkf_1 f) (mkz_1 z) (build_fold mkf_2 mkz_2 xs)
> = foldr (mkf_2 (mkf_1 f)) (mkz_2 (mkz_1 z)) xs
> = foldr ((mkf_2 . mkf_1) f) ((mkz_2 . mkz_1) z) xs
> = foldr f z (build_fold (mkf_2 . mkf_1) (mkz_2 . mkz_1) xs)
which establishes our result:
> build_fold mkf_1 mkz_1 (build_fold mkf_2 mkz_2) = build_fold (mkf_2 . mkf_1) (mkz_2 . mkz_1)

\end{proof}

While this gives us confidence that Deforestation is a possible optimization,
we have already seen that referential transparency \cite{whyFPmatters}, 
and therefore equational reasoning, does not always apply in Curry.
We need to show that both expressions will evaluate to the same set of values in
any contest.
In fact, as they are currently stated, 
These theorems do not actually hold for Curry.
However, with a few assumptions, we can remedy this problem.
\begin{samepage}
First, we need to rewrite our rules so that the reduced expression is in A-Normal form.

> build_fold mkf mkz (build g) =  let g' = (\c n ->  let  f = mkf c
>                                                         z = mkz n
>                                                    in   g f z)
>                                 in build g'
> foldr f z (build_fold mkf mkz xs) =  let  f' = mkf f
>                                           z' = mkz z
>                                      in   foldr f' z' xs
> build_fold mkf_1 mkz_1 (build_fold mkf_2 mkz_2 xs) =  let  mkf = mkf_2 . mkf_1
>                                                            mkz = mkz_2 . mkz_1
>                                                       in   build_fold mkf mkz xs
\end{samepage}

\begin{samepage}
Now we are ready to state our result.
\begin{theorem}
suppose |f|, |z|, |g|, |mkf|, and |mkz| are all FlatCurry functions
whose right had side is an expression in A-Normal form,
then the following equations are valid.
> build_fold mkf mkz (build g) =  let g' = (\c n ->  let  f = mkf c
>                                                         z = mkz n
>                                                    in   g f z)
>                                 in build g'
> foldr f z (build_fold mkf mkz xs) =  let  f' = mkf f
>                                           z' = mkz z
>                                      in   foldr f' z' xs
> build_fold mkf_1 mkz_2 (build_fold mkf_2 mkz_2 xs) =  let  mkf = mkf_2 . mkf_1
>                                                            mkz = mkz12 . mkz_1
>                                                       in   build_fold mkf mkz xs

\end{theorem}
\end{samepage}

\begin{proof}
We show the result for foldr-build, and the rest are similar calculations.
We intend to show that for any |f|, |z|, and |g| that the following equation holds.
> foldr f z (build g (:) []) = g f z
That is, we show that |fold f z (build g (:) [])| reduces to the same values as
|g f z|.

We proceed in a manner similar to \cite{freeTheoremsCurry}.
First, notice that |build g (:) []| is constructing a list.
However, since |g| is potentially non-deterministic, and it might fail,
we may have a non-deterministic alternation of lists when evaluating this expression.
\begin{samepage}
Let us make this explicit.
After evaluating |build g (:) []| we will produce an alternation of several lists.

> build g (:) []  = g_11 : g_12 : g_13 : ... end_1
>                 ? g_21 : g_22 : g_23 : ... end_2
>                   ...
>                 ? g_k1 : g_k2 : g_k3 : ... end_k
Where, for all |i|, |end_i = [] ? EXEMPT|.
\end{samepage}

Here we have a alternation of |k| lists,
and each list ends either with the empty list, or the computation may have failed along the way.
Therefore, |end_i| may be either |[]| or |EXEMPT|.
In fact, it might be the case that an entire list is |EXEMPT|,
but this is fine, because that would still fit this form defined above.

\begin{samepage}
We can generalize this by passing arbitrary arguments to build.
The expression |build g `f` z| evaluates to the following alternation of values.
> build g `f` z
>   =  (g_11 `f` g_12 `f` g_13 `f` ... z_end1) ? 
>      (g_21 `f` g_22 `f` g_23 `f` ... z_end2) ? 
>       ...
>      (g_k1 `f` g_k2 `f` g_k3 `f` ... z_endk)
Where, for all |i|, |z_endi| is |EXEMPT| if |end_i| is |EXEMPT| and |z| otherwise.
\end{samepage}

Now, let us see what happens when we normalize the entire expression.
Recall that if |f| is a dominator of |a ? b|, then |f (a ? b) = f a ? f b| \cite{bubbling}.
Therefore if all arguments are in A-Normal form, then function application distributes over choice.
Since |foldr| is a dominator of everything in |foldr `f` z (build g (:) []| we have the following
\begin{samepage}
derivation.

> foldr `f` z (build g (:) []) 
>   =  let fold = foldr `f` z
>      in fold (build g (:) [])
>   =  let fold = foldr `f` z
>      in fold (  g_11 : g_12 : g_13 : ... end_1 ? 
>                 g_21 : g_22 : g_23 : ... end_2 ? 
>                 ...
>                 g_k1 : g_k2 : g_k3 : ... end_k)
>   =  let fold = foldr `f` z
>      in  fold (  g_11 : g_12 : g_13 : ... end_1) ? 
>          fold (  g_21 : g_22 : g_23 : ... end_2) ? 
>                  ...
>          fold (  g_k1 : g_k2 : g_k3 : ... end_k)
>   =  (g_11 `f` g_12 `f` g_13 `f` ... z_end1) ? 
>      (g_21 `f` g_22 `f` g_23 `f` ... z_end2) ? 
>       ...
>      (g_k1 `f` g_k2 `f` g_k3 `f` ... z_endk)
>   =  g `f` z
Where, for all |i|, |z_endi| is |EXEMPT| if |end_i| is |EXEMPT| and |z| otherwise.
\end{samepage}

This proves the result.

\end{proof}

Note that while this does prove the result, there are still some interesting points here.
First, we never made any assumptions about |f| or |z|.
In fact, we did not really make any assumptions about |g|,
but we did at least give an explicit form for its values.
This form is guaranteed by the type.
This line of reasoning looks like a promising direction
for future explorations into parametricity for functional-logic programming.

\begin{samepage}
Second, it should be noted that branches in |g| that produce |EXEMPT| do not necessarily
fail when evaluated.
If |f| is strict, then any failure in the list will cause the entire branch to fail.
Consider the following expression:
> foldr (\x y -> 1) 0 (build (\c n -> 0 `c` 1 `c` EXEMPT))
\end{samepage}

Evaluating the expression rooted by |build| to constructor normal form would produce a failure,
since the tail of the list is |EXEMPT|.
However, since the first parameter in the expression rooted by |foldr| 
never looks at either of it is arguments,
this branch of the computation can still return a result.


In this chapter we have developed three optimizations to help reduce the memory allocated by
Curry programs.
These optimizations seem effective, and we have shown why they are correct,
but we still need to find out how effective they are.
In the next chapter we show how well our compiler compares to 
Pakcs, Kics2, and MCC on the benchmarking suite provided by Kics2.
We also show the results for each optimization individually, and then combined.

