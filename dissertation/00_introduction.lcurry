
With all of the chaos in the world today,
sometimes it is nice to just relax and make a nice Curry.
But people today are impatient.
They cannot wait; they want their Curry fast.
This is a problem, because Curry implementations have historically been considered slow.
Some have considered it unusably slow,
which is a shame, because Curry is actually a great language,
and can solve many problems well.
In this dissertation we aim to rectify the problem
of Curry taking too long.
We present the \ricesp Curry compiler,
and show how it can deliver a fast, satisfying, Curry.

\section{Why Curry?} \label{sec:intro:why}

Functional logic programming is a very powerful technique for
expressing complicated ideas in a simple form.
Curry implements these ideas with a clean, easy to read syntax,
which is similar to Haskell, a well known functional programming language.
It is also lazy, so evaluation of Curry programs is similar to Haskell as well.
Curry extends Haskell with two concepts from logic programming.
First, there are non-deterministic functions, such as ``|?|''.  
Semantically |a ? b| will evaluate
|a| and |b| and will return both answers to the user.
Second, there are free, or logic, variables.
A free variable is a variable that is not in the scope of the current function.
The value of a free variable is not defined, but it may be constrained.

These features are very useful for solving constraint problems.
Consider the problem of scheduling a test for a large class of students.
Since the class is so large, the students cannot take the test at the same time.
To solve this problem we allow each student to choose all times that they are available
to take the test.
After they have selected their times we partition the students into groups, where each group
corresponds to a testing time, and each group is less than a given capacity.

This is a solvable problem in any language,
but the solution in Curry is both concise and easily understood.

\begin{minipage}{\textwidth}
> type Time = Int
> type Name = String
> type Student = (Name, [Time])
> type Test = [Name]
>
> schedule :: [Test] -> [Student] -> [Test]
> schedule tests = foldr takeTest tests
>
> takeTest :: Student -> [Test] -> [Test]
> takeTest (name, times) tests = anyOf (map (testAt name tests) times)
>
> testAt :: Name -> [Test] -> Time -> [Test]
> testAt name tests k
>   | length test < capacity 
>   = ts1++[name : test]++ts2
>  where (ts1,test:ts2) = splitAt k
\end{minipage}

The students are scheduled one at a time.
Each student has a name, and a list of times that they are available to test.
We non-deterministically place the student in one of the times they marked as available.
To place a student in the $k^{th}$ test, we split the list into the tests before $k$,
which we call |ts1|, and the lists after $k$, which we call |ts2|.
Finally, we check that after putting the student in test $k$, 
That test will still be below the capacity.

We give a fuller account of the semantics in chapters \ref{ch:math} 
and \ref{ch:language},

\section{Current Compilers} \label{sec:intro:current}

There are currently two mature Curry compilers, Pakcs \cite{pakcs} and Kics2 \cite{kics2}.
Pakcs compiles Curry to Prolog in an effort to leverage Prolog's non-determinism and free variables.
Kics2 compiles Curry to Haskell in an effort to leverage Haskell's
higher-order functions and optimizing compiler.
Both compilers have their advantages.
Pakcs tends to perform better on non-deterministic expressions with free variables,
where Kics2 tends to perform much better on deterministic expressions.
Unfortunately neither of these compilers perform well in both circumstances.

Sprite \cite{sprite}, an experimental compiler, aims to fix these inefficiencies.
The strategy is to compile to a virtual assembly language, known as LLVM.
So far, Sprite has shown promising improvements over both Pakcs and Kics2 in performance,
but it is not readily available for testing at the time of this writing.

Similarly Mcc \cite{mcc} also worked to improve performance by compiling to C.
While Mcc often ran faster than both Pakcs or Kics2,
it could perform very slowly on common Curry examples.
It is also no longer in active development.

One major disadvantage of all four compilers is that they all
attempt to pass off optimization to another compiler.
Pakcs attempts to have Prolog optimize the non-deterministic code;
Kics2 attempts to use Haskell to optimize
deterministic code; Sprite attempts to use LLVM to optimize the low level code;
and Mcc simply did not optimize its code.
Unfortunately none of these approaches works very well.
While some implementations of Prolog can optimize non-deterministic expressions,
they have no concept of higher-order functions,
so there are many optimizations that cannot be applied.
Kics2 is in a similar situation.  
In order to incorporate non-deterministic computations in Haskell, 
a significant amount of code must be threaded through each computation.
This means that any non-deterministic expression cannot be optimized in Kics2.
Finally, since LLVM does not know about either higher-order functions or non-determinism,
it loses many easy opportunities for optimization.

Curry programs have one last hope for efficient execution.
Recently, many scientists \cite{peval, offline_peval} 
have developed a strong theory of partial evaluation for functional logic programs.
While these results are interesting, partial evaluation is not currently automatic in Curry.
Guidance is required from the programmer to run the optimization.
Furthermore, the optimization fails to optimize several common programs.

\section{The Need for Optimizations} \label{sec:intro:need}

So far, none of these approaches have included the large body 
of work on program optimizations
\cite{orbit, dragon, optimizationAllen, dataflowAllen, ssa, compilersAppel, continuationsAppel, 
ANormal, shortcutDeforestation, ultimateGoto, rabbit, lambdaRename, dataflowKildall, dominatorFlow, 
haskellInliner, stg, ssaVariable, deforestationWadler, ssaOptimizations }.
This leads to the inescapable conclusion that Curry needs an optimizer.
We propose a new compiler environment for developing and testing optimizations,
which we call the Reduction Inspired Compiler Environment (\rice) Curry compiler.
This compiler is intended to make developing new optimizations for Curry as simple as possible.
We test this idea by developing several common optimizations for the \ricesp compiler.
Furthermore we implement three specific optimizations for Curry, 
Unboxing \cite{unboxing}, Case Shortcutting \cite{shortcutting}, 
and Deforestation \cite{shortcutDeforestation}.
While Unboxing and Deforestation are well known in the function languages community,
the techniques have not been applied in a function logic setting.
Case Shortcutting is a unique optimization for functional logic programs.
We chose these optimizations specifically because they focus on reducing the amount of memory
consumed by programs, which is a common problem for Curry programs \cite{proposal}.

\section{Contributions} \label{sec:intro:contribute}

This work focuses on the construction of an efficient compiler for the Curry programming language.
The main contributions of this dissertation are as follows.
\begin{itemize}
\item We build an efficient implementation of the Curry language. (Section~\ref{sec:language:eval})
\item We identify aspects of existing Curry compilers, Kics2 and Pakcs, that lead to inefficiency.  Specifically:
    \begin{itemize}
    \item We show that compilation of Curry does not require converting all programs to Uniform Programs 
          \cite{Kics2Theory},
          which is more efficient than Kics2's compilation scheme. (Section~\ref{sec:language:nondet})
    \item We give a new backtracking algorithm that omits backtracking deterministic expressions,
          which is more efficient than backtracking in Pakcs. (Section~\ref{sec:language:backtrack})
    \end{itemize}
\item We state and prove the Path Compression Theorem, which justifies several of our transformations,
      as well as improvements to the run-time system. (Section~\ref{sec:language:backtrack})
\item We introduce the \gassp system,
      which is a library for constructing program transformations.
      This is not a new idea\cite{haskellComp},
      but we show how using functional logic ideas can improve the implementation. 
      (Section~\ref{sec:gas:opts})

\item We show that, after converting programs to A-Normal Form,
      important optimizations that are valid for lazy functional programs
      are also valid for lazy functional logic programs.
      Specifically, we show that both inlining and reduction
      remain valid for Curry programs, which is not true without the conversion to A-normal form. 
      (Section~\ref{sec:opts:anf})

\item We implement three memory optimizations that have 
      not been previously implemented for functional logic programs. (Chapter~\ref{ch:mine})

\begin{itemize}
\item We implement unboxing by making boxes first class values in our language \cite{unboxing}, 
      and justify its correctness. (Section~\ref{sec:mine:unbox})

\item We show a new optimization for functional logic programs called case shortcutting.
      We show the problems with trying to elide constructing a node that is evaluated in a case
      expression, then we show how this problem can be solved with a new node. 
      (Section~\ref{sec:mine:shortcut})

\item We implement shortcut deforestation \cite{shortcutDeforestation},
      and show that, under suitable conditions, it remains correct for functional logic programs.
      In order to get decent performance out of this optimization, 
      we develop a scheme for outlining and optimizing partial applications.
      (Section~\ref{sec:mine:deforest})
\end{itemize}

\item We show that programs compiled with \ricesp are anywhere from 10 to 1000 times faster
      than those compiled with the Kics2 compiler, which is the current state of the art.
      (Section~\ref{sec:results:tests})

\item We show that programs compiled with optimizations are almost always at least twice as fast
      as those compiled without, and sometimes up to twenty times as fast.
      (Section~\ref{sec:results:tests})
\end{itemize}

\section{Overview} \label{sec:intro:overview}

The rest of this dissertation is organized as follows.
Chapter \ref{ch:math} presents the mathematical background of Term and Graph Rewriting.
Notions from rewriting will be used throughout this dissertation,
both because the operational semantics of Curry were first described using rewriting,
and because our optimizing engine is based on constructing rewrite rules.
Chapter \ref{ch:language} presents the Curry Language and its semantics.
We introduce the Curry language and describe the IR FlatCurry as well as some conceptual hurdles
with implementing a functional logic language.
We also introduce two novel approaches to improving the performance of evaluation, case function
and fast backtracking.
Case functions can be applied to any evaluation model for Curry,
while fast backtracking is specific to backtracking implementations.
Chapter \ref{ch:codegen} discusses the target code for this compiler.
We describe, by example, the generated code for simple functions,
then we describe the changed needed to add additional features of Curry.
Chapter \ref{ch:gas} introduces the \gassp system for implementing optimizations.
This is arguably the most important contribution to this paper,
as it showcases how Curry can improve the process of writing large pieces of software like
optimizing compilers.
We describe the system, its implementation, and show how to construct optimizations with it.
Chapter \ref{ch:pipeline} overviews the compiler pipeline, and the translation to C.
We show the compiler pipeline, and how \gassp simplifies several of the transformations.
Chapter \ref{ch:opts} discusses the implementation of several common optimizations.
We show several common optimizations including inlining, reduction, and case canceling.
We also introduce A-Normal form, which is required for the correctness of these optimizations.
Chapter \ref{ch:mine} discusses the implementation of Unboxing, Shortcutting, and Deforestation.
Chapter \ref{ch:results} shows the results of our optimizations.
Finally, Chapter \ref{ch:conclusion} concludes and discusses future work.

